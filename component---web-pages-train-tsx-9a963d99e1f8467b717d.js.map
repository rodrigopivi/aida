{"version":3,"sources":["webpack:///./web/components/Logo.tsx","webpack:///./web/components/DefaultHeader.tsx","webpack:///./.cache/public-page-renderer.js","webpack:///./.cache/public-page-renderer-prod.js","webpack:///./web/components/Layout.tsx","webpack:///./.cache/gatsby-browser-entry.js","webpack:///./src/pipelines/zebraWings/pipeline.ts","webpack:///./src/languages/en/EnglishTokenizer.ts","webpack:///./src/languages/es/SpanishTokenizer.ts","webpack:///./src/pipelines/zebraWings/embeddings/EmbeddingsModel.ts","webpack:///./src/pipelines/zebraWings/embeddings/CombineNgramsLayer.ts","webpack:///./src/pipelines/zebraWings/embeddings/PreSavedEmbeddingsInitializer.ts","webpack:///./src/pipelines/zebraWings/models/classification.ts","webpack:///./src/pipelines/zebraWings/models/ner.ts","webpack:///./src/pipelines/zebraWings/TimeSeriesAttention.ts","webpack:///./web/components/TrainedPipelineTestInput.tsx","webpack:///./web/pages/train.tsx","webpack:///./web/components/TrainExample.tsx","webpack:///./web/components/TrainingDashboard.tsx","webpack:///./node_modules/antd/lib/steps/style/css.js","webpack:///./node_modules/antd/lib/steps/index.js","webpack:///./node_modules/antd/lib/alert/style/css.js","webpack:///./node_modules/antd/lib/alert/index.js","webpack:///./node_modules/antd/lib/_util/getDataOrAriaProps.js","webpack:///./web/components/LineChart.tsx","webpack:///./node_modules/rc-steps/es/utils.js","webpack:///./node_modules/rc-steps/es/Steps.js","webpack:///./node_modules/rc-steps/es/Step.js","webpack:///./node_modules/rc-steps/es/index.js"],"names":["__webpack_require__","ColoredText","styled","div","withConfig","displayName","componentId","Logo","extend","_templateObject","React","createElement","_reactHelmet","default","key","title","meta","name","content","rel","href","sizes","type","color","_interopRequireWildcard","m","module","exports","_react","_interopRequireDefault","_propTypes","_pageRenderer","_loader","ProdPageRenderer","_ref","location","pageResources","loader","getResourcesForPathnameSync","pathname","InternalPageRenderer","_objectSpread","json","propTypes","PropTypes","shape","string","isRequired","_gatsbyLink","_styledComponents","_Logo","Header","Content","Footer","overviewRouteRE","demoRouteRE","trainRouteRE","StyledContent","MainLayout","Component","defaultSelectedKeys","test","this","props","_layout","style","minHeight","background","padding","display","textAlign","width","paddingLeft","paddingRight","className","to","flex","float","fontSize","_icon","flexDirection","Sider","breakpoint","collapsedWidth","theme","backgroundColor","_menu","mode","Item","children","Error","_waitForRouteChange","_publicPageRenderer","_parsePath","StaticQueryContext","createContext","StaticQuery","Consumer","staticQueryData","data","query","render","object","func","_EnglishTokenizer","_SpanishTokenizer","_EmbeddingsModel","_classification","_ner","defaultPipelineDefinition","config","classification","epochs","filterSizes","lowConfidenceThreshold","numFilters","batchSize","drop","embeddingDimensions","lossThresholdToStopTraining","maxNgrams","trainingValidationSplit","ner","addAttention","rnnUnits","AidaPipeline","cfg","_this","_classCallCheck","_defineProperty","_asyncToGenerator","regeneratorRuntime","mark","_callee","trainDataset","wrap","_context","prev","next","logger","log","classificationModel","train","nerModel","stop","_x","apply","arguments","_ref2","_callee2","testDataset","classificationStats","nerStats","_context2","sent","abrupt","_x2","sentences","predict","_ref3","_callee3","_context3","tfModel","save","classificationPath","nerPath","embeddingsModel","embeddingPath","_x3","pipelineDefinition","datasetParams","tokenizer","language","lang","toLowerCase","englishTokenizer","spanishTokenizer","getTokenizer","EmbeddingsModel","ngramToIdDictionary","maxWordsPerSentence","pretrainedEmbedding","pretrainedNGramVectors","classificationTrainStatsHandler","nerTrainStatsHandler","classificationCfg","Object","assign","trainStatsHandler","ClassificationModel","pretrainedClassifier","nerCfg","NerModel","pretrainedNer","zero","one","two","three","four","five","six","seven","eight","nine","sentence","trim","replace","FILTER_CHARS_REGEXP","sanitizeSentence","split","WORD_SEPARATORS_REGEXP","map","w","filter","word","grams","index","length","substr","words","join","cero","uno","dos","tres","cuatro","cinco","seis","siete","ocho","nueve","tf","_CombineNgramsLayer","_PreSavedEmbeddingsInitializer","maxWords","pretrainedEmbeddingModel","model","inputModel","input","layers","dtype","embedded","inputs","outputs","tidy","sentencesTensor","sentencesToWordIds","output","modelInput","predictOnBatch","dispose","sentencesSplittedByWords","s","splitSentenceToWords","buffer","forEach","sentenceIndex","wordIndex","undefined","set","generateWordIdsFromNGrams","gram","gramIndex","console","warn","toTensor","vecIds","addToVecsIfNotUndefined","k","push","allNgramsFound","splitWordToBiGrams","wt","setupModel","Map","sequential","embedLayer","embedding","embeddingsInitializer","PreSavedEmbeddingsInitializer","inputDim","size","inputLength","maskZero","outputDim","trainable","add","timeDistributed","layer","inputShape","CombineNgramsLayer","_losses","Layer","kwargs","_this2","invokeCallHook","combined","sum","l2Normalize","serialization","SerializationMap","register","initializers","_lodash","_getPrototypeOf","call","_assertThisInitialized","Initializer","flatMat","flatMapDeep","_toConsumableArray","values","tensor2d","zeros","types","pretrainedModel","prediction","embeddedSentences","embed","d","dataSync","intents","i","preds","slice","sentencePreds","p","idx","confidence","intent","sort","a","b","trainYChunks","trainXChunks","enoughAccuracyReached","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_iterator","_step","_step$value","xChunk","dataLabels","hotEncodedLabels","h","c","chunk","trainY","trainX","entries","Symbol","iterator","done","_slicedToArray","value","tensor1d","oneHot","fit","callbacks","onBatchEnd","nextFrame","shuffle","validationSplit","history","val_loss","batch","batchEpochs","epoch","currentBatchSize","tensorsInMemory","memory","numTensors","totalBatches","trainingAccuracy","acc","trainingLoss","loss","validationAccuracy","val_acc","validationLoss","concat","t0","return","finish","testExamples","resultsHandler","handler","stats","x","y","_iteratorNormalCompletion2","_didIteratorError2","_iteratorError2","_iterator2","_step2","_step2$value","predictions","defaultResultsLogger","correct","wrong","lowConfidence","testX","testY","o","debug","error","setup","PipelineModel","numClasses","optimizer","adam","convLayer1","conv1d","activation","filters","kernelInitializer","kernelSize","maxpool1","maxPooling1d","poolSize","convLayer2","maxpool2","convLayer3","maxpool3","concatLayer","concatenate","axis","flat","flatten","dropOut","dropout","rate","flatPool1","concatForClassification","outClassification","dense","units","compile","metrics","_TimeSeriesAttention","classificationPred","_this$datasetParams","slotsToId","slotTypesLength","keys","encodedIntent","intentEncoded","Array","fill","indexOf","intentsFlat","classLabel","flattenedPredictions","sp","wordTagPredictions","highestIndex","tp","ti","wordPredictionsChunk","rawPrediction","sentenceWordPredictionIds","sentenceWords","reduce","accumulator","currentIndex","current","currentSlotKey","find","slotKey","slots","trainY2Chunks","_this$config","slotsLength","_loop","_ret","trainY2","intentLabels","embeddedSentenceWords","slotTags","v","asType","y2sentences","wordsSlotId","slotIds","pad","ohe","err","stack","delegateYield","_typeof","t1","testY2","_iteratorNormalCompletion3","_didIteratorError3","_iteratorError3","_loop2","_iterator3","_step3","_context4","_step3$value","classifications","y2","sentenceIdx","expectedTags","predictedTags","tag","numSlotTypes","embeddedSentencesInput","classLabelInput","classLabelRepeated","repeatVector","n","concated","biLstm","bidirectional","lstm","returnSequences","finalHidden","timeAttention","TimeSeriesAttention","_topology","inputSpec","InputSpec","ndim","supportsMasking","dimensions","timed","build","trainableWeights","nonTrainableWeights","built","encoded","permuted","permute","dims","unstackedInput","unstack","unstackedPermuted","dotProds","ui","dot","selfAttend","attention","softmax","attentionPermuted","unstackedOutput","ua","SearchInput","_input","Search","TrainedPipelineTestInput","disabled","outTextContent","target","pipeline","setState","JSON","stringify","inputSearch","document","getElementById","_row","justify","_col","span","sm","_card","placeholder","enterButton","onSearch","handleSubmit","id","state","renderIntentsList","marginTop","_DefaultHeader","_Layout","_TrainExample","_axios","_TrainingDashboard","TrainExample","datasetTest","datasetTraining","downloadProgress","embeddingsAndTrainingDatasetLoaded","isDownloading","files","total","progress","downloads","Promise","all","file","axios","get","onDownloadProgress","progressEvent","totalLength","lengthComputable","getResponseHeader","Math","round","loaded","ms","resolve","setTimeout","jsonFiles","withPrefix","downloadFiles","timeoutInMs","_this$state","disableDownload","buttonMessage","marginLeft","_progress","percent","_button","onClick","trainTestAndSaveModels","_pipeline","_LineChart","_TrainedPipelineTestInput","globalLog","LoggerFeed","TrainingDashboard","currentStep","logLinesCounter","pipelineFinishedTraining","plot","valuesClassification","valuesNer","Fragment","_alert","message","marginBottom","batchInfo","lineChart","dataValues","extra","trainStatsClassification","trainStatsNer","logHandler","disposeVariables","_steps","Step","renderPipelineManualTestInput","renderChart","defineProperty","_extends3","_classCallCheck3","_createClass3","_possibleConstructorReturn3","_inherits3","_rcSteps2","_icon2","obj","__esModule","newObj","prototype","hasOwnProperty","Steps","_React$Component","__proto__","getPrototypeOf","prefixCls","icons","defaultProps","iconPrefix","number","_defineProperty3","ReactDOM","_rcAnimate2","_classnames2","_getDataOrAriaProps2","noop","Alert","handleClose","e","preventDefault","dom","findDOMNode","height","offsetHeight","closing","onClose","animationEnd","closed","afterClose","_classNames","_props","closable","description","_props$prefixCls","closeText","showIcon","banner","_props$className","iconType","iconTheme","alertCls","closeIcon","dataOrAriaProps","iconNode","component","showProp","transitionName","onEnd","data-show","AidaLineChart","isFlexSupported","window","documentElement","Steps_Steps","_Component","classCallCheck_default","possibleConstructorReturn_default","calcStepOffsetWidth","domNode","react_dom","calcTimeout","clearTimeout","lastStepOffsetWidth","lastChild","offsetWidth","abs","flexSupported","debounce_default","inherits_default","componentDidMount","componentDidUpdate","componentWillUnmount","cancel","_props$style","direction","labelPlacement","status","progressDot","initial","restProps","objectWithoutProperties_default","_state","filteredChildren","react_default","Children","toArray","lastIndex","adjustedlabelPlacement","classString","classnames_default","extends_default","react","child","stepNumber","childProps","wrapperStyle","itemWidth","adjustMarginRight","prop_types_default","any","oneOfType","bool","node","es_Steps","isString","str","Step_Step","renderIconNode","icon","iconClassName","iconDot","_classNames2","_props2","_props2$status","tailContent","stepItemStyle","marginRight","es_Step","__webpack_exports__"],"mappings":"0FACA,8SADAA,EAAA,KAIO,IAAMC,MAHbD,EAAA,kCAG2BE,QAAOC,IAAVC,WAAA,CAAAC,YAAA,oBAAAC,YAAA,gBAAGJ,CAAH,kdAuBjB,IAAMK,EAAON,EAAYO,OAAfC,2GCxBF,WACX,OACIC,EAAAC,cAACC,EAAAC,QAAD,CACIC,IAAI,SACJC,MAAM,OACNC,KAAM,CACF,CAAEC,KAAM,cAAeC,QAAS,4CAChC,CACIA,QACI,kJACJD,KAAM,cAIdP,EAAAC,cAAA,QAAMQ,IAAI,gBAAgBC,KAAK,iBAC/BV,EAAAC,cAAA,QAAMQ,IAAI,mBAAmBE,MAAM,UAAUD,KAAK,0BAClDV,EAAAC,cAAA,QAAMQ,IAAI,OAAOG,KAAK,YAAYD,MAAM,QAAQD,KAAK,uBACrDV,EAAAC,cAAA,QAAMQ,IAAI,OAAOG,KAAK,YAAYD,MAAM,QAAQD,KAAK,uBACrDV,EAAAC,cAAA,QAAMQ,IAAI,WAAWC,KAAK,sBAC1BV,EAAAC,cAAA,QAAMQ,IAAI,YAAYC,KAAK,yBAAyBG,MAAM,YAC1Db,EAAAC,cAAA,QAAMM,KAAK,0BAA0BC,QAAQ,YAC7CR,EAAAC,cAAA,QAAMM,KAAK,cAAcC,QAAQ,YACjCR,EAAAC,cAAA,QAAMM,KAAK,WAAWC,QAAQ,4CAzB1C,MAAAR,ySAAAc,CAAAxB,EAAA,IACAY,KAAAZ,EAAA,uDCDA,IAAsByB,EAKpBC,EAAOC,SALaF,EAKWzB,EAAQ,OALRyB,EAAEZ,SAAYY,sGCA/C,IAAAG,EAAAC,EAAA7B,EAAA,IACA8B,EAAAD,EAAA7B,EAAA,IAEA+B,EAAAF,EAAA7B,EAAA,KACAgC,EAAAH,EAAA7B,EAAA,+KAEA,IAAMiC,EAAmB,SAAAC,GAAkB,IAAfC,EAAeD,EAAfC,SACpBC,EAAgBC,UAAOC,4BAA4BH,EAASI,UAClE,OAAO7B,UAAMC,cAAc6B,4UAApBC,CAAA,CACLN,WACAC,iBACGA,EAAcM,QAIrBT,EAAiBU,UAAY,CAC3BR,SAAUS,UAAUC,MAAM,CACxBN,SAAUK,UAAUE,OAAOC,aAC1BA,kBAGUd,2ZCrBfjC,EAAA,KAEA,IAAAgD,EAAAnB,EAAA7B,EAAA,KACAU,ySAAAc,CAAAxB,EAAA,IACAiD,EAAApB,EAAA7B,EAAA,KACAkD,EAAAlD,EAAA,8nBAEQmD,mBAAQC,oBAASC,mBAEnBC,EAAkB,uBAClBC,EAAc,mBACdC,EAAe,oBAEfC,GAAgB,EAAAR,EAAApC,SAAOuC,GAAVhD,WAAA,CAAAC,YAAA,wBAAAC,YAAA,gBAAG,CAAH,8FASEoD,gaAAmBhD,EAAMiD,kDAEtC,IAAIC,EAAsB,KAQ1B,OAPIN,EAAgBO,KAAKC,KAAKC,MAAM5B,SAASI,UACzCqB,EAAsB,IACfL,EAAYM,KAAKC,KAAKC,MAAM5B,SAASI,UAC5CqB,EAAsB,IACfJ,EAAaK,KAAKC,KAAKC,MAAM5B,SAASI,YAC7CqB,EAAsB,KAGtBlD,EAAAC,cAAAqD,EAAAnD,QAAA,CAAQoD,MAAO,CAAEC,UAAW,UACxBxD,EAAAC,cAACwC,EAAD,CAAQc,MAAO,CAAEE,WAAY,UAAWC,QAAS,EAAGC,QAAS,SACzD3D,EAAAC,cAACuC,EAAA3C,KAAD,CAAM0D,MAAO,CAAEK,UAAW,QAASC,MAAO,IAAKC,YAAa,GAAIC,aAAc,IAAMC,UAAU,UAC1FhE,EAAAC,cAACqC,EAAAnC,QAAD,CAAM8D,GAAG,KAAT,cAEJjE,EAAAC,cAAA,OAAKsD,MAAO,CAAEW,KAAM,KACpBlE,EAAAC,cAAA,OAAKsD,MAAO,CAAEG,QAAS,gBAAiBC,QAAS,eAAgBC,UAAW,QAASO,MAAO,UACxFnE,EAAAC,cAAA,KAAGS,KAAK,sCAAsCL,MAAM,OAAOkD,MAAO,CAAEa,SAAU,KAC1EpE,EAAAC,cAAAoE,EAAAlE,QAAA,CAAMS,KAAK,cAIvBZ,EAAAC,cAAAqD,EAAAnD,QAAA,CAAQoD,MAAO,CAAEe,cAAe,QAC5BtE,EAAAC,cAAAqD,EAAAnD,QAAQoE,MAAR,CAAcV,MAAO,IAAKW,WAAW,KAAKC,eAAe,IAAIC,MAAM,QAAQnB,MAAO,CAAEoB,gBAAiB,YACjG3E,EAAAC,cAAA2E,EAAAzE,QAAA,CAAMuE,MAAM,QAAQG,KAAK,SAAS3B,oBAAqB,CAACA,GAAsBK,MAAO,CAAEE,WAAY,YAC/FzD,EAAAC,cAAA2E,EAAAzE,QAAM2E,KAAN,CAAW1E,IAAI,KACXJ,EAAAC,cAACqC,EAAAnC,QAAD,CAAM8D,GAAG,aACLjE,EAAAC,cAAAoE,EAAAlE,QAAA,CAAMS,KAAK,mBADf,aAKJZ,EAAAC,cAAA2E,EAAAzE,QAAM2E,KAAN,CAAW1E,IAAI,KACXJ,EAAAC,cAACqC,EAAAnC,QAAD,CAAM8D,GAAG,SACLjE,EAAAC,cAAAoE,EAAAlE,QAAA,CAAMS,KAAK,mBADf,SAKJZ,EAAAC,cAAA2E,EAAAzE,QAAM2E,KAAN,CAAW1E,IAAI,KACXJ,EAAAC,cAACqC,EAAAnC,QAAD,CAAM8D,GAAG,UACLjE,EAAAC,cAAAoE,EAAAlE,QAAA,CAAMS,KAAK,mBADf,qBAOZZ,EAAAC,cAAAqD,EAAAnD,QAAA,CAAQoD,MAAO,CAAEG,QAAS,kBACtB1D,EAAAC,cAAC8C,EAAD,KAAgBK,KAAKC,MAAM0B,UAC3B/E,EAAAC,cAAC0C,EAAD,CAAQY,MAAO,CAAEK,UAAW,WAA5B,iLC/BxB,WACE,MAAM,IAAIoB,MACR,ipCAzCJ,IAAA9D,EAAAC,EAAA7B,EAAA,IACA8B,EAAAD,EAAA7B,EAAA,IACAgD,ySAAAxB,CAAAxB,EAAA,KAOA2F,EAAA3F,EAAA,IACA4F,EAAA/D,EAAA7B,EAAA,MACA6F,EAAAhE,EAAA7B,EAAA,wDAEA,IAAM8F,EAAqBpF,UAAMqF,cAAc,2BAE/C,IAAMC,EAAc,SAAAjC,GAAK,OACvBnC,EAAAf,QAAAF,cAACmF,EAAmBG,SAApB,KACG,SAAAC,GACC,OACEnC,EAAMoC,MACLD,EAAgBnC,EAAMqC,QAAUF,EAAgBnC,EAAMqC,OAAOD,MAEtDpC,EAAMsC,QAAUtC,EAAM0B,UAC5B1B,EAAMoC,KAAOpC,EAAMoC,KAAKA,KAAOD,EAAgBnC,EAAMqC,OAAOD,MAGvDvE,EAAAf,QAAAF,cAAA,uDAMfqF,EAAYrD,UAAY,CACtBwD,KAAMvD,UAAU0D,OAChBF,MAAOxD,UAAUE,OAAOC,WACxBsD,OAAQzD,UAAU2D,KAClBd,SAAU7C,UAAU2D,yXCnCtB,IAAAC,EAAA3E,EAAA7B,EAAA,MACAyG,EAAA5E,EAAA7B,EAAA,MAEA0G,EAAA1G,EAAA,KACA2G,EAAA9E,EAAA7B,EAAA,MACA4G,EAAA/E,EAAA7B,EAAA,2eAYO,IAAM6G,EAAuD,CAChEC,OAAQ,CACJC,eAAgB,CACZC,OAAQ,EACRC,YAAa,CAAC,EAAG,EAAG,GACpBC,uBAAwB,GACxBC,WAAY,KAEhBtG,QAAS,CAILuG,UAAW,IACXC,KAAM,GACNC,oBAAqB,IACrBC,4BAA6B,KAC7BC,UAAW,GACXC,wBAAyB,IAE7BC,IAAK,CACDC,cAAc,EACdX,OAAQ,EACRE,uBAAwB,GACxBC,WAAY,CAAC,IAAK,KAClBS,SAAU,oDAalB,SAAAC,EAAYC,GAUT,IAAAC,EAAAjE,kGAAAkE,CAAAlE,KAAA+D,GAAAI,EAAAnE,KAAA,qBAlBqD+C,GAkBrDoB,EAAAnE,KAAA,wBAAAmE,EAAAnE,KAAA,0BAAAmE,EAAAnE,KAAA,8BAAAmE,EAAAnE,KAAA,mBAAAmE,EAAAnE,KAAA,iBAAAmE,EAAAnE,KAAA,oBAAAmE,EAAAnE,KAAA,SAAA5B,EAAAgG,EAAAC,mBAAAC,KA0CY,SAAAC,EAAOC,GAAP,OAAAH,mBAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,cACXX,EAAKY,OAAOC,IAAI,mCAChBb,EAAKY,OAAOC,IAAI,sGAFLJ,EAAAE,KAAA,EAGLX,EAAKc,oBAAoBC,MAAMR,GAH1B,cAAAE,EAAAE,KAAA,EAILX,EAAKgB,SAASD,MAAMR,GAJf,OAKXP,EAAKY,OAAOC,IAAI,sCAChBb,EAAKY,OAAOC,IAAI,sGANL,wBAAAJ,EAAAQ,SAAAX,EAAAvE,SA1CZ,SAAAmF,GAAA,OAAA/G,EAAAgH,MAAApF,KAAAqF,cAAAlB,EAAAnE,KAAA,QAAAsF,EAAAlB,EAAAC,mBAAAC,KAmDW,SAAAiB,EAAOC,GAAP,IAAAC,EAAAC,EAAA,OAAArB,mBAAAI,KAAA,SAAAkB,GAAA,cAAAA,EAAAhB,KAAAgB,EAAAf,MAAA,cACVX,EAAKY,OAAOC,IAAI,kCAChBb,EAAKY,OAAOC,IAAI,sGAFNa,EAAAf,KAAA,EAGwBX,EAAKc,oBAAoBhF,KAAKyF,GAHtD,cAGJC,EAHIE,EAAAC,KAAAD,EAAAf,KAAA,EAIaX,EAAKgB,SAASlF,KAAKyF,GAJhC,cAIJE,EAJIC,EAAAC,KAAAD,EAAAE,OAAA,SAKH,CAAEJ,sBAAqBC,aALpB,wBAAAC,EAAAT,SAAAK,EAAAvF,SAnDX,SAAA8F,GAAA,OAAAR,EAAAF,MAAApF,KAAAqF,cAAAlB,EAAAnE,KAAA,UA2Dc,SAAC+F,GACd,IAAM9C,EAAiBgB,EAAKc,oBAAoBiB,QAAQD,GAExD,MAAO,CAAE9C,iBAAgBW,IADbK,EAAKgB,SAASe,QAAQD,EAAW9C,MA7D9CkB,EAAAnE,KAAA,QAAAiG,EAAA7B,EAAAC,mBAAAC,KAiEW,SAAA4B,EAAOlC,GAAP,OAAAK,mBAAAI,KAAA,SAAA0B,GAAA,cAAAA,EAAAxB,KAAAwB,EAAAvB,MAAA,cACVX,EAAKY,OAAOC,IAAI,2BAChBb,EAAKY,OAAOC,IAAI,sGAFNqB,EAAAvB,KAAA,EAGJX,EAAKc,oBAAoBqB,UAAUC,KAAKrC,EAAIsC,oBAHxC,cAAAH,EAAAvB,KAAA,EAIJX,EAAKgB,SAASmB,UAAUC,KAAKrC,EAAIuC,SAJ7B,cAAAJ,EAAAvB,KAAA,EAKJX,EAAKuC,gBAAgBJ,UAAUC,KAAKrC,EAAIyC,eALpC,wBAAAN,EAAAjB,SAAAgB,EAAAlG,SAjEX,SAAA0G,GAAA,OAAAT,EAAAb,MAAApF,KAAAqF,cACKrB,EAAI2C,qBACJ3G,KAAK2G,mBAAqB3C,EAAI2C,oBAElC3G,KAAK4G,cAAgB5C,EAAI4C,cACzB5G,KAAK6E,OAASb,EAAIa,OAClB7E,KAAK6G,UA/Db,SAAsBC,GAClB,IAAMC,EAAOD,EAAWA,EAASE,cAAgBF,EACjD,GAAa,OAATC,EACA,OAAOE,UACJ,GAAa,OAATF,EACP,OAAOG,UAEX,MAAM,IAAItF,MAAM,8DAwDKuF,CAAanH,KAAK4G,cAAcE,UACjD9G,KAAKwG,gBAAkB,IAAIY,kBACvBpD,EAAIqD,oBACJrD,EAAI4C,cAAcU,oBAClBtH,KAAK2G,mBAAmB3D,OAAOjG,QAAQ2G,UACvC1D,KAAK2G,mBAAmB3D,OAAOjG,QAAQyG,oBACvCxD,KAAK6G,UACL7C,EAAIuD,oBACJvD,EAAIwD,wBAdT,IAAAvB,EAAA,IAAAX,EAAA,IAAAlH,EAgBC,IACIqJ,EACAC,EAFEC,EAAoBC,OAAOC,OAAO,GAAI7H,KAAK2G,mBAAmB3D,OAAOjG,QAASiD,KAAK2G,mBAAmB3D,OAAOC,gBAG/Ge,EAAI8D,oBACJL,EAAkCzD,EAAI8D,kBAAkB7E,eACxDyE,EAAuB1D,EAAI8D,kBAAkBlE,KAEjD5D,KAAK+E,oBAAsB,IAAIgD,UAC3BJ,EACA3H,KAAK4G,cACL5G,KAAKwG,gBACLxG,KAAK6E,OACLb,EAAIgE,qBACJP,GAEJ,IAAMQ,EAASL,OAAOC,OAAO,GAAI7H,KAAK2G,mBAAmB3D,OAAOjG,QAASiD,KAAK2G,mBAAmB3D,OAAOY,KACxG5D,KAAKiF,SAAW,IAAIiD,UAChBD,EACAjI,KAAK4G,cACL5G,KAAKwG,gBACLxG,KAAK6E,OACLb,EAAImE,cACJT,sOC/CG,+JAnDkB,gGAEG,kEAEC,0CAEN,2BAEqB,CAE5CU,KAAM,IACNC,IAAK,IACLC,IAAK,IACLC,MAAO,IACPC,KAAM,IACNC,KAAM,IACNC,IAAK,IACLC,MAAO,IACPC,MAAO,IACPC,KAAM,gCAIgB,SAACC,GACvB,OAAOA,EACFC,OACA/B,cACAgC,QAAQ/E,EAAKgF,oBAAqB,oCAGb,SAACH,GAC3B,OAAO7E,EAAKiF,iBAAiBJ,GACxBK,MAAMlF,EAAKmF,wBACXC,IAAI,SAAAC,GAAC,OAAIA,EAAEP,SACXQ,OAAO,SAAAD,GAAC,QAAMA,kCAGK,SAACE,GACzB,IACMC,EAAkB,GACpBC,EAAQF,EAAKG,OAFH,EAEoB,EAClC,GAAID,EAAQ,EACR,OAAOD,EAEX,KAAOC,KACHD,EAAMC,GAASF,EAAKI,OAAOF,EAPjB,GASd,OAAOD,iCAEkB,SAACI,GAAD,OAA6BA,EAAMC,KAAK,sPCI1D,+JArDkB,4JAEG,kEAEC,sGAEN,2BAEqB,CAE5CC,KAAM,IACNC,IAAK,IACLC,IAAK,IACLC,KAAM,IACNC,OAAQ,IACRC,MAAO,IACPC,KAAM,IACNC,MAAO,IACPC,KAAM,IACNC,MAAO,gCAIe,SAAC1B,GACvB,OAAOA,EACFC,OACA/B,cACAgC,QAAQ/E,EAAKgF,oBAAqB,oCAGb,SAACH,GAC3B,OAAO7E,EAAKiF,iBAAiBJ,GACxBK,MAAMlF,EAAKmF,wBACXC,IAAI,SAAAC,GAAC,OAAIA,EAAEP,SACXQ,OAAO,SAAAD,GAAC,QAAMA,kCAGK,SAACE,GACzB,IACMC,EAAkB,GACpBC,EAAQF,EAAKG,OAFH,EAEoB,EAClC,GAAID,EAAQ,EACR,OAAOD,EAEX,KAAOC,KACHD,EAAMC,GAASF,EAAKI,OAAOF,EAPjB,GASd,OAAOD,iCAGkB,SAACI,GAAD,OAA6BA,EAAMC,KAAK,gICvDzE,IAAAW,ySAAA/M,CAAAxB,EAAA,KAEAwO,EAAAxO,EAAA,KACAyO,EAAAzO,EAAA,uSAEakL,uBAiCT,SAAAA,EACIC,EACAuD,EACAlH,EACAF,EACAqD,EACAgE,EACArD,GACF,IAAAvD,EAAAjE,kGAAAkE,CAAAlE,KAAAoH,GAAAjD,EAAAnE,KAAA,oBAAAmE,EAAAnE,KAAA,8BAAAmE,EAAAnE,KAAA,mBAAAmE,EAAAnE,KAAA,oBAAAmE,EAAAnE,KAAA,8BAAAmE,EAAAnE,KAAA,gBAAAmE,EAAAnE,KAAA,aAVoC,MAUpCmE,EAAAnE,KAAA,UAWe,kBAAMiE,EAAK6G,QAX1B3G,EAAAnE,KAAA,aAakB,WAChB,IAAKiE,EAAK8G,WAAY,CAClB,IAAMC,EAAQP,EAAGQ,OAAOD,MAAM,CAAEjM,MAAO,CAACkF,EAAK2G,SAAU3G,EAAKP,WAAYwH,MAAO,UACzEC,EAAWlH,EAAK6G,MAAM1F,MAAM4F,GAClC/G,EAAK8G,WAAaN,EAAGK,MAAM,CAAEM,OAAQJ,EAAOK,QAASF,IAEzD,OAAOlH,EAAK8G,aAnBd5G,EAAAnE,KAAA,QAuBa,SAAC+F,GACZ,OAAO0E,EAAGa,KAAK,WACX,IAAMC,EAAkBtH,EAAKuH,mBAAmBzF,GAC1C0F,EAASxH,EAAKyH,aAAaC,eAAeJ,GAEhD,OADAA,EAAgBK,UACTH,MA5BbtH,EAAAnE,KAAA,aAgCkB,kBAAMiE,EAAKoD,sBAhC7BlD,EAAAnE,KAAA,qBAkC2B,SAAC+F,GAC1B,OAAO0E,EAAGa,KAAK,WACX,IAAMO,EAA2B9F,EAAUsD,IAAI,SAAAyC,GAAC,OAAI7H,EAAK4C,UAAUkF,qBAAqBD,KAClFE,EAASvB,EAAGuB,OAAO,CAACjG,EAAU4D,OAAQ1F,EAAK2G,SAAU3G,EAAKP,WAAY,SAkB5E,OAjBAmI,EAAyBI,QAAQ,SAACH,EAAGI,GACjCJ,EAAEG,QAAQ,SAAC3C,EAAW6C,QACkBC,IAAhCnI,EAAKoD,oBAAoBiC,GAEzB0C,EAAOK,IAAIpI,EAAKoD,oBAAoBiC,GAAI4C,EAAeC,EAAW,GAC3D7C,EAAEK,QACT1F,EAAKqI,0BAA0BhD,GAAG2C,QAAQ,SAACM,EAAMC,GACzCA,EAAYvI,EAAKP,UAEjB+I,QAAQC,KAAK,wCAAyCpD,GAG1D0C,EAAOK,IAAIE,EAAML,EAAeC,EAAWK,SAKpDR,EAAOW,eAvDpBxI,EAAAnE,KAAA,4BA2DkC,SAACwJ,GACjC,IAAIoD,EAAmB,GACjBC,EAA0B,SAACC,GAC7B,YAAoCV,IAAhCnI,EAAKoD,oBAAoByF,KAG7BF,EAAOG,KAAK9I,EAAKoD,oBAAoByF,KAC9B,IAGX,GAAItD,EAAKG,OAAS,EAAG,CACjB,IAAIqD,GAAiB,EAOrB,GANmB/I,EAAK4C,UAAUoG,mBAAmBzD,GAC1CyC,QAAQ,SAAAiB,IACVL,EAAwBK,IAAOF,IAChCA,GAAiB,KAGrBA,EACA,OAAOJ,EAOf,OAHAA,EAAS,GAETpD,EAAKL,MAAM,IAAI8C,QAAQY,GAChBD,IApFP5M,KAAKqH,oBAAsBA,EAC3BrH,KAAK4K,SAAWA,EAChB5K,KAAK0D,UAAYA,EACjB1D,KAAKwD,oBAAsBA,EAC3BxD,KAAK8K,MAAQD,GAEPzD,EAAgB+F,WAAW3F,GAA0B,IAAI4F,IAAOpN,KAAK4K,SAAU5K,KAAK0D,UAAW1D,KAAKwD,qBAC1GxD,KAAK6G,UAAYA,iDA/CjBW,EACAoD,EACAlH,EACAF,GAEA,IAAMsH,EAAQL,EAAG4C,aACXC,EAAa7C,EAAGQ,OAAOsC,UAAU,CACnCC,sBAAuB,IAAIC,gCAA8B,CACrDjK,sBACAgE,2BAEJkG,SAAUlG,EAAuBmG,KACjCC,YAAa,CAAClK,GACdmK,UAAU,EACVC,UAAWtK,EACXuK,WAAW,IAIf,OAFAjD,EAAMkD,IAAIvD,EAAGQ,OAAOgD,gBAAgB,CAAEC,MAAOZ,EAAYa,WAAY,CAACvD,EAAUlH,MAChFoH,EAAMkD,IAAI,IAAII,qBAAmB,KAC1BtD,kLC1Bf,IAAAL,ySAAA/M,CAAAxB,EAAA,KACAmS,EAAAnS,EAAA,o2BAIakS,sVAEUA,EAAmBxN,mQAFF6J,EAAGQ,OAAOqD,wDAIpBH,GACtB,MAAO,CAACA,EAAW,GAAIA,EAAW,GAAIA,EAAWA,EAAWxE,OAAS,iCAE7DyB,EAAmBmD,GAAa,IAAAC,EAAAxO,KACxC,OAAOyK,EAAGa,KAAK,WACXkD,EAAKC,eAAerD,EAAQmD,GAC5B,IAAMG,EAAWjE,EAAGkE,IAAIvD,EAAQ,GAC1BK,GAAS,EAAA4C,EAAAO,aAAYF,EAAU,GAErC,OADAA,EAAS9C,UACFH,kEAbN2C,cACiB,sBAiB9B3D,EAAGoE,cAAcC,iBAAiBC,SAASX,6HCvB3C,IAAA3D,EAAA/M,EAAAxB,EAAA,KACA8S,EAAAtR,EAAAxB,EAAA,MACA+S,EAAA/S,EAAA,k+CAOauR,cAIT,SAAAA,EAAYzK,GAAgC,IAAAiB,MAAA,mGAAAC,CAAAlE,KAAAyN,KACxCzN,KAAAiE,MAAAiL,EAAAzB,GAAA0B,KAAAnP,qDADwCmE,EAAAiL,IAAAnL,IAAA,iBAAAE,EAAAiL,IAAAnL,IAAA,YADzBwJ,EAA8B7M,WAG7CqD,EAAKjB,OAASA,EAF0BiB,wPAJG+K,EAAaK,iDAQ/CtQ,EAAiBmM,GAA+B,IAAAsD,EAAAxO,KACzD,OAAKA,KAAKgD,QAAWhD,KAAKgD,OAAOwE,uBAG1BiD,EAAGa,KAAK,WACX,IAAMgE,GAAU,EAAAL,EAAAM,aAAAC,EAAgBhB,EAAKxL,OAAOwE,uBAAuBiI,WACnE,OAAOhF,EAAGiF,SAASJ,EAAS,CAACd,EAAKxL,OAAOwE,uBAAuBmG,KAAMa,EAAKxL,OAAOQ,qBAAsB,aAJjGiH,EAAGkF,MAAM5Q,EAAOmM,uCAS3B,OAAOlL,KAAKgD,OAAOwE,gGAnBdiG,cACiB,iCAqB9BhD,EAAGoE,cAAcC,iBAAiBC,SAAStB,uGC/B3C,IAAAhD,EAAA/M,EAAAxB,EAAA,KACA+S,EAAA/S,EAAA,KACA0T,EAAAlS,EAAAxB,EAAA,01DAGqB6L,wBA8FjB,SAAAA,EACI/E,EACA4D,EACAJ,EACA3B,EACAgL,EACApI,GACF,IAAAxD,MAAA,mGAAAC,CAAAlE,KAAA+H,KACE/H,OAAAkP,EAAAnH,GAAAoH,KAAAnP,MAAAiE,mDADFE,EAAAiL,IAAAnL,IAAA,iBAAAE,EAAAiL,IAAAnL,IAAA,wBAAAE,EAAAiL,IAAAnL,IAAA,gBAAAE,EAAAiL,IAAAnL,IAAA,0BAAAE,EAAAiL,IAAAnL,IAAA,iBAAAE,EAAAiL,IAAAnL,IAAA,0CAAAE,EAAAiL,IAAAnL,IAAA,UAUe,kBAAMA,EAAK6G,QAV1B3G,EAAAiL,IAAAnL,IAAA,UAYe,SAAC8B,GACd,IAAM+J,EAAa,GAsBnB,OArBArF,EAAGa,KAAK,WACJ,IAAMyE,EAAoB9L,EAAKuC,gBAAgBwJ,MAAMjK,GAC/C0F,EAASxH,EAAK6G,MAAM9E,QAAQ+J,GAC5BE,EAAIxE,EAAOyE,WACjBzE,EAAOG,UACPmE,EAAkBnE,UAClB,IAAMuE,EAAUlM,EAAK2C,cAAcuJ,QACnCpK,EAAUkG,QAAQ,SAACH,EAAGsE,GAClB,IAAMC,EAAQJ,EAAEK,MAAMF,EAAID,EAAQxG,OAAQyG,EAAID,EAAQxG,OAASwG,EAAQxG,QACjE4G,EAA6C,GACnDF,EAAMpE,QAAQ,SAACuE,EAAGC,GAAJ,OACVF,EAAcxD,KAAK,CACf2D,WAAYF,EACZG,OAAQR,EAAQM,GAChB3H,SAAUgD,MAGlByE,EAAcK,KAAK,SAACC,EAAQC,GAAT,OAAqBD,EAAEH,WAAaI,EAAEJ,YAAc,EAAI,IAC3EZ,EAAW/C,KAAKwD,EAAc,QAG/BT,IAnCT3L,EAAAiL,IAAAnL,IAAA,uBAAAqB,EAAAlB,EAAAC,mBAAAC,KAsCa,SAAAC,EAAOC,GAAP,IAAAuM,EAAAC,EAAArT,EAAAsT,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA7H,EAAA8H,EAAAzB,EAAA0B,EAAAC,EAAAC,EAAAC,EAAA,OAAAvN,mBAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,OACLmM,GAAe,EAAA9B,EAAA4C,OAAMrN,EAAasN,OAAQ7N,EAAKjB,OAAOM,WACtD0N,GAAe,EAAA/B,EAAA4C,OAAMrN,EAAauN,OAAQ9N,EAAKjB,OAAOM,WAC5DW,EAAKY,OAAOC,IAAI,wCACVnH,EAAIsG,EAAK6G,MACXmG,GAAwB,EALjBC,GAAA,EAAAC,GAAA,EAAAC,OAAAhF,EAAA1H,EAAAC,KAAA,EAAA0M,EAMmBL,EAAagB,UANhCC,OAAAC,YAAA,WAAAhB,GAAAI,EAAAD,EAAAzM,QAAAuN,KAAA,CAAAzN,EAAAE,KAAA,YAAA2M,EAAAa,EAAAd,EAAAe,MAAA,GAMC3I,EAND6H,EAAA,GAMQC,EANRD,EAAA,IAOHN,EAPG,CAAAvM,EAAAE,KAAA,gBAAAF,EAAAmB,OAAA,yBAUDkK,EAAoB9L,EAAKuC,gBAAgBwJ,MAAMwB,GAC/CC,EAAahH,EAAG6H,SAASvB,EAAarH,GAAQ,SAC9CgI,EAAmBjH,EAAG8H,OAAOd,EAAYxN,EAAK2C,cAAcuJ,QAAQxG,QAZnEjF,EAAAE,KAAA,GAaDjH,EAAE6U,IAAIzC,EAAmB2B,EAAkB,CAE7Ce,UAAW,CAAEC,WAAYjI,EAAGkI,WAC5BzP,OAAQe,EAAKjB,OAAOE,OACpB0P,SAAS,EACTC,gBAAiB5O,EAAKjB,OAAOW,0BAlB1B,QAoBP8N,EAAW7F,UACXmE,EAAkBnE,UAClB8F,EAAiB9F,UACX+F,EAAIhU,EAAEmV,QAAQA,QACdlB,EAAID,EAAEoB,SAASpJ,OAAS,EAC1B1F,EAAKwD,iCACLxD,EAAKwD,gCAAgC,CACjCuL,MAAOtJ,EAAQ,EACfuJ,YAAatV,EAAEmV,QAAQI,MAAMvJ,OAC7BwJ,iBAAkBnC,EAAatH,GAAOC,OACtCyJ,gBAAiB3I,EAAG4I,SAASC,WAC7BC,aAAcvC,EAAarH,OAC3B6J,iBAAkB7B,EAAE8B,IAAI7B,GACxB8B,aAAc/B,EAAEgC,KAAK/B,GACrBgC,mBAAoBjC,EAAEkC,QAAQjC,GAC9BkC,eAAgBnC,EAAEoB,SAASnB,KAGnC3N,EAAKY,OAAOC,IAAZ,WAAAiP,OAA2BpW,EAAEmV,QAAQI,MAAMvJ,OAA3C,qBAAAoK,OAAqErK,EAAQ,EAA7E,QAAAqK,OAAqF/C,EAAarH,SAClG1F,EAAKY,OAAOC,IAAZ,kBAAAiP,OAAkCpC,EAAEgC,KAAK/B,GAAzC,0BAAAmC,OAAoEpC,EAAE8B,IAAI7B,KAC1E3N,EAAKY,OAAOC,IAAZ,oBAAAiP,OAAoCpC,EAAEoB,SAASnB,GAA/C,4BAAAmC,OAA4EpC,EAAEkC,QAAQjC,KACtF3N,EAAKY,OAAO6H,KAAZ,6DAAAqH,OAA8EtJ,EAAG4I,SAASC,aAC1FrP,EAAKY,OAAOC,IAAI,sGAEZb,EAAKjB,OAAOS,6BACZkO,EAAEgC,KAAK/B,GAAK3N,EAAKjB,OAAOS,6BACxBkO,EAAEoB,SAASnB,GAAK3N,EAAKjB,OAAOS,8BAE5BwN,GAAwB,EACxBhN,EAAKY,OAAO6H,KAAZ,wDAAAqH,OAAyErK,EAAQ,EAAjF,QAAAqK,OAAyF/C,EAAarH,SACtG1F,EAAKY,OAAOC,IAAI,uGAlDb,QAAAoM,GAAA,EAAAxM,EAAAE,KAAA,iBAAAF,EAAAE,KAAA,iBAAAF,EAAAC,KAAA,GAAAD,EAAAsP,GAAAtP,EAAA,SAAAyM,GAAA,EAAAC,EAAA1M,EAAAsP,GAAA,QAAAtP,EAAAC,KAAA,GAAAD,EAAAC,KAAA,GAAAuM,GAAA,MAAAG,EAAA4C,QAAA5C,EAAA4C,SAAA,WAAAvP,EAAAC,KAAA,IAAAwM,EAAA,CAAAzM,EAAAE,KAAA,eAAAwM,EAAA,eAAA1M,EAAAwP,OAAA,mBAAAxP,EAAAwP,OAAA,6BAAAxP,EAAAQ,SAAAX,EAAAvE,KAAA,+BAtCb,gBAAAmF,GAAA,OAAAG,EAAAF,MAAApF,KAAAqF,YAAA,IAAAlB,EAAAiL,IAAAnL,IAAA,sBAAAgC,EAAA7B,EAAAC,mBAAAC,KA6FY,SAAAiB,EACV4O,EACAC,GAFU,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA1E,EAAArK,EAAAgP,EAAA,OAAA1Q,mBAAAI,KAAA,SAAAkB,GAAA,cAAAA,EAAAhB,KAAAgB,EAAAf,MAAA,OAQV,IAJMyP,EAAUD,GAAkCnQ,EAAK+Q,qBACjDV,EAAgC,CAAEW,QAAS,EAAGC,MAAO,EAAGC,cAAe,GACvEZ,GAAI,EAAAtF,EAAA4C,OAAMsC,EAAaiB,MAAOnR,EAAKjB,OAAOM,WAC1CkR,GAAI,EAAAvF,EAAA4C,OAAMsC,EAAakB,MAAOpR,EAAKjB,OAAOM,WAPtCmR,GAAA,EAAAC,GAAA,EAAAC,OAAAvI,EAAAzG,EAAAhB,KAAA,EAQViQ,EAA6BL,EAAEvC,UAA/BC,OAAAC,cAAAuC,GAAAI,EAAAD,EAAAhQ,QAAAuN,MAAAsC,GAAA,EAA0CK,EAAA1C,EAAAyC,EAAAxC,MAAA,GAA9BjC,EAA8B0E,EAAA,GAA3B/O,EAA2B+O,EAAA,GAChCC,EAAc9Q,EAAK+B,QAAQD,GACjCsO,EAAQtO,EAAWyO,EAAEpE,GAAI2E,EAAaT,GAVhC3O,EAAAf,KAAA,iBAAAe,EAAAhB,KAAA,GAAAgB,EAAAqO,GAAArO,EAAA,SAAA+O,GAAA,EAAAC,EAAAhP,EAAAqO,GAAA,QAAArO,EAAAhB,KAAA,GAAAgB,EAAAhB,KAAA,GAAA8P,GAAA,MAAAG,EAAAX,QAAAW,EAAAX,SAAA,WAAAtO,EAAAhB,KAAA,IAAA+P,EAAA,CAAA/O,EAAAf,KAAA,eAAA+P,EAAA,eAAAhP,EAAAuO,OAAA,mBAAAvO,EAAAuO,OAAA,mBAAAvO,EAAAE,OAAA,SAYHyO,GAZG,yBAAA3O,EAAAT,SAAAK,EAAAvF,KAAA,+BA7FZ,gBAAA8F,EAAAY,GAAA,OAAAT,EAAAb,MAAApF,KAAAqF,YAAA,IAAAlB,EAAAiL,IAAAnL,IAAA,uBA4G6B,SAC3BsQ,EACAC,EACAc,EACAhB,GAmBA,OAjBAC,EAAEtI,QAAQ,SAACH,EAAGsE,GACV,IAAMO,EAAS1M,EAAK2C,cAAcuJ,QAAQqE,EAAEpE,IACtC6E,EAAUK,EAAElF,GAAGO,SAAWA,EAChC,GAAI2E,EAAElF,GAAGM,WAAazM,EAAKjB,OAAOI,uBAAwB,CACtD,QAA4BgJ,IAAxBkI,EAAMa,cACN,OAEJb,EAAMa,gBACNlR,EAAKY,OAAO6H,KAAZ,2BAAAqH,OAA4CuB,EAAElF,GAAGO,OAAjD,kBAAAoD,OAAwEuB,EAAElF,GAAGM,WAA7E,QAAAqD,OAA8FjI,SACvFmJ,GACPX,EAAMW,UACNhR,EAAKY,OAAO0Q,MAAZ,oBAAAxB,OAAsCuB,EAAElF,GAAGO,OAA3C,kBAAAoD,OAAkEuB,EAAElF,GAAGM,WAAvE,QAAAqD,OAAwFjI,MAExFwI,EAAMY,QACNjR,EAAKY,OAAO2Q,MAAZ,kBAAAzB,OAAoCuB,EAAElF,GAAGO,OAAzC,kBAAAoD,OAAgEuB,EAAElF,GAAGM,WAArE,QAAAqD,OAAsFjI,OAGvFwI,IAjIPrQ,EAAKjB,OAASA,EACdiB,EAAK2C,cAAgBA,EACrB3C,EAAKuC,gBAAkBA,EACvBvC,EAAK6G,MAAQ+E,GAAoC9H,EAAoB0N,MAAMxR,EAAKjB,OAAQiB,EAAK2C,eAC7F3C,EAAKY,OAASA,EACdZ,EAAKwD,gCAAkCA,EAPzCxD,8OArG2C2L,EAAM8F,kDAE/C1S,KAEF,IADyB4H,EACzBxM,EADIkJ,oBAEIqO,EADRvX,EADmC+R,QAENxG,OAIrBiM,EAAYnL,EAAGzF,MAAM6Q,KAHL,MACF,MACA,IAGd7K,EAAQP,EAAGO,MAAM,CACnBE,MAAO,UAAWnM,MAAO,CAAC6L,EAAU5H,EAAOQ,qBAAsBrG,KAAM,mBAErE2Y,EAAarL,EAAGQ,OACjB8K,OAAO,CACJC,WAAY,OACZC,QAASjT,EAAOK,WAChB8K,WAAY,CAACvD,EAAU5H,EAAOQ,qBAC9B0S,kBAAmB,eACnBC,WAAY,CAACnT,EAAOG,YAAY,IAChChG,KAAM,aACNmD,QAAS,UAEZ8E,MAAM4F,GACLoL,EAAW3L,EAAGQ,OACfoL,aAAa,CACV/V,QAAS,QACTgW,SAAU1L,EAAW5H,EAAOG,YAAY,GAAK,IAEhDiC,MAAM0Q,GAELS,EAAa9L,EAAGQ,OACjB8K,OAAO,CACJC,WAAY,OACZC,QAASjT,EAAOK,WAChB8K,WAAY,CAACvD,EAAU5H,EAAOQ,qBAC9B0S,kBAAmB,eACnBC,WAAY,CAACnT,EAAOG,YAAY,IAChChG,KAAM,aACNmD,QAAS,UAEZ8E,MAAM4F,GACLwL,EAAW/L,EAAGQ,OACfoL,aAAa,CACV/V,QAAS,QACTgW,SAAU1L,EAAW5H,EAAOG,YAAY,GAAK,IAEhDiC,MAAMmR,GAELE,EAAahM,EAAGQ,OACjB8K,OAAO,CACJC,WAAY,OACZC,QAASjT,EAAOK,WAChB8K,WAAY,CAACvD,EAAU5H,EAAOQ,qBAC9B0S,kBAAmB,eACnBC,WAAY,CAACnT,EAAOG,YAAY,IAChChG,KAAM,aACNmD,QAAS,UAEZ8E,MAAM4F,GACL0L,EAAWjM,EAAGQ,OACfoL,aAAa,CACV/V,QAAS,QACTgW,SAAU1L,EAAW5H,EAAOG,YAAY,GAAK,IAEhDiC,MAAMqR,GAELE,EAAclM,EAAGQ,OAAO2L,YAAY,CAAEC,KAAM,IAAKzR,MAAM,CAACgR,EAAUI,EAAUE,IAC5EI,EAAOrM,EAAGQ,OAAO8L,UAAU3R,MAAMuR,GACjCK,EAAUvM,EAAGQ,OAAOgM,QAAQ,CAAEC,KAAMlU,EAAOO,OAAQ6B,MAAM0R,GACzDK,EAAY1M,EAAGQ,OAAO8L,UAAU3R,MAAMgR,GACtCgB,EAA0B3M,EAAGQ,OAAO2L,YAAY,CAAEC,KAAM,IAAKzR,MAAM,CAAC4R,EAASG,IAC7EE,EAAoB5M,EAAGQ,OACxBqM,MAAM,CACHtB,WAAY,UACZuB,MAAO5B,IAEVvQ,MAAMgS,GACLtM,EAAQL,EAAGK,MAAM,CAAEM,OAAQJ,EAAOK,QAASgM,IAMjD,OALAvM,EAAM0M,QAAQ,CACV7D,KAAM,0BACN8D,QAAS,CAAC,YACV7B,cAEG9K,+JC1Ff,IAAAL,EAAA/M,EAAAxB,EAAA,KACA+S,EAAA/S,EAAA,KACA0T,EAAAlS,EAAAxB,EAAA,MAEAwb,EAAAxb,EAAA,y1DAEqBgM,wBAmEjB,SAAAA,EACIlF,EACA4D,EACAJ,EACA3B,EACAgL,EACAnI,GACF,IAAAzD,MAAA,mGAAAC,CAAAlE,KAAAkI,KACElI,OAAAkP,EAAAhH,GAAAiH,KAAAnP,MAAAiE,mDADFE,EAAAiL,IAAAnL,IAAA,iBAAAE,EAAAiL,IAAAnL,IAAA,wBAAAE,EAAAiL,IAAAnL,IAAA,gBAAAE,EAAAiL,IAAAnL,IAAA,0BAAAE,EAAAiL,IAAAnL,IAAA,iBAAAE,EAAAiL,IAAAnL,IAAA,+BAAAE,EAAAiL,IAAAnL,IAAA,UAUe,kBAAMA,EAAK6G,QAV1B3G,EAAAiL,IAAAnL,IAAA,gBAYqB,SAAC8B,EAAqB4R,GACzC,OAAOlN,EAAGa,KAAK,WAAM,IAAAsM,EACoC3T,EAAK2C,cAA7BgE,EADZgN,EACTtQ,oBAA+BuQ,EADtBD,EACsBC,UACjCC,EAAkBlQ,OAAOmQ,KAAKF,GAAWlO,OACzCoG,EAAoB9L,EAAKuC,gBAAgBwJ,MAAMjK,GAC/CiS,EAAgBL,EAAmBtO,IAAI,SAAAmH,GACzC,IAAMyH,EAAgB,IAAIC,MAAMjU,EAAK2C,cAAcuJ,QAAQxG,QAAQwO,KAAK,GAClE1H,EAAMxM,EAAK2C,cAAcuJ,QAAQiI,QAAQ5H,EAAEG,QAIjD,OAHa,IAATF,IACAwH,EAAcxH,GAAO,GAElBwH,IAELI,GAAc,EAAApJ,EAAAM,aAAYyI,GAC1BM,EAAa7N,EAAGiF,SAAS2I,EAAa,CAACL,EAAcrO,OAAQ1F,EAAK2C,cAAcuJ,QAAQxG,SACxF8B,EAASxH,EAAK6G,MAAM9E,QAAQ,CAACsS,EAAYvI,IACzCwI,EAAuB9M,EAAOyE,WAMpC,OALAzE,EAAOG,UACP0M,EAAW1M,UACXmE,EAAkBnE,WAEH,EAAAqD,EAAA4C,OAAM0G,EAAsB3N,EAAWkN,GAAiBzO,IAAI,SAAAmP,GAAE,OAAI,EAAAvJ,EAAA4C,OAAM2G,EAAIV,KAC7EzO,IAAI,SAAAkH,GACd,OAAOA,EAAclH,IAAI,SAAAoP,GACrB,IAAIC,EAAe,EACfhI,EAAa+H,EAAmB9O,OAAS8O,EAAmBC,GAAgB,EAOhF,OANAD,EAAmBxM,QAAQ,SAAC0M,EAAIC,GACxBH,EAAmBC,GAAgBC,IACnCD,EAAeE,EACflI,EAAaiI,KAGd,CAAED,eAAchI,sBA5CrCvM,EAAAiL,IAAAnL,IAAA,UAkDe,SAAC8B,EAAqB4R,GAAoD,IAC/EvU,EAA2Ba,EAAKjB,OAAhCI,uBACAyU,EAAc5T,EAAK2C,cAAnBiR,UACFgB,EAAuB5U,EAAK6U,cAAc/S,EAAW4R,GAC3D,OAAO5R,EAAUsD,IAAI,SAACyC,EAAGsE,GACrB,IAAM2I,EAA4BF,EAAqBzI,GACjD4I,EAAgB/U,EAAKuC,gBAAgBK,UAAUkF,qBAAqBD,GAC1E,OAAOkN,EAAcC,OACjB,SAACC,EAAiC5P,EAAW6P,GACrCD,EAAYE,SAA8C,IAAnCF,EAAYE,QAAQ1I,aAC3CwI,EAAYE,QAAQ1I,WAAaqI,EAA0BI,GAAczI,YAE7E,IAAM2I,EAAiBzR,OAAOmQ,KAAKF,GAAWyB,KAC1C,SAAAC,GAAO,OACHR,EAA0BI,IAC1BtB,EAAU0B,KAAaR,EAA0BI,GAAcT,eAEvE,OAAKW,GAAmBH,EAAYE,SAGhCF,EAAYE,QAAQpc,MAAQqc,GAExBH,EAAYE,QAAQpc,KACQ,MAA5Bkc,EAAYE,QAAQpc,KACpBkc,EAAYE,QAAQ1I,YAActN,IAE7B8V,EAAYM,MAAMN,EAAYE,QAAQpc,OACvCkc,EAAYM,MAAMN,EAAYE,QAAQpc,KAAO,IAEjDkc,EAAYM,MAAMN,EAAYE,QAAQpc,KAAK+P,KAAK,CAC5C2D,WAAYwI,EAAYE,QAAQ1I,WAChC2B,MAAO6G,EAAYE,QAAQ/G,SAGnC6G,EAAYE,QAAU,CAClB1I,WAAYqI,EAA0BI,GAAczI,WACpD1T,IAAKqc,EACLhH,MAAO/I,KAIX4P,EAAYE,QAAQ/G,OAApB,IAAA0B,OAAiCzK,GACjC4P,EAAYE,QAAQ1I,YACfqI,EAA0BI,GAAczI,WAAawI,EAAYE,QAAQ1I,YAAc,GAE5FyI,EAAe,IAAMH,EAAcrP,QACH,MAA5BuP,EAAYE,QAAQpc,KAAekc,EAAYE,QAAQ1I,YAActN,IAChE8V,EAAYM,MAAMN,EAAYE,QAAQpc,OACvCkc,EAAYM,MAAMN,EAAYE,QAAQpc,KAAO,IAEjDkc,EAAYM,MAAMN,EAAYE,QAAQpc,KAAK+P,KAAK,CAC5C2D,WAAYwI,EAAYE,QAAQ1I,WAChC2B,MAAO6G,EAAYE,QAAQ/G,SAG5B,CAAEvJ,SAAUgD,EAAG0N,MAAON,EAAYM,QAEtCN,GAvCIA,GAyCf,CAAEE,QAAS,CAAEpc,IAAK,GAAIqV,MAAO,GAAI3B,WAAY,GAAK8I,MAAO,GAAI1Q,SAAU,SA7GjF3E,EAAAiL,IAAAnL,IAAA,uBAAA7F,EAAAgG,EAAAC,mBAAAC,KAkHa,SAAAC,EAAOC,GAAP,IAAAiV,EAAA1I,EAAAC,EAAA0I,EAAAxW,EAAA2P,EAAA8G,EAAA1I,EAAAC,EAAAC,EAAAC,EAAAwI,EAAAvI,EAAAC,EAAAuI,EAAA,OAAAxV,mBAAAI,KAAA,SAAAkB,GAAA,cAAAA,EAAAhB,KAAAgB,EAAAf,MAAA,OACL6U,GAAgB,EAAAxK,EAAA4C,OAAMrN,EAAasV,QAAS7V,EAAKjB,OAAOM,WACxDyN,GAAe,EAAA9B,EAAA4C,OAAMrN,EAAasN,OAAQ7N,EAAKjB,OAAOM,WACtD0N,GAAe,EAAA/B,EAAA4C,OAAMrN,EAAauN,OAAQ9N,EAAKjB,OAAOM,WAHjDoW,EAIkDzV,EAAKjB,OAA1DE,EAJGwW,EAIHxW,OAAiC2P,EAJ9B6G,EAIK/V,wBACVgW,EAAc/R,OAAOmQ,KAAK9T,EAAK2C,cAAciR,WAAWlO,OAC9D1F,EAAKY,OAAOC,IAAI,6BACZmM,GAAwB,EAPjBC,GAAA,EAAAC,GAAA,EAAAC,OAAAhF,EAAAzG,EAAAhB,KAAA,GAAAiV,EAAAvV,mBAAAC,KAAA,SAAAsV,IAAA,IAAArI,EAAA7H,EAAA8H,EAAAuI,EAAAC,EAAAC,EAAAtI,EAAAC,EAAAsB,EAAA,OAAA7O,mBAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,UAAA2M,EAAAa,EAAAd,EAAAe,MAAA,GAQC3I,EARD6H,EAAA,GAQQC,EARRD,EAAA,IASHN,EATG,CAAAvM,EAAAE,KAAA,eAAAF,EAAAmB,OAAA,UAAAqU,OAAA,kBAaDH,EAAetP,EAAGa,KAAK,kBACzBb,EAAG8H,OAAO9H,EAAG6H,SAASvB,EAAarH,GAAQ,SAAUzF,EAAK2C,cAAcuJ,QAAQxG,QAAQwQ,OAAO,aAE7FH,EAAwB/V,EAAKuC,gBAAgBwJ,MAAMwB,GAGnDyI,EAAwBxP,EAAGa,KAAK,WAClC,IAAM8O,EAA6B,GADK3F,GAAA,EAAAC,GAAA,EAAAC,OAAAvI,EAAA,IAExC,QAAAyI,EAAAD,EAA0B6E,EAAc/P,GAAxCuI,OAAAC,cAAAuC,GAAAI,EAAAD,EAAAhQ,QAAAuN,MAAAsC,GAAA,EAAgD,KAArC4F,EAAqCxF,EAAAxC,MACtCiI,EAAU7P,EACX6H,SAAS+H,EAAa,SACtBE,IAAI,CAAC,CAAC,EAAGtW,EAAK2C,cAAcU,oBAAsB+S,EAAY1Q,UAC7D6Q,EAAM/P,EAAG8H,OAAO+H,EAASX,GAAaQ,OAAO,WACnDG,EAAQ1O,UACRwO,EAAYrN,KAAKyN,IARmB,MAAAC,GAAA/F,GAAA,EAAAC,EAAA8F,EAAA,YAAAhG,GAAA,MAAAG,EAAAX,QAAAW,EAAAX,SAAA,WAAAS,EAAA,MAAAC,GAUxC,IAAM+F,EAAQjQ,EAAGiQ,MAAMN,GAEvB,OADAA,EAAYnO,QAAQ,SAAAH,GAAC,OAAIA,EAAEF,YACpB8O,IA/BJhW,EAAAE,KAAA,EAiCDX,EAAK6G,MAAM0H,IAAI,CAACuH,EAAcC,GAAwBC,EAAU,CAElExH,UAAW,CAAEC,WAAYjI,EAAGkI,WAC5BzP,SACA0P,SAAS,EACTC,oBAtCG,cAwCPkH,EAAanO,UACboO,EAAsBpO,UAzCflH,EAAAE,KAAA,GA0CD6F,EAAGkI,YA1CF,QA2CDhB,EAAI1N,EAAK6G,MAAMgI,QAAQA,QACvBlB,EAAID,EAAEoB,SAASpJ,OAAS,EACxBuJ,EAAQjP,EAAK6G,MAAMgI,QAAQI,MAC7BjP,EAAKyD,sBACLzD,EAAKyD,qBAAqB,CACtBsL,MAAOtJ,EAAQ,EACfuJ,YAAaC,EAAMvJ,OACnBwJ,iBAAkBnC,EAAatH,GAAOC,OACtCyJ,gBAAiB3I,EAAG4I,SAASC,WAC7BC,aAAcvC,EAAarH,OAC3B6J,iBAAkB7B,EAAE8B,IAAI7B,GACxB8B,aAAc/B,EAAEgC,KAAK/B,GACrBgC,mBAAoBjC,EAAEkC,QAAQjC,GAC9BkC,eAAgBnC,EAAEoB,SAASnB,KAGnC3N,EAAKY,OAAOC,IAAZ,WAAAiP,OAA2Bb,EAAMvJ,OAAjC,qBAAAoK,OAA2DrK,EAAQ,EAAnE,QAAAqK,OAA2E/C,EAAarH,SACxF1F,EAAKY,OAAOC,IAAZ,kBAAAiP,OAAkCpC,EAAEgC,KAAK/B,GAAzC,0BAAAmC,OAAoEpC,EAAE8B,IAAI7B,KAC1E3N,EAAKY,OAAOC,IAAZ,oBAAAiP,OAAoCpC,EAAEoB,SAASnB,GAA/C,4BAAAmC,OAA4EpC,EAAEkC,QAAQjC,KACtF3N,EAAKY,OAAO6H,KAAZ,6DAAAqH,OAA8EtJ,EAAG4I,SAASC,aAC1FrP,EAAKY,OAAOC,IAAI,sGAChBmV,EAASrO,UAEL3H,EAAKjB,OAAOS,6BACZkO,EAAEgC,KAAK/B,GAAK3N,EAAKjB,OAAOS,6BACxBkO,EAAEoB,SAASnB,GAAK3N,EAAKjB,OAAOS,8BAE5BwN,GAAwB,EACxBhN,EAAKY,OAAO6H,KAAZ,wDAAAqH,OAAyErK,EAAQ,EAAjF,QAAAqK,OAAyF/C,EAAarH,SACtG1F,EAAKY,OAAOC,IAAI,uGAxEb,yBAAAJ,EAAAQ,SAAA0U,EAAA5Z,QAAAqR,EAQmBL,EAAagB,UARhCC,OAAAC,YAAA,WAAAhB,GAAAI,EAAAD,EAAAzM,QAAAuN,KAAA,CAAAxM,EAAAf,KAAA,gBAAAe,EAAAgV,cAAAf,IAAA,+BAAAgB,EAAAf,EAAAlU,EAAAqO,IAAA,CAAArO,EAAAf,KAAA,gBAAAe,EAAAE,OAAA,SAAAgU,EAAAK,GAAA,QAAAhJ,GAAA,EAAAvL,EAAAf,KAAA,iBAAAe,EAAAf,KAAA,iBAAAe,EAAAhB,KAAA,GAAAgB,EAAAkV,GAAAlV,EAAA,UAAAwL,GAAA,EAAAC,EAAAzL,EAAAkV,GAAA,QAAAlV,EAAAhB,KAAA,GAAAgB,EAAAhB,KAAA,GAAAuM,GAAA,MAAAG,EAAA4C,QAAA5C,EAAA4C,SAAA,WAAAtO,EAAAhB,KAAA,IAAAwM,EAAA,CAAAxL,EAAAf,KAAA,eAAAwM,EAAA,eAAAzL,EAAAuO,OAAA,mBAAAvO,EAAAuO,OAAA,6BAAAvO,EAAAT,SAAAX,EAAAvE,KAAA,gCAlHb,gBAAAmF,GAAA,OAAA/G,EAAAgH,MAAApF,KAAAqF,YAAA,IAAAlB,EAAAiL,IAAAnL,IAAA,sBAAAqB,EAAAlB,EAAAC,mBAAAC,KA+LY,SAAAiB,EACV4O,EACAC,GAFU,IAAAC,EAAAC,EAAAhR,EAAA8R,EAAAC,EAAAyF,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA,OAAA/W,mBAAAI,KAAA,SAAA4W,GAAA,cAAAA,EAAA1W,KAAA0W,EAAAzW,MAAA,OAIJyP,EAAUD,GAAkCnQ,EAAK+Q,qBACjDV,EAAgC,CAAEW,QAAS,EAAGC,MAAO,GACrD5R,EAAYW,EAAKjB,OAAOM,UACxB8R,GAAQ,EAAAnG,EAAA4C,OAAMsC,EAAaiB,MAAO9R,GAClC+R,GAAQ,EAAApG,EAAA4C,OAAMsC,EAAakB,MAAO/R,GAClCwX,GAAS,EAAA7L,EAAA4C,OAAMsC,EAAa2G,OAAQxX,GAThCyX,GAAA,EAAAC,GAAA,EAAAC,OAAA7O,EAAAiP,EAAA1W,KAAA,EAAAuW,EAAA7W,mBAAAC,KAAA,SAAA4W,IAAA,IAAAI,EAAAlL,EAAArK,EAAAwV,EAAAvD,EAAAjD,EAAA,OAAA1Q,mBAAAI,KAAA,SAAA0B,GAAA,cAAAA,EAAAxB,KAAAwB,EAAAvB,MAAA,cAAA0W,EAAAlJ,EAAAgJ,EAAA/I,MAAA,GAUEjC,EAVFkL,EAAA,GAUKvV,EAVLuV,EAAA,GAWAC,EAAkBlG,EAAMjF,GACxB4H,EAAgBjS,EAAUsD,IAC5B,SAACmH,EAAGC,GAAJ,MACK,CACGC,WAAY,EACZC,OAAQ1M,EAAK2C,cAAcuJ,QAAQoL,EAAgB9K,IACnD3H,SAAU0H,KAGhBuE,EAAc9Q,EAAK6U,cAAc/S,EAAWiS,GAAe3O,IAAI,SAAAP,GAAQ,OAAIA,EAASO,IAAI,SAAAyC,GAAC,OAAIA,EAAE4M,iBACrGrE,EAAQtO,EAAW+U,EAAO1K,GAAI2E,EAAaT,GArBrCnO,EAAAvB,KAAA,EAsBA6F,EAAGkI,YAtBH,wBAAAxM,EAAAjB,SAAAgW,EAAAlb,QAAAmb,EAUmB/F,EAAMpD,UAVzBC,OAAAC,YAAA,WAAA6I,GAAAK,EAAAD,EAAAvW,QAAAuN,KAAA,CAAAkJ,EAAAzW,KAAA,gBAAAyW,EAAAV,cAAAO,IAAA,iBAAAH,GAAA,EAAAM,EAAAzW,KAAA,iBAAAyW,EAAAzW,KAAA,iBAAAyW,EAAA1W,KAAA,GAAA0W,EAAAR,GAAAQ,EAAA,SAAAL,GAAA,EAAAC,EAAAI,EAAAR,GAAA,QAAAQ,EAAA1W,KAAA,GAAA0W,EAAA1W,KAAA,GAAAoW,GAAA,MAAAI,EAAAlH,QAAAkH,EAAAlH,SAAA,WAAAoH,EAAA1W,KAAA,IAAAqW,EAAA,CAAAK,EAAAzW,KAAA,eAAAqW,EAAA,eAAAI,EAAAnH,OAAA,mBAAAmH,EAAAnH,OAAA,mBAAAmH,EAAAxV,OAAA,SAwBHyO,GAxBG,yBAAA+G,EAAAnW,SAAAK,EAAAvF,KAAA,+BA/LZ,gBAAA8F,EAAAY,GAAA,OAAApB,EAAAF,MAAApF,KAAAqF,YAAA,IAAAlB,EAAAiL,IAAAnL,IAAA,uBA0N6B,SAC3BsQ,EACAiH,EACAlG,EACAhB,GAmBA,OAjBAC,EAAEtI,QAAQ,SAACH,EAAG2P,GACV,IAAMC,EAAeF,EAAGC,GAClBE,EAAgBrG,EAAEmG,GACpBxG,GAAU,EACdyG,EAAazP,QAAQ,SAAC2P,EAAKnL,GACnBkL,EAAclL,KAASmL,GAAO3G,IAC9BA,GAAU,KAGdA,GACAX,EAAMW,UACNhR,EAAKY,OAAO0Q,MAAZ,aAAAxB,OAA+BjI,EAA/B,eAAAiI,OAA8C2H,EAA9C,iBAAA3H,OAA0E4H,MAE1ErH,EAAMY,QACNjR,EAAKY,OAAO2Q,MAAZ,WAAAzB,OAA6BjI,EAA7B,eAAAiI,OAA4C2H,EAA5C,iBAAA3H,OAAwE4H,OAGzErH,IA/OPrQ,EAAKjB,OAASA,EACdiB,EAAK2C,cAAgBA,EACrB3C,EAAKuC,gBAAkBA,EACvBvC,EAAK6G,MAAQ+E,GAAoC3H,EAASuN,MAAMxR,EAAKjB,OAAQiB,EAAK2C,eAClF3C,EAAKY,OAASA,EACdZ,EAAKyD,qBAAuBA,EAP9BzD,8OA1EgC2L,EAAM8F,kDACnB1S,EAA2D4D,GAC5E,IAAMgE,EAAWhE,EAAcU,oBACvBzD,EAA4Db,EAA5Da,aAAcL,EAA8CR,EAA9CQ,oBAAqBH,EAAyBL,EAAzBK,WAAYS,EAAad,EAAbc,SACjD+X,EAAejU,OAAOmQ,KAAKnR,EAAciR,WAAWlO,OAIpDiM,EAAYnL,EAAGzF,MAAM6Q,KAHL,MACF,MACA,IAGdiG,EAAyBrR,EAAGO,MAAM,CACpCE,MAAO,UAAWnM,MAAO,CAAC6L,EAAUpH,GAAsBrG,KAAM,mBAE9D2Y,EAAarL,EAAGQ,OACjB8K,OAAO,CACJC,WAAY,OACZC,QAAS5S,EAAW,GACpB8K,WAAY,CAACvD,EAAUpH,GACvB0S,kBAAmB,eACnBC,WAAY,EACZhZ,KAAM,WACNmD,QAAS,UAEZ8E,MAAM0W,GACLvF,EAAa9L,EAAGQ,OACjB8K,OAAO,CACJC,WAAY,OACZC,QAAS5S,EAAW,GACpB6S,kBAAmB,eACnBC,WAAY,EACZhZ,KAAM,WACNmD,QAAS,UAEZ8E,MAAM0Q,GAELiG,EAAkBtR,EAAGO,MAAM,CAC7BE,MAAO,UAAWnM,MAAO,CAAC6H,EAAcuJ,QAAQxG,QAASxM,KAAM,oBAE7D6e,EAAqBvR,EAAGQ,OAAOgR,aAAa,CAAEC,IAAe9W,MAAM2W,GACnEI,EAAW1R,EAAGQ,OAAO2L,cAAcxR,MAAM,CAC3C4W,EAAoBF,EAAwBvF,IAE1C6F,EAAS3R,EAAGQ,OACboR,cAAc,CACXnO,MAAOzD,EAAGQ,OAAOqR,KAAK,CAAE/E,MAAOzT,EAAUyY,iBAAiB,EAAMpf,KAAM,mBAEzEiI,MAAM+W,GACPK,EAAwC,KAC5C,GAAI3Y,EAAc,CACd,IAAM4Y,EAAgB,IAAIC,sBAAoB,CAAEvf,KAAM,qBAAsBiI,MAAMgX,EAAO,IACzFI,EAAc/R,EAAGQ,OAAO2L,cAAcxR,MAAM,CAACqX,EAAeL,EAAO,GAAIA,EAAO,UAE9EI,EAAc/R,EAAGQ,OAAO2L,cAAcxR,MAAM,CAACgX,EAAO,GAAIA,EAAO,KAEnE,IAAM/Q,EAAUZ,EAAGQ,OAAOqM,MAAM,CAAEtB,WAAY,UAAWuB,MAAOsE,IAAgBzW,MAAMoX,GAChF1R,EAAQL,EAAGK,MAAM,CAAEM,OAAQ,CAAC2Q,EAAiBD,GAAyBzQ,YAE5E,OADAP,EAAM0M,QAAQ,CAAE7D,KAAM,0BAA2B8D,QAAS,CAAC,YAAa7B,cACjE9K,2KC/Df,IAAAL,ySAAA/M,CAAAxB,EAAA,KACAygB,EAAAzgB,EAAA,o2BAOawgB,cAMT,SAAAA,EAAY1Z,GAAc,IAAAiB,MAAA,mGAAAC,CAAAlE,KAAA0c,KACtB1c,KAAAiE,MAAAiL,EAAAwN,GAAAvN,KAAAnP,KAAMgD,GAAU,mDADMmB,EAAAiL,IAAAnL,IAAA,YAJPyY,EAAoB9b,WAIbuD,EAAAiL,IAAAnL,IAAA,QAFa,MAInCA,EAAK2Y,UAAY,CAAC,IAAIC,YAAU,CAAEC,KAAM,KACxC7Y,EAAK8Y,iBAAkB,EAHD9Y,wPANWwG,EAAGQ,OAAOqD,2CAYlCH,GACT,IAAM6O,EAAa7O,EAAW,GACxB8O,EAAQxS,EAAG4C,WAAW,CAAElQ,KAAM,kBACpC8f,EAAMjP,IAAIvD,EAAGQ,OAAOqM,MAAM,CACtBnJ,WAAY,CAAC6O,GAAa9G,kBAAmB,QAASqB,MAAOyF,EAAYhH,WAAY,UAAW7Y,KAAM,gBAE1G8f,EAAMjP,IAAIvD,EAAGQ,OAAOqM,MAAM,CAAEC,MAAOyF,EAAY9G,kBAAmB,eAAgBF,WAAY,OAAQ7Y,KAAM,gBAC5G6C,KAAKid,MAAQxS,EAAGQ,OAAOgD,gBAAgB,CAAEC,MAAO+O,EAAO9f,KAAM,WAC7D6C,KAAKid,MAAMC,MAAM/O,GACjBnO,KAAKmd,iBAAmBnd,KAAKid,MAAME,iBACnCnd,KAAKod,oBAAsBpd,KAAKid,MAAMG,oBACtCpd,KAAKqd,OAAQ,+BAGLjS,EAAqBmD,GAAa,IAAAC,EAAAxO,KAC1C,IAAKA,KAAKqd,QAAUrd,KAAKid,MACrB,MAAM,IAAIrb,MAAM,oEAEpB,OAAO6I,EAAGa,KAAK,WACXkD,EAAKC,eAAerD,EAAQmD,GAC5B,IAAM+O,EAAW9O,EAAKyO,MAA0B7X,MAAMgG,GAChDmS,EAAW9S,EAAGQ,OAAOuS,QAAQ,CAAEC,KAAM,CAAC,EAAG,KAAMrY,MAAMkY,GAGrDI,EAAiBjT,EAAGkT,QAAQvS,EAAO,IACnCwS,EAAoBnT,EAAGkT,QAAQJ,GAC/BM,EAAWH,EAAerU,IAAI,SAACyU,EAAI1N,GAAL,OAAW3F,EAAGsT,IAAID,EAAIF,EAAkBxN,MACtE4N,EAAavT,EAAGiQ,MAAMmD,GACtBI,EAAYxT,EAAGyT,QAAQF,GACvBG,EAAoB1T,EAAGQ,OAAOuS,QAAQ,CAAEC,KAAM,CAAC,EAAG,KAAMrY,MAAM6Y,GAE9DG,EADqB3T,EAAGkT,QAAQQ,GACK9U,IAAI,SAACgV,EAAIjO,GAAL,OAAW3F,EAAGsT,IAAIM,EAAIX,EAAetN,MAEpF,OADe3F,EAAGiQ,MAAM0D,gDAKNjQ,GACtB,OAAOA,iEAlDFuO,cACiB,uBAqD9BjS,EAAGoE,cAAcC,iBAAiBC,SAAS2N,mMC7D3C9f,ySAAAc,CAAAxB,EAAA,k5BAYA,IAAMoiB,GAAc,EAXpBvgB,EAAA7B,EAAA,KAWoBa,SAAOwhB,EAAAxhB,QAAMyhB,QAAhBliB,WAAA,CAAAC,YAAA,wCAAAC,YAAA,eAAG,CAAH,6CAKIiiB,kVACuB,CACpCC,UAAU,EACVC,eAAgB,qCAEO,kBACvB/hB,EAAAC,cAAA,WACID,EAAAC,cAAA,mFACAD,EAAAC,cAAA,WACID,EAAAC,cAAA,UACID,EAAAC,cAAA,mBACAD,EAAAC,cAAA,iBACAD,EAAAC,cAAA,yBACAD,EAAAC,cAAA,sBACAD,EAAAC,cAAA,2DACAD,EAAAC,cAAA,8CACAD,EAAAC,cAAA,oEAGRD,EAAAC,cAAA,qJAIAD,EAAAC,cAAA,qBACc,IACVD,EAAAC,cAAA,KAAG+hB,OAAO,SAASthB,KAAK,sEAAxB,+CAFJ,qFAuCU,SAACyI,GACf,IAAMgP,EAAc9Q,EAAKhE,MAAM4e,SAAS7Y,QAAQ,CAACD,IACjD,OAAO6B,OAAOC,OAAO,GAAIkN,EAAY9R,eAAe,GAAI8R,EAAYnR,IAAI,+BAGrD,SAACyO,GACpB,IAAKA,IAAUA,EAAMtJ,OACjB,OAAO,KAEX9E,EAAK6a,SAAS,CAAEJ,UAAU,GAAQ,WAC9B,IAAMC,EAAiBI,KAAKC,UAAU/a,EAAK+B,QAAQqM,GAAQ,KAAM,GACjEpO,EAAK6a,SAAS,CAAEH,kBAAkB,WAC9B1a,EAAK6a,SAAS,CAAEJ,UAAU,IAC1B,IAAMO,EAAcC,SAASC,eAAe,iBACxCF,GAAeA,EAAY5M,QAC3B4M,EAAY5M,MAAQ,kQA7EczV,EAAMiD,kDAkCpD,OACIjD,EAAAC,cAAA,WACID,EAAAC,cAAAuiB,EAAAriB,QAAA,CAAKS,KAAK,OAAO6hB,QAAQ,UACrBziB,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,GAAIC,GAAI,CAAED,KAAM,KACvB3iB,EAAAC,cAAA4iB,EAAA1iB,QAAA,CAAME,MAAM,yBAAyBkD,MAAO,CAAEC,UAAW,SACrDxD,EAAAC,cAAA,SACID,EAAAC,cAACyhB,EAAD,CACIoB,YAAY,iCACZC,YAAY,OACZhS,KAAK,QACLiS,SAAU5f,KAAK6f,aACfC,GAAG,gBACHpB,SAAU1e,KAAK+f,MAAMrB,YAG5B1e,KAAKggB,sBAGdpjB,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,GAAIC,GAAI,CAAED,KAAM,KACvB3iB,EAAAC,cAAA4iB,EAAA1iB,QAAA,CAAME,MAAM,mBAAmBkD,MAAO,CAAEC,UAAW,SAC/CxD,EAAAC,cAAA,OAAKsD,MAAO,CAAE8f,UAAW,QAAUjgB,KAAK+f,MAAMpB,gBAAkB,4OCxE5F,IAAA/hB,ySAAAc,CAAAxB,EAAA,IACAgkB,EAAAniB,EAAA7B,EAAA,MACAikB,EAAApiB,EAAA7B,EAAA,MACAkkB,EAAAriB,EAAA7B,EAAA,mEAEe,SAAAkC,GAAuB,IAApBC,EAAoBD,EAApBC,SACd,OACIzB,EAAAC,cAACsjB,EAAApjB,QAAD,CAAQsB,SAAUA,EAAU8B,MAAO,CAAEC,UAAW,SAC5CxD,EAAAC,cAACqjB,EAAAnjB,QAAD,MACAH,EAAAC,cAACujB,EAAArjB,QAAD,+NCRZsjB,EAAAtiB,EAAA7B,EAAA,MACAgD,EAAAhD,EAAA,IACAU,ySAAAc,CAAAxB,EAAA,IAEAokB,EAAAviB,EAAA7B,EAAA,ktCAaqBqkB,kVACkB,CAC/B3Z,cAAe,KACf4Z,YAAa,KACbC,gBAAiB,KACjBC,iBAAkB,EAClBC,oCAAoC,EACpCC,eAAe,EACfvZ,oBAAqB,KACrBG,uBAAwB,qCAmEA,kBACxB5K,EAAAC,cAAA,WACID,EAAAC,cAAA,uFACAD,EAAAC,cAAA,WACID,EAAAC,cAAA,UACID,EAAAC,cAAA,mBACAD,EAAAC,cAAA,iBACAD,EAAAC,cAAA,yBACAD,EAAAC,cAAA,sBACAD,EAAAC,cAAA,2DACAD,EAAAC,cAAA,8CACAD,EAAAC,cAAA,oEAGRD,EAAAC,cAAA,qBACc,IACVD,EAAAC,cAAA,KAAG+hB,OAAO,SAASthB,KAAK,sEAAxB,+CAFJ,sIAUgB,SAAAiH,EAAOsc,GAAP,IAAAC,EAAAC,EAAAC,EAAA,OAAA3c,mBAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,cAChBkc,EAAQ,EACRC,EAAW,EACf9c,EAAK6a,SAAS,CAAE8B,eAAe,EAAMF,iBAAkB,IAHnChc,EAAAE,KAAA,EAIIqc,QAAQC,IAC5BL,EAAMxX,IAAI,SAAA8X,GAAI,OACVC,UAAMC,IAAIF,EAAM,CACZG,mBAAoB,SAAAC,GAChB,IAAMC,EAAcD,EAAcE,iBAC5BF,EAAcT,MACdS,EAAc3C,OAAO8C,kBAAkB,mBACvCH,EAAc3C,OAAO8C,kBAAkB,iCACzB,OAAhBF,IACAV,GAASU,EACTT,GAAYY,KAAKC,MAA8B,IAAvBL,EAAcM,OAAgBf,IAE1D7c,EAAK6a,SAAS,CAAE4B,iBAAkBK,UAhB9B,cAIdC,EAJctc,EAAAkB,KAqBpB3B,EAAK6a,SAAS,CAAE8B,eAAe,EAAOF,iBAAkB,MArBpChc,EAAAmB,OAAA,SAsBbmb,GAtBa,wBAAAtc,EAAAQ,SAAAX,EAAAvE,mIAyBF,SAAAuF,EAAOuc,GAAP,OAAAzd,mBAAAI,KAAA,SAAAkB,GAAA,cAAAA,EAAAhB,KAAAgB,EAAAf,MAAA,cAAAe,EAAAE,OAAA,SAAsB,IAAIob,QAAQ,SAAAc,GAAO,OAAIC,WAAWD,EAASD,MAAjE,wBAAAnc,EAAAT,SAAAK,EAAAvF,6HAEW,SAAAkG,IAAA,IAAA2a,EAAAoB,EAAAza,EAAAH,EAAAT,EAAA6Z,EAAAD,EAAA,OAAAnc,mBAAAI,KAAA,SAAA0B,GAAA,cAAAA,EAAAxB,KAAAwB,EAAAvB,MAAA,cACvBic,EAAQ,EACV,EAAA3hB,EAAAgjB,YAAW,4BACX,EAAAhjB,EAAAgjB,YAAW,wCACX,EAAAhjB,EAAAgjB,YAAW,gCACX,EAAAhjB,EAAAgjB,YAAW,kCACX,EAAAhjB,EAAAgjB,YAAW,iCANc/b,EAAAvB,KAAA,EAQLX,EAAKke,cAActB,GARd,cAQvBoB,EARuB9b,EAAAP,KASvB4B,EAAyB,IAAI4F,IAA0B6U,EAAU,GAAG5f,MACpEgF,EAAsB4a,EAAU,GAAG5f,KACnCuE,EAAgBqb,EAAU,GAAG5f,KAC7Boe,EAAkBwB,EAAU,GAAG5f,KAC/Bme,EAAcyB,EAAU,GAAG5f,KAbJ8D,EAAAvB,KAAA,GAcvBX,EAAKme,YAAY,KAdM,QAe7Bne,EAAK6a,SAAS,CACVlY,gBACA4Z,cACAC,kBACAE,oCAAoC,EACpCtZ,sBACAG,2BArByB,yBAAArB,EAAAjB,SAAAgB,EAAAlG,kQA/HKpD,EAAMiD,kDAY5B,IAAAwiB,EAQRriB,KAAK+f,MANLY,EAFQ0B,EAER1B,mCACA/Z,EAHQyb,EAGRzb,cACA6Z,EAJQ4B,EAIR5B,gBACAD,EALQ6B,EAKR7B,YACAnZ,EANQgb,EAMRhb,oBACAG,EAPQ6a,EAOR7a,uBAEJ,GACImZ,GACA/Z,GACA6Z,GACAD,GACAnZ,GACAG,EAEA,OACI5K,EAAAC,cAACyjB,EAAAvjB,QAAD,CACI6J,cAAeA,EACfpC,aAAcic,EACdjb,YAAagb,EACbnZ,oBAAqBA,EACrBG,uBAAwBA,IAIpC,IAAM8a,EAAkBtiB,KAAK+f,MAAMa,eAAiD,MAAhC5gB,KAAK+f,MAAMW,iBACzD6B,EAAgBD,EAAmD,MAAhCtiB,KAAK+f,MAAMW,iBAA2B,aAAe,iBAAoB,iBAClH,OACI9jB,EAAAC,cAAAuiB,EAAAriB,QAAA,CAAKS,KAAK,QACNZ,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,GAAIC,GAAI,CAAED,KAAM,KACvB3iB,EAAAC,cAAA,2CACAD,EAAAC,cAAA,0VAKCmD,KAAKggB,oBACNpjB,EAAAC,cAAA,iDAEJD,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,GAAIC,GAAI,CAAED,KAAM,KACvB3iB,EAAAC,cAAA4iB,EAAA1iB,QAAA,CAAMoD,MAAO,CAAEqiB,WAAY,MAAOhiB,UAAW,WACzC5D,EAAAC,cAAA,WACID,EAAAC,cAAA4lB,EAAA1lB,QAAA,CAAUS,KAAK,SAASklB,QAAS1iB,KAAK+f,MAAMW,oBAEhD9jB,EAAAC,cAAA,WACAD,EAAAC,cAAA,WACID,EAAAC,cAAA8lB,EAAA5lB,QAAA,CAAQS,KAAK,UAAUmQ,KAAK,QAAQ+Q,SAAU4D,EAAiBM,QAAS5iB,KAAK6iB,wBACxEN,IAGT3lB,EAAAC,cAAA,WACAD,EAAAC,cAAA,mhBCnFxB4N,EAAA/M,EAAAxB,EAAA,KAEAU,EAAAc,EAAAxB,EAAA,IACAiD,EAAApB,EAAA7B,EAAA,KACA4mB,EAAA5mB,EAAA,KAEA6mB,EAAAhlB,EAAA7B,EAAA,MACA8mB,EAAAjlB,EAAA7B,EAAA,u/CAEA,IAAM+mB,EAAsB,CACxB,qGACA,kHACA,oIACA,qHACA,sGAEEC,EAAa9mB,UAAOC,IAAVC,WAAA,CAAAC,YAAA,gCAAAC,YAAA,YAAGJ,CAAH,yNA+BK+mB,kVACuB,CACpCC,YAAa,EACbC,gBAAiB,EACjBC,0BAA0B,EAC1BC,MAAM,EACNC,qBAAsB,GACtBC,UAAW,0BAEyB,2CACsB,8BACX,8CAmCX,WACpC,OAA+B,IAA3Bxf,EAAK8b,MAAMqD,aAAqBnf,EAAK4a,SAEjCjiB,EAAAC,cAAAD,EAAA8mB,SAAA,KACI9mB,EAAAC,cAAA8mB,EAAA5mB,QAAA,CACI6mB,QAAQ,oFACRpmB,KAAK,UACL2C,MAAO,CAAE0jB,aAAc,MAE3BjnB,EAAAC,cAACmmB,EAAAjmB,QAAD,CAA0B8hB,SAAU5a,EAAK4a,YAI9C,+BAGW,SAAC5hB,EAAewS,EAA8B6E,GAChE,IAAKA,EAAM3K,SAAW8F,EAAO9F,OACzB,OACI/M,EAAAC,cAAA4iB,EAAA1iB,QAAA,CAAME,MAAOA,EAAOkD,MAAO,CAAEC,UAAW,SACpCxD,EAAAC,cAAA,wBAIZ,IAAMinB,EAAS,SAAA/P,OAAYtE,EAAO9F,OAAnB,QAAAoK,OAAgCO,EAAMA,EAAM3K,OAAS,GAAG4J,cACjEwQ,EAAY9f,EAAK8b,MAAMwD,KAAO3mB,EAAAC,cAACkmB,EAAAhmB,QAAD,CAAWinB,WAAYvU,IAAa,KACxE,OACI7S,EAAAC,cAAA4iB,EAAA1iB,QAAA,CAAME,MAAOA,EAAOgnB,MAAOH,EAAW3jB,MAAO,CAAEC,UAAW,SACrD2jB,EACDnnB,EAAAC,cAAA,KAAGsD,MAAO,CAAEa,SAAU,SAClBpE,EAAAC,cAAA,iCADJ,IACsCyX,EAAMA,EAAM3K,OAAS,GAAG6J,iBAC1D5W,EAAAC,cAAA,WACAD,EAAAC,cAAA,sCAHJ,IAG2CyX,EAAMA,EAAM3K,OAAS,GAAGiK,mBAC/DhX,EAAAC,cAAA,WACAD,EAAAC,cAAA,6BALJ,IAKkCyX,EAAMA,EAAM3K,OAAS,GAAG+J,aACtD9W,EAAAC,cAAA,WACAD,EAAAC,cAAA,kCAPJ,IAOuCyX,EAAMA,EAAM3K,OAAS,GAAGmK,eAC3DlX,EAAAC,cAAA,6CAMY,iBAAiC,CACzDoG,eAAgB,SAAAqR,GACZrQ,EAAKigB,yBAAyBnX,KAAKuH,GADd,IAEbtB,EAAwCsB,EAAxCtB,MAAOc,EAAiCQ,EAAjCR,eAAgBJ,EAAiBY,EAAjBZ,aAC/BzP,EAAK6a,SAAS,SAAAhT,GAAC,MAAK,CAChB0X,qBAAsB1X,EAAE0X,qBAAqBzP,OAAO,CAAC,CAAEf,QAAOc,iBAAgBJ,sBAGtF9P,IAAK,SAAA0Q,GACDrQ,EAAKkgB,cAAcpX,KAAKuH,GADd,IAEFtB,EAAwCsB,EAAxCtB,MAAOc,EAAiCQ,EAAjCR,eAAgBJ,EAAiBY,EAAjBZ,aAC/BzP,EAAK6a,SAAS,SAAAhT,GAAC,MAAK,CAChBsX,YAA+B,IAAlBtX,EAAEsX,YAAoB,EAAItX,EAAEsX,YACzCK,UAAW3X,EAAE2X,UAAU1P,OAAO,CAAC,CAAEf,QAAOc,iBAAgBJ,sFAKnC,SAAAnP,IAAA,IAAA6f,EAAAvf,EAAAyP,EAAA,OAAAjQ,mBAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,UAKvBC,EAAqC,CACvC0Q,MAAO,kBAAM,MACbC,MANE4O,EAAa,WACfnB,EAAUlW,KAAV3H,MAAA6d,EAAS5d,WACTpB,EAAK6a,SAAS,SAAAna,GAAI,MAAK,CAAE0e,gBAAiB1e,EAAK0e,gBAAkB,MAKjEve,IAAKsf,EACL1X,KAAM0X,GAEVngB,EAAK4a,SAAW,IAAI9a,eAAa,CAC7B6C,cAAe3C,EAAKhE,MAAM2G,cAC1B/B,SACAwC,oBAAqBpD,EAAKhE,MAAMoH,oBAChCG,uBAAwBvD,EAAKhE,MAAMuH,uBACnCM,kBAAmB7D,EAAK6D,sBAEvB7D,EAAK4a,SAlBmB,CAAAna,EAAAE,KAAA,eAAAF,EAAAmB,OAAA,SAmBlB,MAnBkB,cAAAnB,EAAAE,KAAA,EAqBvBX,EAAK4a,SAAS7Z,MAAMf,EAAKhE,MAAMuE,cArBR,cAsB7BP,EAAK6a,SAAS,CAAEsE,YAAa,IAtBA1e,EAAAE,KAAA,GAuBTX,EAAK4a,SAAS9e,KAAKkE,EAAKhE,MAAMuF,aAvBrB,eAuBvB8O,EAvBuB5P,EAAAkB,KAwB7B3B,EAAK6a,SAAS,CAAEsE,YAAa,IAC7Bve,EAAOC,IAAI,sGACXD,EAAOC,IAAI,uBACXD,EAAOC,IAAIia,KAAKC,UAAU1K,EAAO,KAAM,IACvCzP,EAAOC,IAAI,sGA5BkBJ,EAAAE,KAAA,GA6BvBX,EAAK4a,SAASxY,KAAK,CACrBC,mBAAoB,6BACpBG,cAAe,wBACfF,QAAS,oBAhCgB,QAkC7BtC,EAAK6a,SAAS,CAAEyE,MAAM,IAlCO,yBAAA7e,EAAAQ,SAAAX,EAAAvE,kQA3GUpD,EAAMiD,6DAc7CG,KAAK6iB,wEAIL7iB,KAAK6e,SAAW,KAEhBpS,QAAQ3H,IAAI2F,EAAG4I,UACf5I,EAAG4Z,oDAIH,OACIznB,EAAAC,cAAA,WACID,EAAAC,cAAAynB,EAAAvnB,QAAA,CAAO4Q,KAAK,QAAQyL,QAASpZ,KAAK+f,MAAMqD,YAAajjB,MAAO,CAAE0jB,aAAc,SACxEjnB,EAAAC,cAAAynB,EAAAvnB,QAAOwnB,KAAP,CAAYtnB,MAAM,+BAClBL,EAAAC,cAAAynB,EAAAvnB,QAAOwnB,KAAP,CAAYtnB,MAAM,oBAClBL,EAAAC,cAAAynB,EAAAvnB,QAAOwnB,KAAP,CAAYtnB,MAAM,gBAClBL,EAAAC,cAAAynB,EAAAvnB,QAAOwnB,KAAP,CAAYtnB,MAAM,sBAErB+C,KAAKwkB,gCACN5nB,EAAAC,cAAA,MAAIsD,MAAO,CAAE8f,UAAW,SAAxB,kBACArjB,EAAAC,cAACqmB,EAAD,KAAaD,EAAUnZ,KAAK,OAC5BlN,EAAAC,cAAAuiB,EAAAriB,QAAA,CAAKS,KAAK,OAAO6hB,QAAQ,UACrBziB,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,IACNvf,KAAKykB,YAAY,6BAA8BzkB,KAAK+f,MAAMyD,qBAAsBxjB,KAAKkkB,2BAE1FtnB,EAAAC,cAAAyiB,EAAAviB,QAAA,CAAKwiB,KAAM,IAAKvf,KAAKykB,YAAY,kBAAmBzkB,KAAK+f,MAAM0D,UAAWzjB,KAAKmkB,qGCrFnGjoB,EAAQ,IAERA,EAAQ,6DCFR0L,OAAA8c,eAAA7mB,EAAA,cACAwU,OAAA,IAGA,IAEAsS,EAAA5mB,EAFgB7B,EAAQ,KAMxB0oB,EAAA7mB,EAFuB7B,EAAQ,KAM/B2oB,EAAA9mB,EAFoB7B,EAAQ,KAM5B4oB,EAAA/mB,EAFkC7B,EAAQ,KAM1C6oB,EAAAhnB,EAFiB7B,EAAQ,KAMzBU,EAAAc,EAFaxB,EAAQ,IAMrB4C,EAAApB,EAFiBxB,EAAQ,IAMzB8oB,EAAAjnB,EAFe7B,EAAQ,MAMvB+oB,EAAAlnB,EAFY7B,EAAQ,KAIpB,SAAAwB,EAAAwnB,GAAuC,GAAAA,KAAAC,WAA6B,OAAAD,EAAqB,IAAAE,EAAA,GAAiB,SAAAF,EAAmB,QAAAloB,KAAAkoB,EAAuBtd,OAAAyd,UAAAC,eAAAnW,KAAA+V,EAAAloB,KAAAooB,EAAApoB,GAAAkoB,EAAAloB,IAAyG,OAAzBooB,EAAA,QAAAF,EAAyBE,EAE7P,SAAArnB,EAAAmnB,GAAsC,OAAAA,KAAAC,WAAAD,EAAA,CAAuCnoB,QAAAmoB,GAE7E,IAAAK,EAAA,SAAAC,GAGA,SAAAD,IAEA,OADA,EAAAX,EAAA,SAAA5kB,KAAAulB,IACA,EAAAT,EAAA,SAAA9kB,MAAAulB,EAAAE,WAAA7d,OAAA8d,eAAAH,IAAAngB,MAAApF,KAAAqF,YAeA,OAnBA,EAAA0f,EAAA,SAAAQ,EAAAC,IAOA,EAAAX,EAAA,SAAAU,EAAA,EACAvoB,IAAA,SACAqV,MAAA,WACA,IAAAsT,EAAA3lB,KAAAC,MAAA0lB,UAEAC,EAAA,CACA1R,OAAAtX,EAAAC,cAAAooB,EAAA,SAAgEznB,KAAA,QAAAoD,UAAA+kB,EAAA,iBAChEnQ,MAAA5Y,EAAAC,cAAAooB,EAAA,SAA+DznB,KAAA,QAAAoD,UAAA+kB,EAAA,iBAE/D,OAAA/oB,EAAAC,cAAAmoB,EAAA,WAAAL,EAAA,UAAwFiB,SAAe5lB,KAAAC,YAGvGslB,EApBA,CAqBC3oB,EAAAiD,WAEDhC,EAAA,QAAA0nB,EAEAA,EAAAhB,KAAAS,EAAA,QAAAT,KACAgB,EAAAM,aAAA,CACAF,UAAA,YACAG,WAAA,MACA1M,QAAA,GAEAmM,EAAA1mB,UAAA,CACA8mB,UAAA7mB,EAAAE,OACA8mB,WAAAhnB,EAAAE,OACAoa,QAAAta,EAAAinB,QAEAnoB,EAAAC,UAAA,0CChFA3B,EAAQ,IAERA,EAAQ,6DCFR0L,OAAA8c,eAAA7mB,EAAA,cACAwU,OAAA,IAGA,IAEAsS,EAAA5mB,EAFgB7B,EAAQ,KAMxB8pB,EAAAjoB,EAFuB7B,EAAQ,KAM/B0oB,EAAA7mB,EAFuB7B,EAAQ,KAM/B2oB,EAAA9mB,EAFoB7B,EAAQ,KAM5B4oB,EAAA/mB,EAFkC7B,EAAQ,KAM1C6oB,EAAAhnB,EAFiB7B,EAAQ,KAMzBU,EAAAc,EAFaxB,EAAQ,IAMrB+pB,EAAAvoB,EAFgBxB,EAAQ,IAMxBgqB,EAAAnoB,EAFiB7B,EAAQ,MAMzB+oB,EAAAlnB,EAFY7B,EAAQ,KAMpBiqB,EAAApoB,EAFkB7B,EAAQ,KAM1BkqB,EAAAroB,EAF0B7B,EAAQ,MAIlC,SAAAwB,EAAAwnB,GAAuC,GAAAA,KAAAC,WAA6B,OAAAD,EAAqB,IAAAE,EAAA,GAAiB,SAAAF,EAAmB,QAAAloB,KAAAkoB,EAAuBtd,OAAAyd,UAAAC,eAAAnW,KAAA+V,EAAAloB,KAAAooB,EAAApoB,GAAAkoB,EAAAloB,IAAyG,OAAzBooB,EAAA,QAAAF,EAAyBE,EAE7P,SAAArnB,EAAAmnB,GAAsC,OAAAA,KAAAC,WAAAD,EAAA,CAAuCnoB,QAAAmoB,GAE7E,SAAAmB,KAEA,IAAAC,EAAA,SAAAd,GAGA,SAAAc,EAAArmB,IACA,EAAA2kB,EAAA,SAAA5kB,KAAAsmB,GAEA,IAAAriB,GAAA,EAAA6gB,EAAA,SAAA9kB,MAAAsmB,EAAAb,WAAA7d,OAAA8d,eAAAY,IAAAnX,KAAAnP,KAAAC,IAyBA,OAvBAgE,EAAAsiB,YAAA,SAAAC,GACAA,EAAAC,iBACA,IAAAC,EAAAT,EAAAU,YAAA1iB,GACAyiB,EAAAvmB,MAAAymB,OAAAF,EAAAG,aAAA,KAGAH,EAAAvmB,MAAAymB,OAAAF,EAAAG,aAAA,KACA5iB,EAAA6a,SAAA,CACAgI,SAAA,KAEA7iB,EAAAhE,MAAA8mB,SAAAV,GAAAG,IAEAviB,EAAA+iB,aAAA,WACA/iB,EAAA6a,SAAA,CACAmI,QAAA,EACAH,SAAA,KAEA7iB,EAAAhE,MAAAinB,YAAAb,MAEApiB,EAAA8b,MAAA,CACA+G,SAAA,EACAG,QAAA,GAEAhjB,EAoFA,OAlHA,EAAA8gB,EAAA,SAAAuB,EAAAd,IAiCA,EAAAX,EAAA,SAAAyB,EAAA,EACAtpB,IAAA,SACAqV,MAAA,WACA,IAAA8U,EAEAC,EAAApnB,KAAAC,MACAonB,EAAAD,EAAAC,SACAC,EAAAF,EAAAE,YACA9pB,EAAA4pB,EAAA5pB,KACA+pB,EAAAH,EAAAzB,UACAA,OAAAvZ,IAAAmb,EAAA,YAAAA,EACA3D,EAAAwD,EAAAxD,QACA4D,EAAAJ,EAAAI,UACAC,EAAAL,EAAAK,SACAC,EAAAN,EAAAM,OACAC,EAAAP,EAAAxmB,UACAA,OAAAwL,IAAAub,EAAA,GAAAA,EACAxnB,EAAAinB,EAAAjnB,MACAynB,EAAAR,EAAAQ,SAGAH,KAAAC,QAAAtb,IAAAqb,MAEAjqB,EAAAkqB,QAAAtb,IAAA5O,EAAA,UAAAA,GAAA,OACA,IAAAqqB,EAAA,SACA,IAAAD,EAAA,CACA,OAAApqB,GACA,cACAoqB,EAAA,eACA,MACA,WACAA,EAAA,cACA,MACA,YACAA,EAAA,eACA,MACA,cACAA,EAAA,qBACA,MACA,QACAA,EAAA,UAGAN,IACAO,EAAA,YAGA,IAAAC,GAAA,EAAA3B,EAAA,SAAAR,GAAAwB,EAAA,IAAoF,EAAAnB,EAAA,SAAAmB,EAAAxB,EAAA,IAAAnoB,GAAA,MAAAwoB,EAAA,SAAAmB,EAAAxB,EAAA,UAAA3lB,KAAA+f,MAAA+G,UAAA,EAAAd,EAAA,SAAAmB,EAAAxB,EAAA,sBAAA2B,IAAA,EAAAtB,EAAA,SAAAmB,EAAAxB,EAAA,YAAA8B,IAAA,EAAAzB,EAAA,SAAAmB,EAAAxB,EAAA,YAAA+B,GAAAP,GAAAvmB,GAEpF4mB,IACAH,GAAA,GAEA,IAAAU,EAAAV,EAAAzqB,EAAAC,cACA,IACA,CAAiB+lB,QAAA5iB,KAAAumB,YAAA3lB,UAAA+kB,EAAA,eACjB6B,GAAA5qB,EAAAC,cAAAooB,EAAA,SAAqEznB,KAAA,WACrE,KACAwqB,GAAA,EAAA5B,EAAA,SAAApmB,KAAAC,OACAgoB,EAAArrB,EAAAC,cAAAooB,EAAA,SAAmErkB,UAAA+kB,EAAA,QAAAnoB,KAAAoqB,EAAAtmB,MAAAumB,IACnE,OAAA7nB,KAAA+f,MAAAkH,OAAA,KAAArqB,EAAAC,cACAqpB,EAAA,QACA,CAAiBgC,UAAA,GAAAC,SAAA,YAAAC,eAAAzC,EAAA,YAAA0C,MAAAroB,KAAAgnB,cACjBpqB,EAAAC,cACA,OACA,EAAA8nB,EAAA,UAA+C2D,YAAAtoB,KAAA+f,MAAA+G,QAAAlmB,UAAAknB,EAAA3nB,SAAqE6nB,GACpHP,EAAAQ,EAAA,KACArrB,EAAAC,cACA,OACA,CAAyB+D,UAAA+kB,EAAA,YACzB/B,GAEAhnB,EAAAC,cACA,OACA,CAAyB+D,UAAA+kB,EAAA,gBACzB2B,GAEAS,QAKAzB,EAnHA,CAoHC1pB,EAAAiD,WAEDhC,EAAA,QAAAyoB,EACA1oB,EAAAC,UAAA,0CCjLA+J,OAAA8c,eAAA7mB,EAAA,cACAwU,OAAA,IAEAxU,EAAA,QACA,SAAAoC,GACA,OAAA2H,OAAAmQ,KAAA9X,GAAAgZ,OAAA,SAAAtU,EAAA3H,GAIA,MAHA,UAAAA,EAAA4M,OAAA,gBAAA5M,EAAA4M,OAAA,eAAA5M,GAAA,YAAAA,EAAA4M,OAAA,OACAjF,EAAA3H,GAAAiD,EAAAjD,IAEA2H,GACK,KAEL/G,EAAAC,UAAA,4GCdA,IAAAjB,ySAAAc,CAAAxB,EAAA,+yBAIqBqsB,gaAAsB3rB,EAAMiD,kDAEzC,OACIjD,EAAAC,cAAA,yQCPL,SAAA2rB,IACP,uBAAAC,eAAAvJ,UAAAuJ,OAAAvJ,SAAAwJ,gBAAA,CACA,IAAAA,EAAAD,OAAAvJ,SAAAwJ,gBAEA,eAAAA,EAAAvoB,OAAA,eAAAuoB,EAAAvoB,OAAA,SAAAuoB,EAAAvoB,OAAA,WAAAuoB,EAAAvoB,MAEA,SCOA,IAAIwoB,EAAK,SAAAC,GAGT,SAAArD,EAAAtlB,GACI4oB,IAAe7oB,KAAAulB,GAEnB,IAAAthB,EAAgB6kB,IAA0B9oB,KAAA4oB,EAAAzZ,KAAAnP,KAAAC,IA6B1C,OA3BAgE,EAAA8kB,oBAAA,WACA,IAAUP,IAAV,CAIA,IAAAQ,EAAoBphB,OAAAqhB,EAAA,YAAArhB,CAAW3D,GAC/B+kB,EAAArnB,SAAAgI,OAAA,IACA1F,EAAAilB,aACAC,aAAAllB,EAAAilB,aAEAjlB,EAAAilB,YAAAlH,WAAA,WAEA,IAAAoH,GAAAJ,EAAAK,UAAAC,aAAA,KAEArlB,EAAA8b,MAAAqJ,yBAAAzH,KAAA4H,IAAAtlB,EAAA8b,MAAAqJ,wBAAA,GAGAnlB,EAAA6a,SAAA,CAA0BsK,6BAK1BnlB,EAAA8b,MAAA,CACAyJ,eAAA,EACAJ,oBAAA,GAEAnlB,EAAA8kB,oBAAgCU,IAAQxlB,EAAA8kB,oBAAA,KACxC9kB,EA8FA,OAhIEylB,IAASnE,EAAAqD,GAqCXrD,EAAAF,UAAAsE,kBAAA,WACA3pB,KAAA+oB,sBACSP,KACTxoB,KAAA8e,SAAA,CACA0K,eAAA,KAKAjE,EAAAF,UAAAuE,mBAAA,WACA5pB,KAAA+oB,uBAGAxD,EAAAF,UAAAwE,qBAAA,WACA7pB,KAAAkpB,aACAC,aAAAnpB,KAAAkpB,aAEAlpB,KAAA+oB,qBAAA/oB,KAAA+oB,oBAAAe,QACA9pB,KAAA+oB,oBAAAe,UAIAvE,EAAAF,UAAA9iB,OAAA,WACA,IAAA4kB,EAEAC,EAAApnB,KAAAC,MACA0lB,EAAAyB,EAAAzB,UACAoE,EAAA3C,EAAAjnB,MACAA,OAAAiM,IAAA2d,EAAA,GAA+CA,EAC/CnpB,EAAAwmB,EAAAxmB,UACAe,EAAAylB,EAAAzlB,SACAqoB,EAAA5C,EAAA4C,UACAC,EAAA7C,EAAA6C,eACAnE,EAAAsB,EAAAtB,WACAoE,EAAA9C,EAAA8C,OACAvc,EAAAyZ,EAAAzZ,KACAyL,EAAAgO,EAAAhO,QACA+Q,EAAA/C,EAAA+C,YACAC,EAAAhD,EAAAgD,QACAxE,EAAAwB,EAAAxB,MACAyE,EAAoBC,IAAwBlD,EAAA,kJAE5CmD,EAAAvqB,KAAA+f,MACAqJ,EAAAmB,EAAAnB,oBACAI,EAAAe,EAAAf,cAEAgB,EAA2BC,EAAA5Z,EAAK6Z,SAAAC,QAAAhpB,GAAA4H,OAAA,SAAAqI,GAChC,QAAAA,IAEAgZ,EAAAJ,EAAA7gB,OAAA,EACAkhB,EAAAV,EAAA,WAAAF,EACAa,EAAsBC,IAAUpF,IAAA,IAAAqE,EAAAppB,IAAAumB,EAAA,IAAqExB,EAAA,IAAAhY,KAAAwZ,EAAAxB,EAAA,UAAAkF,GAAA,eAAAb,EAAA7C,EAAAxB,EAAA,UAAAwE,EAAAhD,IAErG,OAAWsD,EAAA5Z,EAAKhU,cAChB,MACMmuB,IAAQ,CAAEpqB,UAAAkqB,EAAA3qB,SAAuCkqB,GACjDY,EAAA,SAAQ5hB,IAAAmhB,EAAA,SAAAU,EAAAxhB,GACd,IAAAwhB,EACA,YAEA,IAAAC,EAAAf,EAAA1gB,EACA0hB,EAAyBJ,IAAQ,CACjCG,WAAA,IAAAA,EAAA,GACAxF,YACAG,aACAuF,aAAAlrB,EACAgqB,cACAvE,SACSsF,EAAAjrB,OAkBT,OAjBAupB,GAAA,aAAAQ,GAAAtgB,IAAAkhB,IACAQ,EAAAE,UAAA,IAAAV,EAAA,IACAQ,EAAAG,mBAAA5J,KAAAC,MAAAwH,EAAAwB,EAAA,IAGA,UAAAV,GAAAxgB,IAAA0P,EAAA,IACAgS,EAAAxqB,UAAA+kB,EAAA,eAEAuF,EAAAjrB,MAAAiqB,SAEAkB,EAAAlB,OADAiB,IAAA/R,EACA8Q,EACWiB,EAAA/R,EACX,SAEA,QAGexR,OAAAqjB,EAAA,aAAArjB,CAAYsjB,EAAAE,OAK3B7F,EAjIS,CAkIP0F,EAAA,WAEFtC,EAAK9pB,UAAA,CACL8mB,UAAa6F,EAAA3a,EAAS7R,OACtB4B,UAAa4qB,EAAA3a,EAAS7R,OACtB8mB,WAAc0F,EAAA3a,EAAS7R,OACvBgrB,UAAawB,EAAA3a,EAAS7R,OACtBirB,eAAkBuB,EAAA3a,EAAS7R,OAC3B2C,SAAY6pB,EAAA3a,EAAS4a,IACrBvB,OAAUsB,EAAA3a,EAAS7R,OACnB2O,KAAQ6d,EAAA3a,EAAS7R,OACjBmrB,YAAeqB,EAAA3a,EAAS6a,UAAA,CAAYF,EAAA3a,EAAS8a,KAAOH,EAAA3a,EAASpO,OAC7DtC,MAASqrB,EAAA3a,EAASrO,OAClB4nB,QAAWoB,EAAA3a,EAASkV,OACpB3M,QAAWoS,EAAA3a,EAASkV,OACpBH,MAAS4F,EAAA3a,EAAS9R,MAAA,CAClBmV,OAAYsX,EAAA3a,EAAS+a,KACrBpW,MAAWgW,EAAA3a,EAAS+a,QAGpBjD,EAAK9C,aAAA,CACLF,UAAA,WACAG,WAAA,KACAkE,UAAA,aACAC,eAAA,aACAG,QAAA,EACAhR,QAAA,EACA8Q,OAAA,UACAvc,KAAA,GACAwc,aAAA,GAEe,IAAA0B,EAAA,ECrKf,SAAAC,EAAAC,GACA,uBAAAA,EAGA,IAAIC,EAAI,SAAAxG,GAGR,SAAAjB,IAGA,OAFIsE,IAAe7oB,KAAAukB,GAERuE,IAA0B9oB,KAAAwlB,EAAApgB,MAAApF,KAAAqF,YAiIrC,OAtIEqkB,IAASnF,EAAAiB,GAQXjB,EAAAc,UAAA4G,eAAA,WACA,IAAA9E,EAEAC,EAAApnB,KAAAC,MACA0lB,EAAAyB,EAAAzB,UACAwE,EAAA/C,EAAA+C,YACAgB,EAAA/D,EAAA+D,WACAjB,EAAA9C,EAAA8C,OACAjtB,EAAAmqB,EAAAnqB,MACAqqB,EAAAF,EAAAE,YACA4E,EAAA9E,EAAA8E,KACApG,EAAAsB,EAAAtB,WACAF,EAAAwB,EAAAxB,MAGAuG,EAAwBpB,IAAUpF,EAAA,QAAAG,EAAA,SAAAqB,EAAA,IAA4DrB,EAAA,QAAAoG,MAAAJ,EAAAI,GAAA/E,EAAArB,EAAA,eAAAoG,GAAA,WAAAhC,GAAAtE,MAAA1R,OAAAiT,EAAArB,EAAA,eAAAoG,GAAA,UAAAhC,GAAAtE,MAAApQ,MAAA2R,IAC9FiF,EAAkB3B,EAAA5Z,EAAKhU,cAAA,QAAwB+D,UAAA+kB,EAAA,cA4C/C,OA1CAwE,EACA,mBAAAA,EACmBM,EAAA5Z,EAAKhU,cACxB,OACA,CAAW+D,UAAA+kB,EAAA,SACXwE,EAAAiC,EAAA,CAAgC1iB,MAAAyhB,EAAA,EAAAjB,SAAAjtB,QAAAqqB,iBAGbmD,EAAA5Z,EAAKhU,cACxB,OACA,CAAW+D,UAAA+kB,EAAA,SACXyG,GAGKF,IAAAJ,EAAAI,GACYzB,EAAA5Z,EAAKhU,cACtB,OACA,CAAS+D,UAAA+kB,EAAA,SACTuG,GAEKtG,KAAA1R,QAAA,WAAAgW,EACYO,EAAA5Z,EAAKhU,cACtB,OACA,CAAS+D,UAAA+kB,EAAA,SACTC,EAAA1R,QAEK0R,KAAApQ,OAAA,UAAA0U,EACYO,EAAA5Z,EAAKhU,cACtB,OACA,CAAS+D,UAAA+kB,EAAA,SACTC,EAAApQ,OAEK0W,GAAA,WAAAhC,GAAA,UAAAA,EACYO,EAAA5Z,EAAKhU,cAAA,QAAwB+D,UAAAurB,IAE7B1B,EAAA5Z,EAAKhU,cACtB,OACA,CAAS+D,UAAA+kB,EAAA,SACTwF,IAOA5G,EAAAc,UAAA9iB,OAAA,WACA,IAAA8pB,EAEAC,EAAAtsB,KAAAC,MACAW,EAAA0rB,EAAA1rB,UACA+kB,EAAA2G,EAAA3G,UACAxlB,EAAAmsB,EAAAnsB,MACAmrB,EAAAgB,EAAAhB,UACAiB,EAAAD,EAAApC,OACAA,OAAA9d,IAAAmgB,EAAA,OAAAA,EAEAL,GADAI,EAAAxG,WACAwG,EAAAJ,MAEAX,GADAe,EAAAjB,aACAiB,EAAAf,mBAEAjE,GADAgF,EAAAnB,WACAmB,EAAAhF,aACArqB,EAAAqvB,EAAArvB,MAEAuvB,GADAF,EAAAnC,YACAmC,EAAAE,aAEAnC,GADAiC,EAAA1G,MACoB0E,IAAwBgC,EAAA,uLAE5CxB,EAAsBC,IAAUpF,EAAA,QAAAA,EAAA,SAAAuE,EAAAtpB,IAAAyrB,EAAA,IAAkF1G,EAAA,gBAAAuG,EAAAG,IAClHI,EAAwBzB,IAAQ,GAAG7qB,GAOnC,OANAmrB,IACAmB,EAAAhsB,MAAA6qB,GAEAC,IACAkB,EAAAC,YAAAnB,GAEWd,EAAA5Z,EAAKhU,cAChB,MACMmuB,IAAQ,GAAGX,EAAA,CACjBzpB,UAAAkqB,EACA3qB,MAAAssB,IAEMhC,EAAA5Z,EAAKhU,cACX,MACA,CAAS+D,UAAA+kB,EAAA,cACT6G,GAEM/B,EAAA5Z,EAAKhU,cACX,MACA,CAAS+D,UAAA+kB,EAAA,cACT3lB,KAAAisB,kBAEMxB,EAAA5Z,EAAKhU,cACX,MACA,CAAS+D,UAAA+kB,EAAA,iBACD8E,EAAA5Z,EAAKhU,cACb,MACA,CAAW+D,UAAA+kB,EAAA,eACX1oB,GAEAqqB,GAAuBmD,EAAA5Z,EAAKhU,cAC5B,MACA,CAAW+D,UAAA+kB,EAAA,qBACX2B,MAMA/C,EAvIQ,CAwINkG,EAAA5Z,EAAKhR,WAEPmsB,EAAIntB,UAAA,CACJ+B,UAAa4qB,EAAA3a,EAAS7R,OACtB2mB,UAAa6F,EAAA3a,EAAS7R,OACtBmB,MAASqrB,EAAA3a,EAASrO,OAClB6oB,aAAgBG,EAAA3a,EAASrO,OACzB8oB,UAAaE,EAAA3a,EAAS6a,UAAA,CAAYF,EAAA3a,EAASkV,OAASyF,EAAA3a,EAAS7R,SAC7DkrB,OAAUsB,EAAA3a,EAAS7R,OACnB8mB,WAAc0F,EAAA3a,EAAS7R,OACvBktB,KAAQV,EAAA3a,EAAS+a,KACjBL,kBAAqBC,EAAA3a,EAAS6a,UAAA,CAAYF,EAAA3a,EAASkV,OAASyF,EAAA3a,EAAS7R,SACrEmsB,WAAcK,EAAA3a,EAAS7R,OACvBsoB,YAAekE,EAAA3a,EAAS4a,IACxBxuB,MAASuuB,EAAA3a,EAAS4a,IAClBtB,YAAeqB,EAAA3a,EAAS6a,UAAA,CAAYF,EAAA3a,EAAS8a,KAAOH,EAAA3a,EAASpO,OAC7D+pB,YAAehB,EAAA3a,EAAS4a,IACxB7F,MAAS4F,EAAA3a,EAAS9R,MAAA,CAClBmV,OAAYsX,EAAA3a,EAAS+a,KACrBpW,MAAWgW,EAAA3a,EAAS+a,QAGL,IAAAe,EAAA,EC3KfzwB,EAAA+T,EAAA2c,EAAA,yBAAAD,IAGAd,EAAKtH,KAAQoI,EAGEC,EAAA","file":"component---web-pages-train-tsx-9a963d99e1f8467b717d.js","sourcesContent":["import '@babel/polyfill';\nimport styled from 'styled-components';\n\n// The Button from the last section without the interpolations\nexport const ColoredText = styled.div`\n    font-weight: bold;\n    color: #1890ff;\n    display: inline-block;\n    text-decoration: none;\n    background-image: linear-gradient(to right, #1890ff 25%, #c4ce35 50%, #ac24e2 75%, #1890ff 100%);\n    -webkit-text-fill-color: transparent;\n    -webkit-background-clip: text;\n    background-clip: text;\n    background-size: 300% auto;\n    &.static {\n        background-position: -215% center;\n    }\n    &.animated {\n        @keyframes text-gradient {\n            to {\n                background-position: -300% center;\n            }\n        }\n        animation: text-gradient 16s ease-in-out infinite;\n    }\n`;\n\nexport const Logo = ColoredText.extend`\n    text-align: center;\n    font-size: 19px;\n`;\n","import * as React from 'react';\nimport Helmet from 'react-helmet';\n\nexport default function DefaultHeader() {\n    return (\n        <Helmet\n            key=\"helmet\"\n            title=\"Aida\"\n            meta={[\n                { name: 'description', content: 'Build amazing conversational experiences' },\n                {\n                    content:\n                        'aida, chatito, chatbots, ai chatbots, nlu, nlp, natural language processing, tensorflowjs, keras, named entity recognition, text classification',\n                    name: 'keywords'\n                }\n            ]}\n        >\n            <link rel=\"shortcut icon\" href=\"/favicon.ico\" />\n            <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\" />\n            <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/favicon-32x32.png\" />\n            <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/favicon-16x16.png\" />\n            <link rel=\"manifest\" href=\"/site.webmanifest\" />\n            <link rel=\"mask-icon\" href=\"/safari-pinned-tab.svg\" color=\"#5bbad5\" />\n            <meta name=\"msapplication-TileColor\" content=\"#da532c\" />\n            <meta name=\"theme-color\" content=\"#fcfcfc\" />\n            <meta name=\"viewport\" content=\"initial-scale=1.0, width=device-width\" />\n        </Helmet>\n    );\n}\n","const preferDefault = m => (m && m.default) || m\n\nif (process.env.BUILD_STAGE === `develop`) {\n  module.exports = preferDefault(require(`./public-page-renderer-dev`))\n} else if (process.env.BUILD_STAGE === `build-javascript`) {\n  module.exports = preferDefault(require(`./public-page-renderer-prod`))\n} else {\n  module.exports = () => null\n}\n","import React from \"react\"\nimport PropTypes from \"prop-types\"\n\nimport InternalPageRenderer from \"./page-renderer\"\nimport loader from \"./loader\"\n\nconst ProdPageRenderer = ({ location }) => {\n  const pageResources = loader.getResourcesForPathnameSync(location.pathname)\n  return React.createElement(InternalPageRenderer, {\n    location,\n    pageResources,\n    ...pageResources.json,\n  })\n}\n\nProdPageRenderer.propTypes = {\n  location: PropTypes.shape({\n    pathname: PropTypes.string.isRequired,\n  }).isRequired,\n}\n\nexport default ProdPageRenderer\n","import '@babel/polyfill';\nimport { Icon, Layout, Menu } from 'antd';\nimport Link from 'gatsby-link';\nimport * as React from 'react';\nimport styled from 'styled-components';\nimport { Logo } from './Logo';\n\nconst { Header, Content, Footer } = Layout;\n\nconst overviewRouteRE = /^\\/overview(\\/.*)?$/i;\nconst demoRouteRE = /^\\/demo(\\/.*)?$/i;\nconst trainRouteRE = /^\\/train(\\/.*)?$/i;\n\nconst StyledContent = styled(Content)`\n    > p {\n        text-align: justify;\n    }\n    background: #fcfcfc;\n    padding: 48px 48px 48px 72px;\n    min-height: 280px;\n`;\n\nexport default class MainLayout extends React.Component<any, {}> {\n    public render() {\n        let defaultSelectedKeys = '-1';\n        if (overviewRouteRE.test(this.props.location.pathname)) {\n            defaultSelectedKeys = '0';\n        } else if (demoRouteRE.test(this.props.location.pathname)) {\n            defaultSelectedKeys = '1';\n        } else if (trainRouteRE.test(this.props.location.pathname)) {\n            defaultSelectedKeys = '2';\n        }\n        return (\n            <Layout style={{ minHeight: '100vh' }}>\n                <Header style={{ background: '#fcfcfc', padding: 0, display: 'flex' }}>\n                    <Logo style={{ textAlign: 'right', width: 200, paddingLeft: 24, paddingRight: 24 }} className=\"static\">\n                        <Link to=\"/\">{`< Aida />`}</Link>\n                    </Logo>\n                    <div style={{ flex: 1 }} />\n                    <div style={{ padding: '0 48px 0 24px', display: 'inline-block', textAlign: 'right', float: 'right' }}>\n                        <a href=\"https://github.com/rodrigopivi/aida\" title=\"Aida\" style={{ fontSize: 26 }}>\n                            <Icon type=\"github\" />\n                        </a>\n                    </div>\n                </Header>\n                <Layout style={{ flexDirection: 'row' }}>\n                    <Layout.Sider width={200} breakpoint=\"lg\" collapsedWidth=\"0\" theme=\"light\" style={{ backgroundColor: '#fcfcfc' }}>\n                        <Menu theme=\"light\" mode=\"inline\" defaultSelectedKeys={[defaultSelectedKeys]} style={{ background: '#fcfcfc' }}>\n                            <Menu.Item key=\"0\">\n                                <Link to=\"/overview\">\n                                    <Icon type=\"right-circle-o\" />\n                                    Overview\n                                </Link>\n                            </Menu.Item>\n                            <Menu.Item key=\"1\">\n                                <Link to=\"/demo\">\n                                    <Icon type=\"right-circle-o\" />\n                                    Demo\n                                </Link>\n                            </Menu.Item>\n                            <Menu.Item key=\"2\">\n                                <Link to=\"/train\">\n                                    <Icon type=\"right-circle-o\" />\n                                    Train your own\n                                </Link>\n                            </Menu.Item>\n                        </Menu>\n                    </Layout.Sider>\n                    <Layout style={{ padding: '24px 0 0 24px' }}>\n                        <StyledContent>{this.props.children}</StyledContent>\n                        <Footer style={{ textAlign: 'center' }}>Aida  2018 Rodrigo Pimentel</Footer>\n                    </Layout>\n                </Layout>\n            </Layout>\n        );\n    }\n}\n","import React from \"react\"\nimport PropTypes from \"prop-types\"\nimport Link, {\n  withPrefix,\n  navigate,\n  push,\n  replace,\n  navigateTo,\n} from \"gatsby-link\"\nimport { waitForRouteChange } from \"./wait-for-route-change\"\nimport PageRenderer from \"./public-page-renderer\"\nimport parsePath from \"./parse-path\"\n\nconst StaticQueryContext = React.createContext({})\n\nconst StaticQuery = props => (\n  <StaticQueryContext.Consumer>\n    {staticQueryData => {\n      if (\n        props.data ||\n        (staticQueryData[props.query] && staticQueryData[props.query].data)\n      ) {\n        return (props.render || props.children)(\n          props.data ? props.data.data : staticQueryData[props.query].data\n        )\n      } else {\n        return <div>Loading (StaticQuery)</div>\n      }\n    }}\n  </StaticQueryContext.Consumer>\n)\n\nStaticQuery.propTypes = {\n  data: PropTypes.object,\n  query: PropTypes.string.isRequired,\n  render: PropTypes.func,\n  children: PropTypes.func,\n}\n\nfunction graphql() {\n  throw new Error(\n    `It appears like Gatsby is misconfigured. Gatsby related \\`graphql\\` calls ` +\n      `are supposed to only be evaluated at compile time, and then compiled away,. ` +\n      `Unfortunately, something went wrong and the query was left in the compiled code.\\n\\n.` +\n      `Unless your site has a complex or custom babel/Gatsby configuration this is likely a bug in Gatsby.`\n  )\n}\n\nexport {\n  Link,\n  withPrefix,\n  graphql,\n  parsePath,\n  navigate,\n  push, // TODO replace for v3\n  replace, // TODO remove replace for v3\n  navigateTo, // TODO: remove navigateTo for v3\n  StaticQueryContext,\n  StaticQuery,\n  PageRenderer,\n  waitForRouteChange,\n}\n","import * as tf from '@tensorflow/tfjs';\nimport englishTokenizer from '../../languages/en/EnglishTokenizer';\nimport spanishTokenizer from '../../languages/es/SpanishTokenizer';\nimport * as types from '../../types';\nimport { EmbeddingsModel } from './embeddings/EmbeddingsModel';\nimport ClassificationModel from './models/classification';\nimport NerModel from './models/ner';\n\nfunction getTokenizer(language: 'en' | 'es') {\n    const lang = language ? language.toLowerCase() : language;\n    if (lang === 'en') {\n        return englishTokenizer;\n    } else if (lang === 'es') {\n        return spanishTokenizer;\n    }\n    throw new Error(\"Invalid config language. Only 'en' and 'es' are supported.\");\n}\n\nexport const defaultPipelineDefinition: types.IPipelineDefinition = {\n    config: {\n        classification: {\n            epochs: 5,\n            filterSizes: [2, 4, 8],\n            lowConfidenceThreshold: 0.3,\n            numFilters: 128\n        },\n        default: {\n            // NOTE Using batch size of 50 because on windows higher batch sizes tend to exit with\n            // lost context error, on a Mac a batchSize of 70-100 works just fine and trains faster.\n            // Reference TF.js issue: https://github.com/tensorflow/tfjs/issues/263\n            batchSize: 120,\n            drop: 0.5,\n            embeddingDimensions: 300,\n            lossThresholdToStopTraining: 1e-6,\n            maxNgrams: 20,\n            trainingValidationSplit: 0.3\n        },\n        ner: {\n            addAttention: true,\n            epochs: 5,\n            lowConfidenceThreshold: 0.2,\n            numFilters: [128, 128],\n            rnnUnits: 100,\n        }\n    }\n};\nexport class AidaPipeline {\n    private pipelineDefinition: types.IPipelineDefinition = defaultPipelineDefinition;\n    private datasetParams: types.IDatasetParams;\n    private embeddingsModel: EmbeddingsModel;\n    private classificationModel: ClassificationModel;\n    private nerModel: NerModel;\n    private logger: types.IPipelineModelLogger;\n    private tokenizer: types.IAidaTokenizer;\n\n    constructor(cfg: {\n        datasetParams: types.IDatasetParams;\n        logger: types.IPipelineModelLogger;\n        ngramToIdDictionary: { [key: string]: number };\n        trainStatsHandler?: types.ITrainStatsHandler;\n        pipelineDefinition?: types.IPipelineDefinition;\n        pretrainedClassifier?: tf.Model;\n        pretrainedNer?: tf.Model;\n        pretrainedEmbedding?: tf.Model;\n        pretrainedNGramVectors?: types.PretrainedDict;\n    }) {\n        if (cfg.pipelineDefinition) {\n            this.pipelineDefinition = cfg.pipelineDefinition;\n        }\n        this.datasetParams = cfg.datasetParams;\n        this.logger = cfg.logger;\n        this.tokenizer = getTokenizer(this.datasetParams.language);\n        this.embeddingsModel = new EmbeddingsModel(\n            cfg.ngramToIdDictionary,\n            cfg.datasetParams.maxWordsPerSentence,\n            this.pipelineDefinition.config.default.maxNgrams,\n            this.pipelineDefinition.config.default.embeddingDimensions,\n            this.tokenizer,\n            cfg.pretrainedEmbedding,\n            cfg.pretrainedNGramVectors\n        );\n        const classificationCfg = Object.assign({}, this.pipelineDefinition.config.default, this.pipelineDefinition.config.classification);\n        let classificationTrainStatsHandler;\n        let nerTrainStatsHandler;\n        if (cfg.trainStatsHandler) {\n            classificationTrainStatsHandler = cfg.trainStatsHandler.classification;\n            nerTrainStatsHandler = cfg.trainStatsHandler.ner;\n        }\n        this.classificationModel = new ClassificationModel(\n            classificationCfg,\n            this.datasetParams,\n            this.embeddingsModel,\n            this.logger,\n            cfg.pretrainedClassifier,\n            classificationTrainStatsHandler\n        );\n        const nerCfg = Object.assign({}, this.pipelineDefinition.config.default, this.pipelineDefinition.config.ner);\n        this.nerModel = new NerModel(\n            nerCfg,\n            this.datasetParams,\n            this.embeddingsModel,\n            this.logger,\n            cfg.pretrainedNer,\n            nerTrainStatsHandler\n        );\n    }\n\n    public train = async (trainDataset: types.ITrainingParams): Promise<void> => {\n        this.logger.log('START TRAINING PIPELINE MODELS!');\n        this.logger.log('==================================================================================================');\n        await this.classificationModel.train(trainDataset);\n        await this.nerModel.train(trainDataset);\n        this.logger.log('FINISHED TRAINING PIPELINE MODELS!');\n        this.logger.log('==================================================================================================');\n    };\n\n    public test = async (testDataset: types.ITestingParams) => {\n        this.logger.log('START TESTING PIPELINE MODELS!');\n        this.logger.log('==================================================================================================');\n        const classificationStats = await this.classificationModel.test(testDataset);\n        const nerStats = await this.nerModel.test(testDataset);\n        return { classificationStats, nerStats };\n    };\n\n    public predict = (sentences: string[]) => {\n        const classification = this.classificationModel.predict(sentences);\n        const ner = this.nerModel.predict(sentences, classification);\n        return { classification, ner };\n    };\n\n    public save = async (cfg: { classificationPath: string; nerPath: string; embeddingPath: string }) => {\n        this.logger.log('SAVING PIPELINE MODELS!');\n        this.logger.log('==================================================================================================');\n        await this.classificationModel.tfModel().save(cfg.classificationPath);\n        await this.nerModel.tfModel().save(cfg.nerPath);\n        await this.embeddingsModel.tfModel().save(cfg.embeddingPath);\n    };\n}\n","import { IAidaTokenizer } from '../../types';\n\n// TODO: use fancier tokenizer, better split of words, better joining of sentences\nclass EnglishTokenizer implements IAidaTokenizer {\n    // list of valid characters used for the dictionary, any word with a char that is not listed here will be skip\n    public FILTER_CHARS_REGEXP = /[^a-z0-9\\.,\\?\\'\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~ ]/gi;\n    // list of charaters that act as word splitters (includes space)\n    public WORD_SEPARATORS_REGEXP = /([\\ \\.\\,\\%\\*\\-\\=\\+\\;\\|\\`\\~])/g;\n    // regexp that detect if a word contains non alphanumeric characters\n    public NON_ALPHANUMERIC_REGEXP = /[^a-z0-9]/gi;\n    // when ngram is unkown, replace it with this string listed at the dictionary\n    public UNKNOWN_NGRAM_KEY = '__';\n    // fastText doesn't contain numbers, so we use the sane embeddings for the number words\n    public NUMBERS_MAP: { [key: string]: string } = {\n        // tslint:disable:object-literal-sort-keys\n        zero: '0',\n        one: '1',\n        two: '2',\n        three: '3',\n        four: '4',\n        five: '5',\n        six: '6',\n        seven: '7',\n        eight: '8',\n        nine: '9'\n        // tslint:enable:object-literal-sort-keys\n    };\n\n    public sanitizeSentence = (sentence: string): string => {\n        return sentence\n            .trim()\n            .toLowerCase()\n            .replace(this.FILTER_CHARS_REGEXP, '');\n    };\n\n    public splitSentenceToWords = (sentence: string): string[] => {\n        return this.sanitizeSentence(sentence)\n            .split(this.WORD_SEPARATORS_REGEXP)\n            .map(w => w.trim())\n            .filter(w => !!w);\n    };\n\n    public splitWordToBiGrams = (word: string): string[] => {\n        const ngram = 2;\n        const grams: string[] = [];\n        let index = word.length - ngram + 1;\n        if (index < 1) {\n            return grams;\n        }\n        while (index--) {\n            grams[index] = word.substr(index, ngram);\n        }\n        return grams;\n    };\n    public joinWordsToSentence = (words: string[]): string => words.join(' ');\n}\nexport default new EnglishTokenizer();\n","import { IAidaTokenizer } from '../../types';\n\n// TODO: use fancier tokenizer, better split of words, better joining of sentences\nclass SpanishTokenizer implements IAidaTokenizer {\n    // list of valid characters used for the dictionary, any word with a char that is not listed here will be skip\n    public FILTER_CHARS_REGEXP = /[^abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ 0-9\\.,\\?\\'\"!@#\\$%\\^&\\*\\(\\)-_=\\+;:<>\\/\\\\\\|\\}\\{\\[\\]`~]/g;\n    // list of charaters that act as word splitters (includes space)\n    public WORD_SEPARATORS_REGEXP = /([\\ \\.\\,\\%\\*\\-\\=\\+\\;\\|\\`\\~])/g;\n    // regexp that detect if a word contains non alphanumeric characters\n    public NON_ALPHANUMERIC_REGEXP = /[^abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0-9]/g;\n    // when ngram is unkown, replace it with this string listed at the dictionary\n    public UNKNOWN_NGRAM_KEY = '__';\n    // fastText doesn't contain numbers, so we use the sane embeddings for the number words\n    public NUMBERS_MAP: { [key: string]: string } = {\n        // tslint:disable:object-literal-sort-keys\n        cero: '0',\n        uno: '1',\n        dos: '2',\n        tres: '3',\n        cuatro: '4',\n        cinco: '5',\n        seis: '6',\n        siete: '7',\n        ocho: '8',\n        nueve: '9'\n        // tslint:enable:object-literal-sort-keys\n    };\n\n    public sanitizeSentence = (sentence: string): string => {\n        return sentence\n            .trim()\n            .toLowerCase()\n            .replace(this.FILTER_CHARS_REGEXP, '');\n    };\n\n    public splitSentenceToWords = (sentence: string): string[] => {\n        return this.sanitizeSentence(sentence)\n            .split(this.WORD_SEPARATORS_REGEXP)\n            .map(w => w.trim())\n            .filter(w => !!w);\n    };\n\n    public splitWordToBiGrams = (word: string): string[] => {\n        const ngram = 3;\n        const grams: string[] = [];\n        let index = word.length - ngram + 1;\n        if (index < 1) {\n            return grams;\n        }\n        while (index--) {\n            grams[index] = word.substr(index, ngram);\n        }\n        return grams;\n    };\n\n    public joinWordsToSentence = (words: string[]): string => words.join(' ');\n}\n\nexport default new SpanishTokenizer();\n","import * as tf from '@tensorflow/tfjs';\nimport * as types from '../../../types';\nimport { CombineNgramsLayer } from './CombineNgramsLayer';\nimport { PreSavedEmbeddingsInitializer } from './PreSavedEmbeddingsInitializer';\n\nexport class EmbeddingsModel {\n    public static setupModel(\n        pretrainedNGramVectors: types.PretrainedDict,\n        maxWords: number,\n        maxNgrams: number,\n        embeddingDimensions: number\n    ) {\n        const model = tf.sequential();\n        const embedLayer = tf.layers.embedding({\n            embeddingsInitializer: new PreSavedEmbeddingsInitializer({\n                embeddingDimensions,\n                pretrainedNGramVectors\n            }),\n            inputDim: pretrainedNGramVectors.size,\n            inputLength: [maxNgrams],\n            maskZero: true,\n            outputDim: embeddingDimensions,\n            trainable: false\n        });\n        model.add(tf.layers.timeDistributed({ layer: embedLayer, inputShape: [maxWords, maxNgrams] }));\n        model.add(new CombineNgramsLayer({}));\n        return model;\n    }\n\n    public tokenizer: types.IAidaTokenizer;\n\n    private ngramToIdDictionary: { [key: string]: number };\n    private maxWords: number;\n    private maxNgrams: number;\n    private embeddingDimensions: number;\n    private model: tf.Model;\n    private inputModel: tf.Model | null = null;\n\n    constructor(\n        ngramToIdDictionary: { [key: string]: number },\n        maxWords: number,\n        maxNgrams: number,\n        embeddingDimensions: number,\n        tokenizer: types.IAidaTokenizer,\n        pretrainedEmbeddingModel?: tf.Model,\n        pretrainedNGramVectors?: types.PretrainedDict\n    ) {\n        this.ngramToIdDictionary = ngramToIdDictionary;\n        this.maxWords = maxWords;\n        this.maxNgrams = maxNgrams;\n        this.embeddingDimensions = embeddingDimensions;\n        this.model = pretrainedEmbeddingModel\n            ? pretrainedEmbeddingModel\n            : EmbeddingsModel.setupModel(pretrainedNGramVectors || new Map(), this.maxWords, this.maxNgrams, this.embeddingDimensions);\n        this.tokenizer = tokenizer;\n    }\n\n    public tfModel = () => this.model;\n\n    public modelInput = () => {\n        if (!this.inputModel) {\n            const input = tf.layers.input({ shape: [this.maxWords, this.maxNgrams], dtype: 'int32' });\n            const embedded = this.model.apply(input) as tf.SymbolicTensor;\n            this.inputModel = tf.model({ inputs: input, outputs: embedded });\n        }\n        return this.inputModel;\n    };\n\n    // Embeds by word bigrams\n    public embed = (sentences: string[]) => {\n        return tf.tidy(() => {\n            const sentencesTensor = this.sentencesToWordIds(sentences);\n            const output = this.modelInput().predictOnBatch(sentencesTensor) as tf.Tensor<tf.Rank.R3>;\n            sentencesTensor.dispose();\n            return output;\n        });\n    };\n\n    public dictionary = () => this.ngramToIdDictionary;\n\n    private sentencesToWordIds = (sentences: string[]) => {\n        return tf.tidy(() => {\n            const sentencesSplittedByWords = sentences.map(s => this.tokenizer.splitSentenceToWords(s));\n            const buffer = tf.buffer([sentences.length, this.maxWords, this.maxNgrams], 'int32') as tf.TensorBuffer<tf.Rank.R3>;\n            sentencesSplittedByWords.forEach((s, sentenceIndex) => {\n                s.forEach((w: string, wordIndex: number) => {\n                    if (this.ngramToIdDictionary[w] !== undefined) {\n                        // use the word dictionary\n                        buffer.set(this.ngramToIdDictionary[w], sentenceIndex, wordIndex, 0);\n                    } else if (w.length) {\n                        this.generateWordIdsFromNGrams(w).forEach((gram, gramIndex) => {\n                            if (gramIndex > this.maxNgrams) {\n                                // tslint:disable-next-line:no-console\n                                console.warn('Word exceeding max n grams per word: ', w);\n                                return;\n                            }\n                            buffer.set(gram, sentenceIndex, wordIndex, gramIndex);\n                        });\n                    }\n                });\n            });\n            return buffer.toTensor();\n        });\n    };\n\n    private generateWordIdsFromNGrams = (word: string): number[] => {\n        let vecIds: number[] = [];\n        const addToVecsIfNotUndefined = (k: string) => {\n            if (this.ngramToIdDictionary[k] === undefined) {\n                return false;\n            }\n            vecIds.push(this.ngramToIdDictionary[k]);\n            return true;\n        };\n        // first try using ngrams to reconstruct the word vector\n        if (word.length > 2) {\n            let allNgramsFound = true;\n            const wordNgrams = this.tokenizer.splitWordToBiGrams(word);\n            wordNgrams.forEach(wt => {\n                if (!addToVecsIfNotUndefined(wt) && allNgramsFound) {\n                    allNgramsFound = false;\n                }\n            });\n            if (allNgramsFound) {\n                return vecIds;\n            }\n        }\n        // if not by ngrams use characters to construct the word vector\n        vecIds = [];\n        // TODO: use characters to construct ngrams, not the word\n        word.split('').forEach(addToVecsIfNotUndefined);\n        return vecIds;\n    };\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { l2Normalize } from '@tensorflow/tfjs-layers/dist/losses';\n\n// given an imput composed of max_ngrams x 300d this layer will sum\n// and normalize all the max_ngrams to get a unique 300d vector representation\nexport class CombineNgramsLayer extends tf.layers.Layer {\n    public static className = 'CombineNgramsLayer';\n    public className = CombineNgramsLayer.className;\n    // The output shape removes the ngram dimension\n    public computeOutputShape(inputShape: number[]) {\n        return [inputShape[0], inputShape[1], inputShape[inputShape.length - 1]];\n    }\n    public call(inputs: tf.Tensor, kwargs: any) {\n        return tf.tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const combined = tf.sum(inputs, 2);\n            const output = l2Normalize(combined, 2);\n            combined.dispose();\n            return output;\n        });\n    }\n}\n\ntf.serialization.SerializationMap.register(CombineNgramsLayer);\n","import * as tf from '@tensorflow/tfjs';\nimport * as initializers from '@tensorflow/tfjs-layers/dist/initializers';\nimport { flatMapDeep } from 'lodash';\n\nexport interface IEmbeddingsModelConfig {\n    pretrainedNGramVectors: Map<string, Float32Array>;\n    embeddingDimensions: number;\n}\n\nexport class PreSavedEmbeddingsInitializer extends initializers.Initializer {\n    public static className = 'PreSavedEmbeddingsInitializer';\n    public config: IEmbeddingsModelConfig;\n    public className = PreSavedEmbeddingsInitializer.className;\n    constructor(config: IEmbeddingsModelConfig) {\n        super();\n        this.config = config;\n    }\n    public apply(shape: tf.Shape, dtype: tf.DataType): tf.Tensor {\n        if (!this.config || !this.config.pretrainedNGramVectors) {\n            return tf.zeros(shape, dtype);\n        }\n        return tf.tidy(() => {\n            const flatMat = flatMapDeep([...this.config.pretrainedNGramVectors.values()]);\n            return tf.tensor2d(flatMat, [this.config.pretrainedNGramVectors.size, this.config.embeddingDimensions], 'float32');\n        });\n    }\n\n    public getConfig() {\n        return this.config.pretrainedNGramVectors as any;\n    }\n}\ntf.serialization.SerializationMap.register(PreSavedEmbeddingsInitializer);\n","import * as tf from '@tensorflow/tfjs';\nimport { chunk } from 'lodash';\nimport * as types from '../../../types';\nimport { EmbeddingsModel } from '../embeddings/EmbeddingsModel';\n\nexport default class ClassificationModel extends types.PipelineModel implements types.IPipelineModel {\n    private static setup(\n        config: types.IClassificationModelParams & types.IDefaultModelParams,\n        { maxWordsPerSentence: maxWords, intents }: types.IDatasetParams\n    ) {\n        const numClasses = intents.length;\n        const LEARNING_RATE = 0.0066; // use 1e-4 as default as alternative starting point\n        const ADAM_BETA_1 = 0.0025;\n        const ADAM_BETA_2 = 0.1;\n        const optimizer = tf.train.adam(LEARNING_RATE, ADAM_BETA_1, ADAM_BETA_2);\n        // Layer 1: Convolution + max pool\n        const input = tf.input({\n            dtype: 'float32', shape: [maxWords, config.embeddingDimensions], name: 'embedded_words'\n        });\n        const convLayer1 = tf.layers\n            .conv1d({\n                activation: 'relu',\n                filters: config.numFilters,\n                inputShape: [maxWords, config.embeddingDimensions],\n                kernelInitializer: 'randomNormal',\n                kernelSize: [config.filterSizes[0]],\n                name: 'classConv1',\n                padding: 'valid'\n            })\n            .apply(input);\n        const maxpool1 = tf.layers\n            .maxPooling1d({\n                padding: 'valid',\n                poolSize: maxWords - config.filterSizes[0] + 1\n            })\n            .apply(convLayer1) as tf.SymbolicTensor;\n        // Layer 2: Convolution + max pool\n        const convLayer2 = tf.layers\n            .conv1d({\n                activation: 'relu',\n                filters: config.numFilters,\n                inputShape: [maxWords, config.embeddingDimensions],\n                kernelInitializer: 'randomNormal',\n                kernelSize: [config.filterSizes[1]],\n                name: 'classConv2',\n                padding: 'valid'\n            })\n            .apply(input);\n        const maxpool2 = tf.layers\n            .maxPooling1d({\n                padding: 'valid',\n                poolSize: maxWords - config.filterSizes[1] + 1\n            })\n            .apply(convLayer2) as tf.SymbolicTensor;\n        // Layer 3: Convolution + max pool\n        const convLayer3 = tf.layers\n            .conv1d({\n                activation: 'relu',\n                filters: config.numFilters,\n                inputShape: [maxWords, config.embeddingDimensions],\n                kernelInitializer: 'randomNormal',\n                kernelSize: [config.filterSizes[2]],\n                name: 'classConv3',\n                padding: 'valid'\n            })\n            .apply(input);\n        const maxpool3 = tf.layers\n            .maxPooling1d({\n                padding: 'valid',\n                poolSize: maxWords - config.filterSizes[2] + 1\n            })\n            .apply(convLayer3) as tf.SymbolicTensor;\n        // Concatenation of all CNN layers on different levels and apply a fully connected dense layer\n        const concatLayer = tf.layers.concatenate({ axis: 1 }).apply([maxpool1, maxpool2, maxpool3]);\n        const flat = tf.layers.flatten().apply(concatLayer);\n        const dropOut = tf.layers.dropout({ rate: config.drop }).apply(flat) as tf.SymbolicTensor;\n        const flatPool1 = tf.layers.flatten().apply(maxpool1) as tf.SymbolicTensor;\n        const concatForClassification = tf.layers.concatenate({ axis: 1 }).apply([dropOut, flatPool1]);\n        const outClassification = tf.layers\n            .dense({\n                activation: 'softmax',\n                units: numClasses\n            })\n            .apply(concatForClassification) as tf.SymbolicTensor;\n        const model = tf.model({ inputs: input, outputs: outClassification });\n        model.compile({\n            loss: 'categoricalCrossentropy',\n            metrics: ['accuracy'],\n            optimizer\n        });\n        return model;\n    }\n\n    private config: types.IClassificationModelParams & types.IDefaultModelParams;\n    private datasetParams: types.IDatasetParams;\n    private model: tf.Model;\n    private embeddingsModel: EmbeddingsModel;\n    private logger: types.IPipelineModelLogger;\n    private classificationTrainStatsHandler: types.ITrainStatsHandler['classification'] | undefined;\n    constructor(\n        config: types.IClassificationModelParams & types.IDefaultModelParams,\n        datasetParams: types.IDatasetParams,\n        embeddingsModel: EmbeddingsModel,\n        logger: types.IPipelineModelLogger,\n        pretrainedModel?: tf.Model,\n        classificationTrainStatsHandler?: types.ITrainStatsHandler['classification']\n    ) {\n        super();\n        this.config = config;\n        this.datasetParams = datasetParams;\n        this.embeddingsModel = embeddingsModel;\n        this.model = pretrainedModel ? pretrainedModel : ClassificationModel.setup(this.config, this.datasetParams);\n        this.logger = logger;\n        this.classificationTrainStatsHandler = classificationTrainStatsHandler;\n    }\n\n    public tfModel = () => this.model;\n\n    public predict = (sentences: string[]): types.IClassificationPred[] => {\n        const prediction = [] as types.IClassificationPred[];\n        tf.tidy(() => {\n            const embeddedSentences = this.embeddingsModel.embed(sentences);\n            const output = this.model.predict(embeddedSentences) as tf.Tensor<tf.Rank>;\n            const d = output.dataSync() as Float32Array;\n            output.dispose();\n            embeddedSentences.dispose();\n            const intents = this.datasetParams.intents;\n            sentences.forEach((s, i) => {\n                const preds = d.slice(i * intents.length, i * intents.length + intents.length);\n                const sentencePreds: types.IClassificationPred[] = [];\n                preds.forEach((p, idx) =>\n                    sentencePreds.push({\n                        confidence: p,\n                        intent: intents[idx],\n                        sentence: s\n                    })\n                );\n                sentencePreds.sort((a: any, b: any) => (a.confidence > b.confidence ? -1 : 1));\n                prediction.push(sentencePreds[0]);\n            });\n        });\n        return prediction;\n    };\n\n    public train = async (trainDataset: types.ITrainingParams): Promise<void> => {\n        const trainYChunks = chunk(trainDataset.trainY, this.config.batchSize);\n        const trainXChunks = chunk(trainDataset.trainX, this.config.batchSize);\n        this.logger.log('Start training classification model!');\n        const m = this.model;\n        let enoughAccuracyReached = false;\n        for (const [index, xChunk] of trainXChunks.entries()) {\n            if (enoughAccuracyReached) {\n                return;\n            }\n            const embeddedSentences = this.embeddingsModel.embed(xChunk);\n            const dataLabels = tf.tensor1d(trainYChunks[index], 'int32');\n            const hotEncodedLabels = tf.oneHot(dataLabels, this.datasetParams.intents.length);\n            await m.fit(embeddedSentences, hotEncodedLabels, {\n                // batchSize: this.config.batchSize,\n                callbacks: { onBatchEnd: tf.nextFrame },\n                epochs: this.config.epochs,\n                shuffle: true,\n                validationSplit: this.config.trainingValidationSplit\n            });\n            dataLabels.dispose();\n            embeddedSentences.dispose();\n            hotEncodedLabels.dispose();\n            const h = m.history.history;\n            const c = h.val_loss.length - 1;\n            if (this.classificationTrainStatsHandler) {\n                this.classificationTrainStatsHandler({\n                    batch: index + 1,\n                    batchEpochs: m.history.epoch.length,\n                    currentBatchSize: trainXChunks[index].length,\n                    tensorsInMemory: tf.memory().numTensors,\n                    totalBatches: trainXChunks.length,\n                    trainingAccuracy: h.acc[c],\n                    trainingLoss: h.loss[c],\n                    validationAccuracy: h.val_acc[c],\n                    validationLoss: h.val_loss[c]\n                });\n            }\n            this.logger.log(`Trained ${m.history.epoch.length} epochs on batch ${index + 1} of ${trainXChunks.length}`);\n            this.logger.log(`Training Loss: ${h.loss[c]} | Training Accuracy: ${h.acc[c]}`);\n            this.logger.log(`Validation Loss: ${h.val_loss[c]} | Validation Accuracy: ${h.val_acc[c]}`);\n            this.logger.warn(`(Memory) Number of tensors in memory at the end of batch: ${tf.memory().numTensors}`);\n            this.logger.log('==================================================================================================');\n            if (\n                this.config.lossThresholdToStopTraining &&\n                h.loss[c] < this.config.lossThresholdToStopTraining &&\n                h.val_loss[c] < this.config.lossThresholdToStopTraining\n            ) {\n                enoughAccuracyReached = true;\n                this.logger.warn(`Enough accuracy reached! Ending training after batch ${index + 1} of ${trainXChunks.length}`);\n                this.logger.log('==================================================================================================');\n            }\n        }\n    };\n\n    public test = async (\n        testExamples: types.ITestingParams,\n        resultsHandler?: types.ITestPredictionsHandler\n    ): Promise<types.IPredictionStats> => {\n        const handler = resultsHandler ? resultsHandler : this.defaultResultsLogger;\n        const stats: types.IPredictionStats = { correct: 0, wrong: 0, lowConfidence: 0 };\n        const x = chunk(testExamples.testX, this.config.batchSize);\n        const y = chunk(testExamples.testY, this.config.batchSize);\n        for (const [i, sentences] of x.entries()) {\n            const predictions = this.predict(sentences);\n            handler(sentences, y[i], predictions, stats);\n        }\n        return stats;\n    };\n\n    private defaultResultsLogger = (\n        x: types.ITestingParams['testX'],\n        y: types.ITestingParams['testY'],\n        o: types.IClassificationPred[],\n        stats: types.IPredictionStats\n    ): types.IPredictionStats => {\n        x.forEach((s, i) => {\n            const intent = this.datasetParams.intents[y[i]];\n            const correct = o[i].intent === intent;\n            if (o[i].confidence < this.config.lowConfidenceThreshold) {\n                if (stats.lowConfidence === undefined) {\n                    return;\n                }\n                stats.lowConfidence++;\n                this.logger.warn(`LOW CONFIDENCE (intent: ${o[i].intent}, confidence: ${o[i].confidence}) - ${s}`);\n            } else if (correct) {\n                stats.correct++;\n                this.logger.debug(`CORRECT (intent: ${o[i].intent}, confidence: ${o[i].confidence}) - ${s}`);\n            } else {\n                stats.wrong++;\n                this.logger.error(`WRONG (intent: ${o[i].intent}, confidence: ${o[i].confidence}) - ${s}`);\n            }\n        });\n        return stats;\n    };\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { chunk, flatMapDeep } from 'lodash';\nimport * as types from '../../../types';\nimport { EmbeddingsModel } from '../embeddings/EmbeddingsModel';\nimport { TimeSeriesAttention } from '../TimeSeriesAttention';\n\nexport default class NerModel extends types.PipelineModel implements types.IPipelineModel {\n    private static setup(config: types.INerModelParams & types.IDefaultModelParams, datasetParams: types.IDatasetParams) {\n        const maxWords = datasetParams.maxWordsPerSentence;\n        const { addAttention, embeddingDimensions, numFilters, rnnUnits } = config;\n        const numSlotTypes = Object.keys(datasetParams.slotsToId).length;\n        const LEARNING_RATE = 0.0066; // use 1e-4 as default as alternative starting point\n        const ADAM_BETA_1 = 0.0025;\n        const ADAM_BETA_2 = 0.1;\n        const optimizer = tf.train.adam(LEARNING_RATE, ADAM_BETA_1, ADAM_BETA_2);\n        // WORD-NGRAMS LEVEL EMBEDDINGS\n        const embeddedSentencesInput = tf.input({\n            dtype: 'float32', shape: [maxWords, embeddingDimensions], name: 'embedded_words'\n        });\n        const convLayer1 = tf.layers\n            .conv1d({\n                activation: 'relu',\n                filters: numFilters[0],\n                inputShape: [maxWords, embeddingDimensions],\n                kernelInitializer: 'randomNormal',\n                kernelSize: 1,\n                name: 'nerConv1',\n                padding: 'valid'\n            })\n            .apply(embeddedSentencesInput) as tf.SymbolicTensor;\n        const convLayer2 = tf.layers\n            .conv1d({\n                activation: 'relu',\n                filters: numFilters[0],\n                kernelInitializer: 'randomNormal',\n                kernelSize: 1,\n                name: 'nerConv2',\n                padding: 'valid'\n            })\n            .apply(convLayer1) as tf.SymbolicTensor;\n        // CONCATENATE BOTH CNN ENCODERS (WORD AND CHAR) WITH THE INPUT AND THE CHAR CNN LAYER 1\n        const classLabelInput = tf.input({\n            dtype: 'float32', shape: [datasetParams.intents.length], name: 'embedded_intent'\n        });\n        const classLabelRepeated = tf.layers.repeatVector({ n: maxWords }).apply(classLabelInput) as tf.SymbolicTensor;\n        const concated = tf.layers.concatenate().apply([\n            classLabelRepeated, embeddedSentencesInput, convLayer2,\n        ]);\n        const biLstm = tf.layers\n            .bidirectional({\n                layer: tf.layers.lstm({ units: rnnUnits, returnSequences: true, name: 'bidi_encoder'}) as tf.RNN\n            })\n            .apply(concated) as tf.SymbolicTensor[];\n        let finalHidden: tf.SymbolicTensor | null = null;\n        if (addAttention) {\n            const timeAttention = new TimeSeriesAttention({ name: 'attention_weight' }).apply(biLstm[0]) as tf.SymbolicTensor;\n            finalHidden = tf.layers.concatenate().apply([timeAttention, biLstm[0], biLstm[1]]) as tf.SymbolicTensor;\n        } else {\n            finalHidden = tf.layers.concatenate().apply([biLstm[0], biLstm[1]]) as tf.SymbolicTensor;\n        }\n        const outputs = tf.layers.dense({ activation: 'softmax', units: numSlotTypes }).apply(finalHidden) as tf.SymbolicTensor;\n        const model = tf.model({ inputs: [classLabelInput, embeddedSentencesInput], outputs });\n        model.compile({ loss: 'categoricalCrossentropy', metrics: ['accuracy'], optimizer });\n        return model;\n    }\n\n    private config: types.INerModelParams & types.IDefaultModelParams;\n    private datasetParams: types.IDatasetParams;\n    private model: tf.Model;\n    private embeddingsModel: EmbeddingsModel;\n    private logger: types.IPipelineModelLogger;\n    private nerTrainStatsHandler: types.ITrainStatsHandler['ner'] | undefined;\n\n    constructor(\n        config: types.INerModelParams & types.IDefaultModelParams,\n        datasetParams: types.IDatasetParams,\n        embeddingsModel: EmbeddingsModel,\n        logger: types.IPipelineModelLogger,\n        pretrainedModel?: tf.Model,\n        nerTrainStatsHandler?: types.ITrainStatsHandler['ner']\n    ) {\n        super();\n        this.config = config;\n        this.datasetParams = datasetParams;\n        this.embeddingsModel = embeddingsModel;\n        this.model = pretrainedModel ? pretrainedModel : NerModel.setup(this.config, this.datasetParams);\n        this.logger = logger;\n        this.nerTrainStatsHandler = nerTrainStatsHandler;\n    }\n\n    public tfModel = () => this.model;\n\n    public rawPrediction = (sentences: string[], classificationPred: types.IClassificationPred[]) => {\n        return tf.tidy(() => {\n            const { maxWordsPerSentence: maxWords, slotsToId } = this.datasetParams;\n            const slotTypesLength = Object.keys(slotsToId).length;\n            const embeddedSentences = this.embeddingsModel.embed(sentences);\n            const encodedIntent = classificationPred.map(p => {\n                const intentEncoded = new Array(this.datasetParams.intents.length).fill(0) as number[];\n                const idx = this.datasetParams.intents.indexOf(p.intent);\n                if (idx !== -1) {\n                    intentEncoded[idx] = 1;\n                }\n                return intentEncoded;\n            });\n            const intentsFlat = flatMapDeep(encodedIntent);\n            const classLabel = tf.tensor2d(intentsFlat, [encodedIntent.length, this.datasetParams.intents.length]);\n            const output = this.model.predict([classLabel, embeddedSentences]) as tf.Tensor<tf.Rank>;\n            const flattenedPredictions = output.dataSync() as Float32Array;\n            output.dispose();\n            classLabel.dispose();\n            embeddedSentences.dispose();\n            // word predictions for each sentence in the form [sentence, word, slots scores]\n            const chunks = chunk(flattenedPredictions, maxWords * slotTypesLength).map(sp => chunk(sp, slotTypesLength));\n            return chunks.map(sentencePreds => {\n                return sentencePreds.map(wordTagPredictions => {\n                    let highestIndex = 0;\n                    let confidence = wordTagPredictions.length ? wordTagPredictions[highestIndex] : 0;\n                    wordTagPredictions.forEach((tp, ti) => {\n                        if (wordTagPredictions[highestIndex] < tp) {\n                            highestIndex = ti;\n                            confidence = tp;\n                        }\n                    });\n                    return { highestIndex, confidence };\n                });\n            });\n        });\n    };\n\n    public predict = (sentences: string[], classificationPred: types.IClassificationPred[]) => {\n        const { lowConfidenceThreshold } = this.config;\n        const { slotsToId } = this.datasetParams;\n        const wordPredictionsChunk = this.rawPrediction(sentences, classificationPred);\n        return sentences.map((s, i) => {\n            const sentenceWordPredictionIds = wordPredictionsChunk[i];\n            const sentenceWords = this.embeddingsModel.tokenizer.splitSentenceToWords(s);\n            return sentenceWords.reduce(\n                (accumulator: types.ISlotReducer, w: string, currentIndex) => {\n                    if (accumulator.current && accumulator.current.confidence === 0) {\n                        accumulator.current.confidence = sentenceWordPredictionIds[currentIndex].confidence;\n                    }\n                    const currentSlotKey = Object.keys(slotsToId).find(\n                        slotKey =>\n                            sentenceWordPredictionIds[currentIndex] &&\n                            slotsToId[slotKey] === sentenceWordPredictionIds[currentIndex].highestIndex\n                    );\n                    if (!currentSlotKey || !accumulator.current) {\n                        return accumulator;\n                    }\n                    if (accumulator.current.key !== currentSlotKey) {\n                        if (\n                            accumulator.current.key &&\n                            accumulator.current.key !== 'O' &&\n                            accumulator.current.confidence >= lowConfidenceThreshold\n                        ) {\n                            if (!accumulator.slots[accumulator.current.key]) {\n                                accumulator.slots[accumulator.current.key] = [];\n                            }\n                            accumulator.slots[accumulator.current.key].push({\n                                confidence: accumulator.current.confidence,\n                                value: accumulator.current.value\n                            });\n                        }\n                        accumulator.current = {\n                            confidence: sentenceWordPredictionIds[currentIndex].confidence,\n                            key: currentSlotKey,\n                            value: w\n                        };\n                    } else {\n                        // todo: add a join words handler for languages that tokenize differently\n                        accumulator.current.value += ` ${w}`;\n                        accumulator.current.confidence =\n                            (sentenceWordPredictionIds[currentIndex].confidence + accumulator.current.confidence) / 2;\n                    }\n                    if (currentIndex + 1 === sentenceWords.length) {\n                        if (accumulator.current.key !== 'O' && accumulator.current.confidence >= lowConfidenceThreshold) {\n                            if (!accumulator.slots[accumulator.current.key]) {\n                                accumulator.slots[accumulator.current.key] = [];\n                            }\n                            accumulator.slots[accumulator.current.key].push({\n                                confidence: accumulator.current.confidence,\n                                value: accumulator.current.value\n                            });\n                        }\n                        return { sentence: s, slots: accumulator.slots };\n                    }\n                    return accumulator;\n                },\n                { current: { key: '', value: '', confidence: 0 }, slots: {}, sentence: '' }\n            );\n        });\n    };\n\n    public train = async (trainDataset: types.ITrainingParams) => {\n        const trainY2Chunks = chunk(trainDataset.trainY2, this.config.batchSize);\n        const trainYChunks = chunk(trainDataset.trainY, this.config.batchSize);\n        const trainXChunks = chunk(trainDataset.trainX, this.config.batchSize);\n        const { epochs, trainingValidationSplit: validationSplit } = this.config;\n        const slotsLength = Object.keys(this.datasetParams.slotsToId).length;\n        this.logger.log('Start training NER model!');\n        let enoughAccuracyReached = false;\n        for (const [index, xChunk] of trainXChunks.entries()) {\n            if (enoughAccuracyReached) {\n                return;\n            }\n            // classification hot encoded labels as input\n            const intentLabels = tf.tidy(() =>\n                tf.oneHot(tf.tensor1d(trainYChunks[index], 'int32'), this.datasetParams.intents.length).asType('float32')\n            );\n            const embeddedSentenceWords = this.embeddingsModel.embed(xChunk);\n            // convert sentence-word-slots from the highest index format like [0,0,0,0,4,4,0,0,3,3] for a sentence\n            // to one hot encoded sentences with correct maxWords and batch sizes tensor sizes\n            const slotTags: tf.Tensor3D = tf.tidy(() => {\n                const y2sentences: tf.Tensor2D[] = [];\n                for (const wordsSlotId of trainY2Chunks[index]) {\n                    const slotIds = tf\n                        .tensor1d(wordsSlotId, 'int32')\n                        .pad([[0, this.datasetParams.maxWordsPerSentence - wordsSlotId.length]]);\n                    const ohe = tf.oneHot(slotIds, slotsLength).asType('float32');\n                    slotIds.dispose();\n                    y2sentences.push(ohe);\n                }\n                const stack = tf.stack(y2sentences) as tf.Tensor3D;\n                y2sentences.forEach(s => s.dispose());\n                return stack;\n            });\n            await this.model.fit([intentLabels, embeddedSentenceWords], slotTags, {\n                // batchSize: this.config.batchSize,\n                callbacks: { onBatchEnd: tf.nextFrame },\n                epochs,\n                shuffle: true,\n                validationSplit\n            });\n            intentLabels.dispose();\n            embeddedSentenceWords.dispose();\n            await tf.nextFrame();\n            const h = this.model.history.history;\n            const c = h.val_loss.length - 1;\n            const epoch = this.model.history.epoch;\n            if (this.nerTrainStatsHandler) {\n                this.nerTrainStatsHandler({\n                    batch: index + 1,\n                    batchEpochs: epoch.length,\n                    currentBatchSize: trainXChunks[index].length,\n                    tensorsInMemory: tf.memory().numTensors,\n                    totalBatches: trainXChunks.length,\n                    trainingAccuracy: h.acc[c],\n                    trainingLoss: h.loss[c],\n                    validationAccuracy: h.val_acc[c],\n                    validationLoss: h.val_loss[c]\n                });\n            }\n            this.logger.log(`Trained ${epoch.length} epochs on batch ${index + 1} of ${trainXChunks.length}`);\n            this.logger.log(`Training Loss: ${h.loss[c]} | Training Accuracy: ${h.acc[c]}`);\n            this.logger.log(`Validation Loss: ${h.val_loss[c]} | Validation Accuracy: ${h.val_acc[c]}`);\n            this.logger.warn(`(Memory) Number of tensors in memory at the end of batch: ${tf.memory().numTensors}`);\n            this.logger.log('==================================================================================================');\n            slotTags.dispose();\n            if (\n                this.config.lossThresholdToStopTraining &&\n                h.loss[c] < this.config.lossThresholdToStopTraining &&\n                h.val_loss[c] < this.config.lossThresholdToStopTraining\n            ) {\n                enoughAccuracyReached = true;\n                this.logger.warn(`Enough accuracy reached! Ending training after batch ${index + 1} of ${trainXChunks.length}`);\n                this.logger.log('==================================================================================================');\n            }\n        }\n    };\n\n    public test = async (\n        testExamples: types.ITestingParams,\n        resultsHandler?: types.ITestPredictionsHandler\n    ): Promise<types.IPredictionStats> => {\n        const handler = resultsHandler ? resultsHandler : this.defaultResultsLogger;\n        const stats: types.IPredictionStats = { correct: 0, wrong: 0 };\n        const batchSize = this.config.batchSize; // this.config.batchSize\n        const testX = chunk(testExamples.testX, batchSize);\n        const testY = chunk(testExamples.testY, batchSize);\n        const testY2 = chunk(testExamples.testY2, batchSize);\n        for (const [i, sentences] of testX.entries()) {\n            const classifications = testY[i];\n            const encodedIntent = sentences.map(\n                (p, idx) =>\n                    ({\n                        confidence: 1,\n                        intent: this.datasetParams.intents[classifications[idx]],\n                        sentence: p\n                    } as types.IClassificationPred)\n            );\n            const predictions = this.rawPrediction(sentences, encodedIntent).map(sentence => sentence.map(s => s.highestIndex));\n            handler(sentences, testY2[i], predictions, stats);\n            await tf.nextFrame();\n        }\n        return stats;\n    };\n\n    private defaultResultsLogger = (\n        x: types.ITestingParams['testX'],\n        y2: types.ITestingParams['testY2'],\n        o: types.ITestingParams['testY2'],\n        stats: types.IPredictionStats\n    ): types.IPredictionStats => {\n        x.forEach((s, sentenceIdx) => {\n            const expectedTags = y2[sentenceIdx];\n            const predictedTags = o[sentenceIdx];\n            let correct = true;\n            expectedTags.forEach((tag, idx) => {\n                if (predictedTags[idx] !== tag && correct) {\n                    correct = false;\n                }\n            });\n            if (correct) {\n                stats.correct++;\n                this.logger.debug(`CORRECT - ${s} expected: ${expectedTags}, predicted: ${predictedTags}`);\n            } else {\n                stats.wrong++;\n                this.logger.error(`WRONG - ${s} expected: ${expectedTags}, predicted: ${predictedTags}`);\n            }\n        });\n        return stats;\n    };\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { InputSpec } from '@tensorflow/tfjs-layers/dist/engine/topology';\n\n// NOTE:\n// Attention of multi dimensional time series following the implementation\n// from the great NLP course \"Tensorflow Solutions for Text\" by Will Ballard.\n// References:\n// https://www.safaribooksonline.com/library/view/tensorflow-solutions-for/9781788399180/\nexport class TimeSeriesAttention extends tf.layers.Layer {\n    public static className = 'TimeSeriesAttention';\n    public className = TimeSeriesAttention.className;\n\n    public timed: tf.layers.Layer | null = null;\n\n    constructor(config?: any) {\n        super(config || {});\n        this.inputSpec = [new InputSpec({ ndim: 3 })];\n        this.supportsMasking = true;\n    }\n\n    public build(inputShape: tf.Shape): void {\n        const dimensions = inputShape[2];\n        const timed = tf.sequential({ name: 'per_time_step' });\n        timed.add(tf.layers.dense({\n            inputShape: [dimensions], kernelInitializer: 'zeros', units: dimensions, activation: 'softmax', name: 'att_dense1',\n        }));\n        timed.add(tf.layers.dense({ units: dimensions, kernelInitializer: 'glorotNormal', activation: 'tanh', name: 'att_dense2' }));\n        this.timed = tf.layers.timeDistributed({ layer: timed, name: 'att_td' });\n        this.timed.build(inputShape);\n        this.trainableWeights = this.timed.trainableWeights;\n        this.nonTrainableWeights = this.timed.nonTrainableWeights;\n        this.built = true;\n    }\n\n    public call(inputs: tf.Tensor[], kwargs: any) {\n        if (!this.built || !this.timed) {\n            throw new Error('Calling TimeSeriesAttention layer before it was built correctly.');\n        }\n        return tf.tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const encoded = (this.timed as tf.layers.Layer).apply(inputs) as tf.Tensor;\n            const permuted = tf.layers.permute({ dims: [2, 1] }).apply(encoded) as tf.Tensor;\n            // NOTE: this code is a workaround the absense of batch_dot in tfjs\n            // TODO: replace this with batch_dot\n            const unstackedInput = tf.unstack(inputs[0]);\n            const unstackedPermuted = tf.unstack(permuted);\n            const dotProds = unstackedInput.map((ui, i) => tf.dot(ui, unstackedPermuted[i]));\n            const selfAttend = tf.stack(dotProds);\n            const attention = tf.softmax(selfAttend);\n            const attentionPermuted = tf.layers.permute({ dims: [2, 1] }).apply(attention) as tf.Tensor;\n            const unstackedAttention = tf.unstack(attentionPermuted);\n            const unstackedOutput = unstackedAttention.map((ua, i) => tf.dot(ua, unstackedInput[i]));\n            const output = tf.stack(unstackedOutput);\n            return output;\n        });\n    }\n\n    public computeOutputShape(inputShape: tf.Shape) {\n        return inputShape;\n    }\n}\n\ntf.serialization.SerializationMap.register(TimeSeriesAttention);\n\n// WIP!\n// export function batchDot(x: tf.Tensor, y: tf.Tensor): tf.Tensor {\n//     const xNdim = x.shape.length;\n//     const yNdim = y.shape.length;\n//     const axes = [xNdim - 1, yNdim - 2];\n//     let reshapedX = x;\n//     let reshapedY = y;\n//     let diff = 0;\n//     if (xNdim > yNdim) {\n//         diff = xNdim - yNdim;\n//         reshapedY = tf.reshape(y, y.shape.concat(Array(diff).fill(1)));\n//     } else if (yNdim > xNdim) {\n//         diff = yNdim - xNdim;\n//         reshapedX = tf.reshape(x, x.shape.concat(Array(diff).fill(1)));\n//     }\n//     let out;\n//     if (xNdim === 2 && yNdim === 2) {\n//         if (axes[0] === axes[1]) {\n//             out = tf.sum(tf.mul(reshapedX, reshapedY), axes[0]);\n//         } else {\n//             out = tf.sum(tf.mul(tf.transpose(reshapedX, [1, 0]), reshapedY), axes[1]);\n//         }\n//     } else {\n//         const adjX = axes[0] !== xNdim - 1;\n//         const adjY = axes[1] === yNdim - 1;\n//         out = tf.matMul(reshapedX, reshapedY, adjX, adjY);\n//     }\n//     if (diff) {\n//         const idx = xNdim > yNdim - 3 ? xNdim + yNdim - 3 : xNdim - 1;\n//         out = tf.squeeze(out, Array.from(Array(idx + diff).keys()));\n//     }\n//     if (out.shape.length === 1) {\n//         out = tf.expandDims(out, 1);\n//     }\n//     return out;\n// }\n","import { Card, Col, Input, Row } from 'antd';\nimport * as React from 'react';\nimport styled from 'styled-components';\nimport { AidaPipeline } from '../../src/pipelines/zebraWings/pipeline';\n\ninterface IPipelineTestInputProps {\n    pipeline: AidaPipeline;\n}\ninterface IPipelineTestInputState {\n    disabled: boolean;\n    outTextContent: string | null;\n}\n// ant bug: patch input styling of search text input to avoid being hidden by the button\nconst SearchInput = styled(Input.Search)`\n    > input {\n        padding-right: 70px !important;\n    }\n`;\nexport default class TrainedPipelineTestInput extends React.Component<IPipelineTestInputProps, IPipelineTestInputState> {\n    public state: IPipelineTestInputState = {\n        disabled: false,\n        outTextContent: null\n    };\n    public renderIntentsList = () => (\n        <div>\n            <p>The pipeline was trained on this list of intents and slots per intent:</p>\n            <div>\n                <ul>\n                    <li>greet</li>\n                    <li>bye</li>\n                    <li>affirmative</li>\n                    <li>negative</li>\n                    <li>wtf (detect insults and out of context stuff)</li>\n                    <li>playMusic -> slots: artist, song</li>\n                    <li>addEventToCalendar -> slots: calendarEvent, dateTime</li>\n                </ul>\n            </div>\n            <p>\n                You can try a sentence like 'please remind to me watch real madrid match tomorrow at 9pm' or 'play new york new york\n                from frank sinatra'\n            </p>\n            <p>\n                Check the{' '}\n                <a target=\"_blank\" href=\"https://github.com/rodrigopivi/aida/tree/master/typescript/intents\">\n                    chatito definition files at the github repo\n                </a>\n                &nbsp; for more details about the training examples generation.\n            </p>\n        </div>\n    );\n\n    public render() {\n        return (\n            <div>\n                <Row type=\"flex\" justify=\"center\">\n                    <Col span={24} sm={{ span: 12 }} >\n                        <Card title=\"Test trained pipeline:\" style={{ minHeight: '100%' }}>\n                            <p>\n                                <SearchInput\n                                    placeholder=\"Enter some input to process...\"\n                                    enterButton=\"Send\"\n                                    size=\"large\"\n                                    onSearch={this.handleSubmit}\n                                    id=\"__inputSearch\"\n                                    disabled={this.state.disabled}\n                                />\n                            </p>\n                            {this.renderIntentsList()}\n                        </Card>\n                    </Col>\n                    <Col span={24} sm={{ span: 12 }} >\n                        <Card title=\"Pipeline output:\" style={{ minHeight: '100%' }}>\n                            <pre style={{ marginTop: '2em' }}>{this.state.outTextContent || ''}</pre>\n                        </Card>\n                    </Col>\n                </Row>\n            </div>\n        );\n    }\n\n    private predict = (sentences: string) => {\n        const predictions = this.props.pipeline.predict([sentences]);\n        return Object.assign({}, predictions.classification[0], predictions.ner[0]);\n    };\n\n    private handleSubmit = (value: string) => {\n        if (!value || !value.trim()) {\n            return null;\n        }\n        this.setState({ disabled: true }, () => {\n            const outTextContent = JSON.stringify(this.predict(value), null, 2);\n            this.setState({ outTextContent }, () => {\n                this.setState({ disabled: false });\n                const inputSearch = document.getElementById('__inputSearch') as HTMLInputElement;\n                if (inputSearch && inputSearch.value) {\n                    inputSearch.value = '';\n                }\n            });\n        });\n    };\n}\n","import * as React from 'react';\nimport DefaultHeader from '../components/DefaultHeader';\nimport Layout from '../components/Layout';\nimport TrainExample from '../components/TrainExample';\n\nexport default ({ location }: any) => {\n    return (\n        <Layout location={location} style={{ minHeight: '95vh' }}>\n            <DefaultHeader />\n            <TrainExample />\n        </Layout>\n    );\n};\n","import { Button, Card, Col, Progress, Row } from 'antd';\nimport axios from 'axios';\nimport { withPrefix } from 'gatsby-link';\nimport * as React from 'react';\nimport * as types from '../../src/types';\nimport TrainingDashboard from './TrainingDashboard';\n\ninterface ITrainExampleState {\n    ngramToIdDictionary: types.IPretrainedDictionary['NGRAM_TO_ID_MAP'] | null;\n    pretrainedNGramVectors: types.IPretrainedDictionary['PRETRAINED'] | null;\n    datasetParams: types.IDatasetParams | null;\n    datasetTest: types.ITestingParams | null;\n    datasetTraining: types.ITrainingParams | null;\n    downloadProgress: number;\n    embeddingsAndTrainingDatasetLoaded: boolean;\n    isDownloading: boolean;\n}\n\nexport default class TrainExample extends React.Component<{}, ITrainExampleState> {\n    public state: ITrainExampleState = {\n        datasetParams: null,\n        datasetTest: null,\n        datasetTraining: null,\n        downloadProgress: 0,\n        embeddingsAndTrainingDatasetLoaded: false,\n        isDownloading: false,\n        ngramToIdDictionary: null,\n        pretrainedNGramVectors: null\n    };\n\n    public render() {\n        const {\n            embeddingsAndTrainingDatasetLoaded,\n            datasetParams,\n            datasetTraining,\n            datasetTest,\n            ngramToIdDictionary,\n            pretrainedNGramVectors\n        } = this.state;\n        if (\n            embeddingsAndTrainingDatasetLoaded &&\n            datasetParams &&\n            datasetTraining &&\n            datasetTest &&\n            ngramToIdDictionary &&\n            pretrainedNGramVectors\n        ) {\n            return (\n                <TrainingDashboard\n                    datasetParams={datasetParams}\n                    trainDataset={datasetTraining}\n                    testDataset={datasetTest}\n                    ngramToIdDictionary={ngramToIdDictionary}\n                    pretrainedNGramVectors={pretrainedNGramVectors}\n                />\n            );\n        }\n        const disableDownload = this.state.isDownloading || this.state.downloadProgress === 100;\n        const buttonMessage = disableDownload ? (this.state.downloadProgress === 100 ? 'Loading...' : 'Downloading...') : 'Start training';\n        return (\n            <Row type=\"flex\">\n                <Col span={24} sm={{ span: 12 }} >\n                    <h2>Train your model from scratch</h2>\n                    <p>\n                        The pipeline is composed of two trainable models. Text classification model determines the intent of a sentence, named entity\n                        recognition model extracts the slots. Once the training finishes, will run the test dataset on them and give you a\n                        report, finally your browser will ask you to accept the download of the trained model files.\n                    </p>\n                    {this.renderIntentsList()}\n                    <p>Click 'start training' to continue.</p>\n                </Col>\n                <Col span={24} sm={{ span: 12 }} >\n                    <Card style={{ marginLeft: '2em', textAlign: 'center' }}>\n                        <div>\n                            <Progress type=\"circle\" percent={this.state.downloadProgress} />\n                        </div>\n                        <br />\n                        <div>\n                            <Button type=\"primary\" size=\"large\" disabled={disableDownload} onClick={this.trainTestAndSaveModels}>\n                                {buttonMessage}\n                            </Button>\n                        </div>\n                        <br />\n                        <p>\n                            Will download the embeddings dictionary (about 1mb), generate the dataset, then train and test the\n                            models. This process may take several minutes to complete, you will get feedback of the progress but the webpage\n                            might feel unresponsive while training.\n                        </p>\n                    </Card>\n                </Col>\n            </Row>\n        );\n    }\n\n    private renderIntentsList = () => (\n        <div>\n            <p>The pipeline is going to start training on this list of intents and slots:</p>\n            <div>\n                <ul>\n                    <li>greet</li>\n                    <li>bye</li>\n                    <li>affirmative</li>\n                    <li>negative</li>\n                    <li>wtf (detect insults and out of context stuff)</li>\n                    <li>playMusic -> slots: artist, song</li>\n                    <li>addEventToCalendar -> slots: calendarEvent, dateTime</li>\n                </ul>\n            </div>\n            <p>\n                Check the{' '}\n                <a target=\"_blank\" href=\"https://github.com/rodrigopivi/aida/tree/master/typescript/intents\">\n                    chatito definition files at the github repo\n                </a>\n                &nbsp; for more details about the training examples generation.\n            </p>\n        </div>\n    );\n\n    private downloadFiles = async (files: string[]) => {\n        let total = 0;\n        let progress = 0;\n        this.setState({ isDownloading: true, downloadProgress: 0 });\n        const downloads = await Promise.all(\n            files.map(file =>\n                axios.get(file, {\n                    onDownloadProgress: progressEvent => {\n                        const totalLength = progressEvent.lengthComputable\n                            ? progressEvent.total\n                            : progressEvent.target.getResponseHeader('content-length') ||\n                              progressEvent.target.getResponseHeader('x-decompressed-content-length');\n                        if (totalLength !== null) {\n                            total += totalLength;\n                            progress += Math.round((progressEvent.loaded * 100) / total);\n                        }\n                        this.setState({ downloadProgress: progress });\n                    }\n                })\n            )\n        );\n        this.setState({ isDownloading: false, downloadProgress: 100 });\n        return downloads;\n    };\n\n    private timeoutInMs = async (ms: number) => new Promise(resolve => setTimeout(resolve, ms));\n\n    private trainTestAndSaveModels = async () => {\n        const files = [\n            withPrefix('/models/dictionary.json'),\n            withPrefix('/models/ngram_to_id_dictionary.json'),\n            withPrefix('/models/dataset_params.json'),\n            withPrefix('/models/dataset_training.json'),\n            withPrefix('/models/dataset_testing.json')\n        ];\n        const jsonFiles = await this.downloadFiles(files);\n        const pretrainedNGramVectors = new Map<string, Float32Array>(jsonFiles[0].data);\n        const ngramToIdDictionary = jsonFiles[1].data;\n        const datasetParams = jsonFiles[2].data;\n        const datasetTraining = jsonFiles[3].data;\n        const datasetTest = jsonFiles[4].data;\n        await this.timeoutInMs(200); // give some time for the state update after the model setup (before the gpu blocks)\n        this.setState({\n            datasetParams,\n            datasetTest,\n            datasetTraining,\n            embeddingsAndTrainingDatasetLoaded: true,\n            ngramToIdDictionary,\n            pretrainedNGramVectors\n        });\n    };\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Alert, Card, Col, Row, Steps } from 'antd';\nimport * as React from 'react';\nimport styled from 'styled-components';\nimport { AidaPipeline } from '../../src/pipelines/zebraWings/pipeline';\nimport * as types from '../../src/types';\nimport LineChart, { ILineChartDataValues } from './LineChart';\nimport TrainedPipelineTestInput from './TrainedPipelineTestInput';\n\nconst globalLog: string[] = [\n    '==================================================================================================',\n    'WARNING: Training may take several minutes depending on your hardware, your browser may be slow while training.',\n    'NOTE: Will train classification model, then NER model, then run the test dataset on both and finally download the trained models.',\n    '        The line-plotting of the training models will show at the end to avoid extra GPU/CPU load during training.',\n    '=================================================================================================='\n];\nconst LoggerFeed = styled.div`\n    white-space: pre-wrap;\n    height: 130px;\n    overflow: scroll;\n    background-color: #ededed;\n    padding: 10px 20px;\n    margin-bottom: 20px;\n    display: flex;\n    flex-direction: column-reverse;\n    border: 1px solid #ccc;\n    font-size: 12px;\n    margin-bottom: 20px;\n`;\n\ninterface ITrainingDashboardProps {\n    datasetParams: types.IDatasetParams;\n    trainDataset: types.ITrainingParams;\n    testDataset: types.ITestingParams;\n    ngramToIdDictionary: types.IPretrainedDictionary['NGRAM_TO_ID_MAP'];\n    pretrainedNGramVectors: types.IPretrainedDictionary['PRETRAINED'];\n}\n\ninterface ITrainingDashboardState {\n    currentStep: number;\n    logLinesCounter: number;\n    pipelineFinishedTraining: boolean;\n    valuesClassification: ILineChartDataValues;\n    valuesNer: ILineChartDataValues;\n    plot: boolean;\n}\n\nexport default class TrainingDashboard extends React.Component<ITrainingDashboardProps, ITrainingDashboardState> {\n    public state: ITrainingDashboardState = {\n        currentStep: 0,\n        logLinesCounter: 0,\n        pipelineFinishedTraining: false,\n        plot: false, // only plot at the end of training to make training fast (avoid any gpu external use)\n        valuesClassification: [],\n        valuesNer: []\n    };\n    private pipeline: AidaPipeline | null = null;\n    private trainStatsClassification: types.IStatsHandlerArgs[] = [];\n    private trainStatsNer: types.IStatsHandlerArgs[] = [];\n\n    public componentDidMount() {\n        this.trainTestAndSaveModels();\n    }\n\n    public componentWillUnmount() {\n        this.pipeline = null;\n        // tslint:disable-next-line:no-console\n        console.log(tf.memory());\n        tf.disposeVariables();\n    }\n\n    public render() {\n        return (\n            <div>\n                <Steps size=\"small\" current={this.state.currentStep} style={{ marginBottom: '20px' }}>\n                    <Steps.Step title=\"Train classification model\" />\n                    <Steps.Step title=\"Train NER model\" />\n                    <Steps.Step title=\"Test models\" />\n                    <Steps.Step title=\"Download and try\" />\n                </Steps>\n                {this.renderPipelineManualTestInput()}\n                <h3 style={{ marginTop: '20px' }}>Training logs:</h3>\n                <LoggerFeed>{globalLog.join('\\n')}</LoggerFeed>\n                <Row type=\"flex\" justify=\"center\">\n                    <Col span={12}>\n                        {this.renderChart('Classification model stats', this.state.valuesClassification, this.trainStatsClassification)}\n                    </Col>\n                    <Col span={12}>{this.renderChart('NER model stats', this.state.valuesNer, this.trainStatsNer)}</Col>\n                </Row>\n            </div>\n        );\n    }\n\n    private renderPipelineManualTestInput = () => {\n        if (this.state.currentStep === 3 && this.pipeline) {\n            return (\n                <>\n                    <Alert\n                        message=\"Finished training! You can test sentences manually or look at the logs for stats.\"\n                        type=\"success\"\n                        style={{ marginBottom: 20 }}\n                    />\n                    <TrainedPipelineTestInput pipeline={this.pipeline} />\n                </>\n            );\n        }\n        return null;\n    };\n\n    private renderChart = (title: string, values: ILineChartDataValues, stats: types.IStatsHandlerArgs[]) => {\n        if (!stats.length || !values.length) {\n            return (\n                <Card title={title} style={{ minHeight: '100%' }}>\n                    <p>Waiting...</p>\n                </Card>\n            );\n        }\n        const batchInfo = `Batch ${values.length} of ${stats[stats.length - 1].totalBatches}`;\n        const lineChart = this.state.plot ? <LineChart dataValues={values} /> : null;\n        return (\n            <Card title={title} extra={batchInfo} style={{ minHeight: '100%' }}>\n                {lineChart}\n                <p style={{ fontSize: '12px' }}>\n                    <strong>Train Accuracy:</strong> {stats[stats.length - 1].trainingAccuracy}\n                    <br />\n                    <strong>Validation Accuracy:</strong> {stats[stats.length - 1].validationAccuracy}\n                    <br />\n                    <strong>Train Loss:</strong> {stats[stats.length - 1].trainingLoss}\n                    <br />\n                    <strong>Validation Loss:</strong> {stats[stats.length - 1].validationLoss}\n                    <br />\n                </p>\n            </Card>\n        );\n    };\n\n    private trainStatsHandler = (): types.ITrainStatsHandler => ({\n        classification: stats => {\n            this.trainStatsClassification.push(stats);\n            const { batch, validationLoss, trainingLoss } = stats;\n            this.setState(s => ({\n                valuesClassification: s.valuesClassification.concat([{ batch, validationLoss, trainingLoss }])\n            }));\n        },\n        ner: stats => {\n            this.trainStatsNer.push(stats);\n            const { batch, validationLoss, trainingLoss } = stats;\n            this.setState(s => ({\n                currentStep: s.currentStep === 0 ? 1 : s.currentStep,\n                valuesNer: s.valuesNer.concat([{ batch, validationLoss, trainingLoss }])\n            }));\n        }\n    });\n\n    private trainTestAndSaveModels = async () => {\n        const logHandler = (...args: any[]) => {\n            globalLog.push(...args);\n            this.setState(prev => ({ logLinesCounter: prev.logLinesCounter + 1 }));\n        };\n        const logger: types.IPipelineModelLogger = {\n            debug: () => null,\n            error: logHandler,\n            log: logHandler,\n            warn: logHandler\n        };\n        this.pipeline = new AidaPipeline({\n            datasetParams: this.props.datasetParams,\n            logger,\n            ngramToIdDictionary: this.props.ngramToIdDictionary,\n            pretrainedNGramVectors: this.props.pretrainedNGramVectors,\n            trainStatsHandler: this.trainStatsHandler()\n        });\n        if (!this.pipeline) {\n            return null;\n        }\n        await this.pipeline.train(this.props.trainDataset);\n        this.setState({ currentStep: 2 });\n        const stats = await this.pipeline.test(this.props.testDataset);\n        this.setState({ currentStep: 3 });\n        logger.log('==================================================================================================');\n        logger.log('Test dataset stats:');\n        logger.log(JSON.stringify(stats, null, 2));\n        logger.log('==================================================================================================');\n        await this.pipeline.save({\n            classificationPath: 'downloads://classification',\n            embeddingPath: 'downloads://embedding',\n            nerPath: 'downloads://ner'\n        });\n        this.setState({ plot: true });\n    };\n}\n","'use strict';\n\nrequire('../../style/index.css');\n\nrequire('./index.css');","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\n\nvar _extends2 = require('babel-runtime/helpers/extends');\n\nvar _extends3 = _interopRequireDefault(_extends2);\n\nvar _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');\n\nvar _classCallCheck3 = _interopRequireDefault(_classCallCheck2);\n\nvar _createClass2 = require('babel-runtime/helpers/createClass');\n\nvar _createClass3 = _interopRequireDefault(_createClass2);\n\nvar _possibleConstructorReturn2 = require('babel-runtime/helpers/possibleConstructorReturn');\n\nvar _possibleConstructorReturn3 = _interopRequireDefault(_possibleConstructorReturn2);\n\nvar _inherits2 = require('babel-runtime/helpers/inherits');\n\nvar _inherits3 = _interopRequireDefault(_inherits2);\n\nvar _react = require('react');\n\nvar React = _interopRequireWildcard(_react);\n\nvar _propTypes = require('prop-types');\n\nvar PropTypes = _interopRequireWildcard(_propTypes);\n\nvar _rcSteps = require('rc-steps');\n\nvar _rcSteps2 = _interopRequireDefault(_rcSteps);\n\nvar _icon = require('../icon');\n\nvar _icon2 = _interopRequireDefault(_icon);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj['default'] = obj; return newObj; } }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { 'default': obj }; }\n\nvar Steps = function (_React$Component) {\n    (0, _inherits3['default'])(Steps, _React$Component);\n\n    function Steps() {\n        (0, _classCallCheck3['default'])(this, Steps);\n        return (0, _possibleConstructorReturn3['default'])(this, (Steps.__proto__ || Object.getPrototypeOf(Steps)).apply(this, arguments));\n    }\n\n    (0, _createClass3['default'])(Steps, [{\n        key: 'render',\n        value: function render() {\n            var prefixCls = this.props.prefixCls;\n\n            var icons = {\n                finish: React.createElement(_icon2['default'], { type: 'check', className: prefixCls + '-finish-icon' }),\n                error: React.createElement(_icon2['default'], { type: 'close', className: prefixCls + '-error-icon' })\n            };\n            return React.createElement(_rcSteps2['default'], (0, _extends3['default'])({ icons: icons }, this.props));\n        }\n    }]);\n    return Steps;\n}(React.Component);\n\nexports['default'] = Steps;\n\nSteps.Step = _rcSteps2['default'].Step;\nSteps.defaultProps = {\n    prefixCls: 'ant-steps',\n    iconPrefix: 'ant',\n    current: 0\n};\nSteps.propTypes = {\n    prefixCls: PropTypes.string,\n    iconPrefix: PropTypes.string,\n    current: PropTypes.number\n};\nmodule.exports = exports['default'];","'use strict';\n\nrequire('../../style/index.css');\n\nrequire('./index.css');","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\n\nvar _extends2 = require('babel-runtime/helpers/extends');\n\nvar _extends3 = _interopRequireDefault(_extends2);\n\nvar _defineProperty2 = require('babel-runtime/helpers/defineProperty');\n\nvar _defineProperty3 = _interopRequireDefault(_defineProperty2);\n\nvar _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');\n\nvar _classCallCheck3 = _interopRequireDefault(_classCallCheck2);\n\nvar _createClass2 = require('babel-runtime/helpers/createClass');\n\nvar _createClass3 = _interopRequireDefault(_createClass2);\n\nvar _possibleConstructorReturn2 = require('babel-runtime/helpers/possibleConstructorReturn');\n\nvar _possibleConstructorReturn3 = _interopRequireDefault(_possibleConstructorReturn2);\n\nvar _inherits2 = require('babel-runtime/helpers/inherits');\n\nvar _inherits3 = _interopRequireDefault(_inherits2);\n\nvar _react = require('react');\n\nvar React = _interopRequireWildcard(_react);\n\nvar _reactDom = require('react-dom');\n\nvar ReactDOM = _interopRequireWildcard(_reactDom);\n\nvar _rcAnimate = require('rc-animate');\n\nvar _rcAnimate2 = _interopRequireDefault(_rcAnimate);\n\nvar _icon = require('../icon');\n\nvar _icon2 = _interopRequireDefault(_icon);\n\nvar _classnames = require('classnames');\n\nvar _classnames2 = _interopRequireDefault(_classnames);\n\nvar _getDataOrAriaProps = require('../_util/getDataOrAriaProps');\n\nvar _getDataOrAriaProps2 = _interopRequireDefault(_getDataOrAriaProps);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj['default'] = obj; return newObj; } }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { 'default': obj }; }\n\nfunction noop() {}\n\nvar Alert = function (_React$Component) {\n    (0, _inherits3['default'])(Alert, _React$Component);\n\n    function Alert(props) {\n        (0, _classCallCheck3['default'])(this, Alert);\n\n        var _this = (0, _possibleConstructorReturn3['default'])(this, (Alert.__proto__ || Object.getPrototypeOf(Alert)).call(this, props));\n\n        _this.handleClose = function (e) {\n            e.preventDefault();\n            var dom = ReactDOM.findDOMNode(_this);\n            dom.style.height = dom.offsetHeight + 'px';\n            // Magic code\n            //  height\n            dom.style.height = dom.offsetHeight + 'px';\n            _this.setState({\n                closing: false\n            });\n            (_this.props.onClose || noop)(e);\n        };\n        _this.animationEnd = function () {\n            _this.setState({\n                closed: true,\n                closing: true\n            });\n            (_this.props.afterClose || noop)();\n        };\n        _this.state = {\n            closing: true,\n            closed: false\n        };\n        return _this;\n    }\n\n    (0, _createClass3['default'])(Alert, [{\n        key: 'render',\n        value: function render() {\n            var _classNames;\n\n            var _props = this.props,\n                closable = _props.closable,\n                description = _props.description,\n                type = _props.type,\n                _props$prefixCls = _props.prefixCls,\n                prefixCls = _props$prefixCls === undefined ? 'ant-alert' : _props$prefixCls,\n                message = _props.message,\n                closeText = _props.closeText,\n                showIcon = _props.showIcon,\n                banner = _props.banner,\n                _props$className = _props.className,\n                className = _props$className === undefined ? '' : _props$className,\n                style = _props.style,\n                iconType = _props.iconType;\n            // banner Icon\n\n            showIcon = banner && showIcon === undefined ? true : showIcon;\n            // banner\n            type = banner && type === undefined ? 'warning' : type || 'info';\n            var iconTheme = 'filled';\n            if (!iconType) {\n                switch (type) {\n                    case 'success':\n                        iconType = 'check-circle';\n                        break;\n                    case 'info':\n                        iconType = 'info-circle';\n                        break;\n                    case 'error':\n                        iconType = 'close-circle';\n                        break;\n                    case 'warning':\n                        iconType = 'exclamation-circle';\n                        break;\n                    default:\n                        iconType = 'default';\n                }\n                // use outline icon in alert with description\n                if (!!description) {\n                    iconTheme = 'outlined';\n                }\n            }\n            var alertCls = (0, _classnames2['default'])(prefixCls, (_classNames = {}, (0, _defineProperty3['default'])(_classNames, prefixCls + '-' + type, true), (0, _defineProperty3['default'])(_classNames, prefixCls + '-close', !this.state.closing), (0, _defineProperty3['default'])(_classNames, prefixCls + '-with-description', !!description), (0, _defineProperty3['default'])(_classNames, prefixCls + '-no-icon', !showIcon), (0, _defineProperty3['default'])(_classNames, prefixCls + '-banner', !!banner), _classNames), className);\n            // closeable when closeText is assigned\n            if (closeText) {\n                closable = true;\n            }\n            var closeIcon = closable ? React.createElement(\n                'a',\n                { onClick: this.handleClose, className: prefixCls + '-close-icon' },\n                closeText || React.createElement(_icon2['default'], { type: 'close' })\n            ) : null;\n            var dataOrAriaProps = (0, _getDataOrAriaProps2['default'])(this.props);\n            var iconNode = React.createElement(_icon2['default'], { className: prefixCls + '-icon', type: iconType, theme: iconTheme });\n            return this.state.closed ? null : React.createElement(\n                _rcAnimate2['default'],\n                { component: '', showProp: 'data-show', transitionName: prefixCls + '-slide-up', onEnd: this.animationEnd },\n                React.createElement(\n                    'div',\n                    (0, _extends3['default'])({ 'data-show': this.state.closing, className: alertCls, style: style }, dataOrAriaProps),\n                    showIcon ? iconNode : null,\n                    React.createElement(\n                        'span',\n                        { className: prefixCls + '-message' },\n                        message\n                    ),\n                    React.createElement(\n                        'span',\n                        { className: prefixCls + '-description' },\n                        description\n                    ),\n                    closeIcon\n                )\n            );\n        }\n    }]);\n    return Alert;\n}(React.Component);\n\nexports['default'] = Alert;\nmodule.exports = exports['default'];","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports['default'] = getDataOrAriaProps;\nfunction getDataOrAriaProps(props) {\n    return Object.keys(props).reduce(function (prev, key) {\n        if ((key.substr(0, 5) === 'data-' || key.substr(0, 5) === 'aria-' || key === 'role') && key.substr(0, 7) !== 'data-__') {\n            prev[key] = props[key];\n        }\n        return prev;\n    }, {});\n}\nmodule.exports = exports['default'];","import * as React from 'react';\nexport type ILineChartDataValues = Array<{ batch: number; validationLoss: any; trainingLoss: any }>;\n\n// TODO: Print a line chart\nexport default class AidaLineChart extends React.Component<{ dataValues: ILineChartDataValues }, any> {\n    public render() {\n        return (\n            <div />\n        );\n    }\n}\n","export function isFlexSupported() {\n  if (typeof window !== 'undefined' && window.document && window.document.documentElement) {\n    var documentElement = window.document.documentElement;\n\n    return 'flex' in documentElement.style || 'webkitFlex' in documentElement.style || 'Flex' in documentElement.style || 'msFlex' in documentElement.style;\n  }\n  return false;\n}","import _extends from 'babel-runtime/helpers/extends';\nimport _objectWithoutProperties from 'babel-runtime/helpers/objectWithoutProperties';\nimport _classCallCheck from 'babel-runtime/helpers/classCallCheck';\nimport _possibleConstructorReturn from 'babel-runtime/helpers/possibleConstructorReturn';\nimport _inherits from 'babel-runtime/helpers/inherits';\n/* eslint react/no-did-mount-set-state: 0 */\nimport React, { cloneElement, Children, Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { findDOMNode } from 'react-dom';\nimport classNames from 'classnames';\nimport debounce from 'lodash/debounce';\nimport { isFlexSupported } from './utils';\n\nvar Steps = function (_Component) {\n  _inherits(Steps, _Component);\n\n  function Steps(props) {\n    _classCallCheck(this, Steps);\n\n    var _this = _possibleConstructorReturn(this, _Component.call(this, props));\n\n    _this.calcStepOffsetWidth = function () {\n      if (isFlexSupported()) {\n        return;\n      }\n      // Just for IE9\n      var domNode = findDOMNode(_this);\n      if (domNode.children.length > 0) {\n        if (_this.calcTimeout) {\n          clearTimeout(_this.calcTimeout);\n        }\n        _this.calcTimeout = setTimeout(function () {\n          // +1 for fit edge bug of digit width, like 35.4px\n          var lastStepOffsetWidth = (domNode.lastChild.offsetWidth || 0) + 1;\n          // Reduce shake bug\n          if (_this.state.lastStepOffsetWidth === lastStepOffsetWidth || Math.abs(_this.state.lastStepOffsetWidth - lastStepOffsetWidth) <= 3) {\n            return;\n          }\n          _this.setState({ lastStepOffsetWidth: lastStepOffsetWidth });\n        });\n      }\n    };\n\n    _this.state = {\n      flexSupported: true,\n      lastStepOffsetWidth: 0\n    };\n    _this.calcStepOffsetWidth = debounce(_this.calcStepOffsetWidth, 150);\n    return _this;\n  }\n\n  Steps.prototype.componentDidMount = function componentDidMount() {\n    this.calcStepOffsetWidth();\n    if (!isFlexSupported()) {\n      this.setState({\n        flexSupported: false\n      });\n    }\n  };\n\n  Steps.prototype.componentDidUpdate = function componentDidUpdate() {\n    this.calcStepOffsetWidth();\n  };\n\n  Steps.prototype.componentWillUnmount = function componentWillUnmount() {\n    if (this.calcTimeout) {\n      clearTimeout(this.calcTimeout);\n    }\n    if (this.calcStepOffsetWidth && this.calcStepOffsetWidth.cancel) {\n      this.calcStepOffsetWidth.cancel();\n    }\n  };\n\n  Steps.prototype.render = function render() {\n    var _classNames;\n\n    var _props = this.props,\n        prefixCls = _props.prefixCls,\n        _props$style = _props.style,\n        style = _props$style === undefined ? {} : _props$style,\n        className = _props.className,\n        children = _props.children,\n        direction = _props.direction,\n        labelPlacement = _props.labelPlacement,\n        iconPrefix = _props.iconPrefix,\n        status = _props.status,\n        size = _props.size,\n        current = _props.current,\n        progressDot = _props.progressDot,\n        initial = _props.initial,\n        icons = _props.icons,\n        restProps = _objectWithoutProperties(_props, ['prefixCls', 'style', 'className', 'children', 'direction', 'labelPlacement', 'iconPrefix', 'status', 'size', 'current', 'progressDot', 'initial', 'icons']);\n\n    var _state = this.state,\n        lastStepOffsetWidth = _state.lastStepOffsetWidth,\n        flexSupported = _state.flexSupported;\n\n    var filteredChildren = React.Children.toArray(children).filter(function (c) {\n      return !!c;\n    });\n    var lastIndex = filteredChildren.length - 1;\n    var adjustedlabelPlacement = !!progressDot ? 'vertical' : labelPlacement;\n    var classString = classNames(prefixCls, prefixCls + '-' + direction, className, (_classNames = {}, _classNames[prefixCls + '-' + size] = size, _classNames[prefixCls + '-label-' + adjustedlabelPlacement] = direction === 'horizontal', _classNames[prefixCls + '-dot'] = !!progressDot, _classNames));\n\n    return React.createElement(\n      'div',\n      _extends({ className: classString, style: style }, restProps),\n      Children.map(filteredChildren, function (child, index) {\n        if (!child) {\n          return null;\n        }\n        var stepNumber = initial + index;\n        var childProps = _extends({\n          stepNumber: '' + (stepNumber + 1),\n          prefixCls: prefixCls,\n          iconPrefix: iconPrefix,\n          wrapperStyle: style,\n          progressDot: progressDot,\n          icons: icons\n        }, child.props);\n        if (!flexSupported && direction !== 'vertical' && index !== lastIndex) {\n          childProps.itemWidth = 100 / lastIndex + '%';\n          childProps.adjustMarginRight = -Math.round(lastStepOffsetWidth / lastIndex + 1);\n        }\n        // fix tail color\n        if (status === 'error' && index === current - 1) {\n          childProps.className = prefixCls + '-next-error';\n        }\n        if (!child.props.status) {\n          if (stepNumber === current) {\n            childProps.status = status;\n          } else if (stepNumber < current) {\n            childProps.status = 'finish';\n          } else {\n            childProps.status = 'wait';\n          }\n        }\n        return cloneElement(child, childProps);\n      })\n    );\n  };\n\n  return Steps;\n}(Component);\n\nSteps.propTypes = {\n  prefixCls: PropTypes.string,\n  className: PropTypes.string,\n  iconPrefix: PropTypes.string,\n  direction: PropTypes.string,\n  labelPlacement: PropTypes.string,\n  children: PropTypes.any,\n  status: PropTypes.string,\n  size: PropTypes.string,\n  progressDot: PropTypes.oneOfType([PropTypes.bool, PropTypes.func]),\n  style: PropTypes.object,\n  initial: PropTypes.number,\n  current: PropTypes.number,\n  icons: PropTypes.shape({\n    finish: PropTypes.node,\n    error: PropTypes.node\n  })\n};\nSteps.defaultProps = {\n  prefixCls: 'rc-steps',\n  iconPrefix: 'rc',\n  direction: 'horizontal',\n  labelPlacement: 'horizontal',\n  initial: 0,\n  current: 0,\n  status: 'process',\n  size: '',\n  progressDot: false\n};\nexport default Steps;","import _extends from 'babel-runtime/helpers/extends';\nimport _objectWithoutProperties from 'babel-runtime/helpers/objectWithoutProperties';\nimport _classCallCheck from 'babel-runtime/helpers/classCallCheck';\nimport _possibleConstructorReturn from 'babel-runtime/helpers/possibleConstructorReturn';\nimport _inherits from 'babel-runtime/helpers/inherits';\nimport React from 'react';\nimport PropTypes from 'prop-types';\nimport classNames from 'classnames';\n\nfunction isString(str) {\n  return typeof str === 'string';\n}\n\nvar Step = function (_React$Component) {\n  _inherits(Step, _React$Component);\n\n  function Step() {\n    _classCallCheck(this, Step);\n\n    return _possibleConstructorReturn(this, _React$Component.apply(this, arguments));\n  }\n\n  Step.prototype.renderIconNode = function renderIconNode() {\n    var _classNames;\n\n    var _props = this.props,\n        prefixCls = _props.prefixCls,\n        progressDot = _props.progressDot,\n        stepNumber = _props.stepNumber,\n        status = _props.status,\n        title = _props.title,\n        description = _props.description,\n        icon = _props.icon,\n        iconPrefix = _props.iconPrefix,\n        icons = _props.icons;\n\n    var iconNode = void 0;\n    var iconClassName = classNames(prefixCls + '-icon', iconPrefix + 'icon', (_classNames = {}, _classNames[iconPrefix + 'icon-' + icon] = icon && isString(icon), _classNames[iconPrefix + 'icon-check'] = !icon && status === 'finish' && icons && !icons.finish, _classNames[iconPrefix + 'icon-close'] = !icon && status === 'error' && icons && !icons.error, _classNames));\n    var iconDot = React.createElement('span', { className: prefixCls + '-icon-dot' });\n    // `progressDot` enjoy the highest priority\n    if (progressDot) {\n      if (typeof progressDot === 'function') {\n        iconNode = React.createElement(\n          'span',\n          { className: prefixCls + '-icon' },\n          progressDot(iconDot, { index: stepNumber - 1, status: status, title: title, description: description })\n        );\n      } else {\n        iconNode = React.createElement(\n          'span',\n          { className: prefixCls + '-icon' },\n          iconDot\n        );\n      }\n    } else if (icon && !isString(icon)) {\n      iconNode = React.createElement(\n        'span',\n        { className: prefixCls + '-icon' },\n        icon\n      );\n    } else if (icons && icons.finish && status === 'finish') {\n      iconNode = React.createElement(\n        'span',\n        { className: prefixCls + '-icon' },\n        icons.finish\n      );\n    } else if (icons && icons.error && status === 'error') {\n      iconNode = React.createElement(\n        'span',\n        { className: prefixCls + '-icon' },\n        icons.error\n      );\n    } else if (icon || status === 'finish' || status === 'error') {\n      iconNode = React.createElement('span', { className: iconClassName });\n    } else {\n      iconNode = React.createElement(\n        'span',\n        { className: prefixCls + '-icon' },\n        stepNumber\n      );\n    }\n\n    return iconNode;\n  };\n\n  Step.prototype.render = function render() {\n    var _classNames2;\n\n    var _props2 = this.props,\n        className = _props2.className,\n        prefixCls = _props2.prefixCls,\n        style = _props2.style,\n        itemWidth = _props2.itemWidth,\n        _props2$status = _props2.status,\n        status = _props2$status === undefined ? 'wait' : _props2$status,\n        iconPrefix = _props2.iconPrefix,\n        icon = _props2.icon,\n        wrapperStyle = _props2.wrapperStyle,\n        adjustMarginRight = _props2.adjustMarginRight,\n        stepNumber = _props2.stepNumber,\n        description = _props2.description,\n        title = _props2.title,\n        progressDot = _props2.progressDot,\n        tailContent = _props2.tailContent,\n        icons = _props2.icons,\n        restProps = _objectWithoutProperties(_props2, ['className', 'prefixCls', 'style', 'itemWidth', 'status', 'iconPrefix', 'icon', 'wrapperStyle', 'adjustMarginRight', 'stepNumber', 'description', 'title', 'progressDot', 'tailContent', 'icons']);\n\n    var classString = classNames(prefixCls + '-item', prefixCls + '-item-' + status, className, (_classNames2 = {}, _classNames2[prefixCls + '-item-custom'] = icon, _classNames2));\n    var stepItemStyle = _extends({}, style);\n    if (itemWidth) {\n      stepItemStyle.width = itemWidth;\n    }\n    if (adjustMarginRight) {\n      stepItemStyle.marginRight = adjustMarginRight;\n    }\n    return React.createElement(\n      'div',\n      _extends({}, restProps, {\n        className: classString,\n        style: stepItemStyle\n      }),\n      React.createElement(\n        'div',\n        { className: prefixCls + '-item-tail' },\n        tailContent\n      ),\n      React.createElement(\n        'div',\n        { className: prefixCls + '-item-icon' },\n        this.renderIconNode()\n      ),\n      React.createElement(\n        'div',\n        { className: prefixCls + '-item-content' },\n        React.createElement(\n          'div',\n          { className: prefixCls + '-item-title' },\n          title\n        ),\n        description && React.createElement(\n          'div',\n          { className: prefixCls + '-item-description' },\n          description\n        )\n      )\n    );\n  };\n\n  return Step;\n}(React.Component);\n\nStep.propTypes = {\n  className: PropTypes.string,\n  prefixCls: PropTypes.string,\n  style: PropTypes.object,\n  wrapperStyle: PropTypes.object,\n  itemWidth: PropTypes.oneOfType([PropTypes.number, PropTypes.string]),\n  status: PropTypes.string,\n  iconPrefix: PropTypes.string,\n  icon: PropTypes.node,\n  adjustMarginRight: PropTypes.oneOfType([PropTypes.number, PropTypes.string]),\n  stepNumber: PropTypes.string,\n  description: PropTypes.any,\n  title: PropTypes.any,\n  progressDot: PropTypes.oneOfType([PropTypes.bool, PropTypes.func]),\n  tailContent: PropTypes.any,\n  icons: PropTypes.shape({\n    finish: PropTypes.node,\n    error: PropTypes.node\n  })\n};\nexport default Step;","import Steps from './Steps';\nimport Step from './Step';\n\nSteps.Step = Step;\n\nexport { Step };\nexport default Steps;"],"sourceRoot":""}